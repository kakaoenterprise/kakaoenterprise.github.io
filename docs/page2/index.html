<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="카카오엔터프라이즈 AI Research" />
<meta name="author" content="카카오엔터프라이즈" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="카카오엔터프라이즈 AI Lab에서 발표한 AI 논문과 연구 성과를 소개합니다." />
<meta property="og:description" content="카카오엔터프라이즈 AI Lab에서 발표한 AI 논문과 연구 성과를 소개합니다." />
<link rel="canonical" href="https://kakaoenterprise.github.io/page2/" />
<meta property="og:url" content="https://kakaoenterprise.github.io/page2/" />
<meta property="og:site_name" content="카카오엔터프라이즈 AI Research" />
<meta property="og:image" content="https://t1.kakaocdn.net/kakaoenterprise_com/sns/SNS_W.jpg" />
<meta property="og:type" content="website" />
<link rel="prev" href="https://kakaoenterprise.github.io/" />
<link rel="next" href="https://kakaoenterprise.github.io/page3" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://t1.kakaocdn.net/kakaoenterprise_com/sns/SNS_W.jpg" />
<meta property="twitter:title" content="카카오엔터프라이즈 AI Research" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"카카오엔터프라이즈"},"description":"카카오엔터프라이즈 AI Lab에서 발표한 AI 논문과 연구 성과를 소개합니다.","headline":"카카오엔터프라이즈 AI Research","image":"https://t1.kakaocdn.net/kakaoenterprise_com/sns/SNS_W.jpg","url":"https://kakaoenterprise.github.io/page2/"}</script>
<!-- End Jekyll SEO tag -->

  
  <title> 카카오엔터프라이즈 AI Research | 카카오엔터프라이즈 AI Research </title>
  

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link  rel="stylesheet" href="https://fonts.googleapis.com/css?family=Nanum+Gothic:400,700,800&amp;subset=korean">

  <!-- Favicon -->
  <link rel="shortcut icon" href="/assets/favicon-96x96.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-icon-180x180.png">

  <!-- Icon -->
  <script src="https://kit.fontawesome.com/29661d1774.js" crossorigin="anonymous"></script>

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="https://kakaoenterprise.github.io/feed.xml" title="카카오엔터프라이즈 AI Research" />

  <!-- Google Analytics-->
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YVX7R4680W"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-YVX7R4680W');
</script>

  

  <!-- Google Search -->
  <meta name="google-site-verification" content="g1aJ_c07rYqVQwi6hpDDBI9jGk1wrEqOOj2bJI_CWHE" />

  <!-- Naver Search-->
  <meta name="naver-site-verification" content="faa46269506eaffea0caefdeeb1feb5166961947" />

  <!-- katex -->
  
</head>

  <body>
    <nav class="nav">
  <div class="nav-container">
    <a href="/">
      <h2 class="nav-title">Kakao Enterprise AI Research</h2>
    </a>
    <ul>
      <li><a href="/papers">Papers</a></li>
      <li><a href="https://tech.kakaoenterprise.com/" target="_blank">Tech&</a></li>
      <li><a href="http://kko.to/icW8PeHsT" target="_blank">Careers</a></li>
    </ul>
  </div>
</nav>

    <main>
      <div class="catalogue">
  
      <a href="/papers/coling-multi-context-retrieval" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Persona-Knowledge Dialogue Multi-Context Retrieval and Enhanced Decoding Methods</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">Customized Chat Grounding Persona and Knowledge Workshop at COLING 2022. 10</h4>
        </div>
      </a>
  
      <a href="/papers/interspeech-rnn-t" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Generalizing RNN-Transducer to Out-Domain Audio via Sparse Self-Attention Layers</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">INTERSPEECH 2022. 09</h4>
        </div>
      </a>
  
      <a href="/papers/interspeech-pronunciation" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Automatic Pronunciation Assessment using Self-Supervised Speech Representation Learning</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">INTERSPEECH 2022. 09</h4>
        </div>
      </a>
  
      <a href="/papers/interspeech-emotion-recognition" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">The Emotion is Not One-hot Encoding: Learning with Grayscale Label for Emotion Recognition in Conversation</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">INTERSPEECH 2022. 09</h4>
        </div>
      </a>
  
      <a href="/papers/interspeech-jets" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">JETS: Jointly Training FastSpeech2 and HiFi-GAN for End to End Text to Speech</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">INTERSPEECH 2022. 09</h4>
        </div>
      </a>
  
      <a href="/papers/ieee-pnaa" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Proxyless Neural Architecture Adaptation at Once</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">IEEE Access 2022. 09</h4>
        </div>
      </a>
  
      <a href="/papers/ieee-action-seg" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Efficient Two-Stream Network for Online Video Action Segmentation</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">IEEE Access 2022. 08</h4>
        </div>
      </a>
  
      <a href="/papers/icpr-pose-estimation" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Classification-based Multi-task Learning for Efficient Pose Estimation Network</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICPR 2022. 08</h4>
        </div>
      </a>
  
      <a href="/papers/icpr-comdense" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">KNOWLEDGE GRAPH</h4>
          <h1 class="catalogue-title">ComDensE : Combined Dense Embedding of Relation-aware and Common Features for Knowledge Graph Completion</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICPR 2022. 08</h4>
        </div>
      </a>
  
      <a href="/papers/sigkdd-oasys" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">KNOWLEDGE GRAPH</h4>
          <h1 class="catalogue-title">OASYS: Domain-Agnostic Automated System for Constructing Knowledge Base from Unstructured Text</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">Mining and Learning on Graphs Workshop at SIGKDD 2022. 08</h4>
        </div>
      </a>
  
      <a href="/papers/sigkdd-federated-learning" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">MACHINE LEARNING</h4>
          <h1 class="catalogue-title">Connecting a Low Loss Subspace for Personalized Federated Learning</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">SIGKDD Research Track 2022. 08</h4>
        </div>
      </a>
  
      <a href="/papers/inlg-paraphrasing" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Paraphrasing via Ranking Many Candidates</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">INLG 2022. 07</h4>
        </div>
      </a>
  
      <a href="/papers/icml-point-cloud-data" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">A Statistical Manifold Framework for Point Cloud Data</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICML 2022. 07</h4>
        </div>
      </a>
  
      <a href="/papers/sigir-rl-irs" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">REINFORCEMENT LEARNING</h4>
          <h1 class="catalogue-title">Towards Validating Long-Term User Feedbacks in Interactive Recommendation Systems</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">SIGIR (Best Short Paper Honorable Mention) 2022. 07</h4>
        </div>
      </a>
  
      <a href="/papers/naacl-compm" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">CoMPM: Context Modeling with Speaker's Pre-trained Memory Tracking for Emotion Recognition in Conversation</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">NAACL 2022. 07</h4>
        </div>
      </a>
  
      <a href="/papers/cvpr-contrastive-regularization" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Contrastive Regularization for Semi-Supervised Learning</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">L3D-IVU Workshop at CVPR 2022. 06</h4>
        </div>
      </a>
  
      <a href="/papers/cvpr-xvit" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">X-ViT: High Performance Linear Vision Transformer without Softmax</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">Transformers for Vision Workshop at CVPR 2022. 06</h4>
        </div>
      </a>
  
      <a href="/papers/humeval-meta-evaluation" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Vacillating Human Correlation of SacreBLEU in Unprotected Languages</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">Human Evaluation of NLP Systems Workshop at ACL 2022. 05</h4>
        </div>
      </a>
  
      <a href="/papers/aaai-simmc" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Multimodal Interactions Using Pretrained Unimodal Models for SIMMC 2.0</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">DSTC10 Wokrshop at AAAI 2022. 02</h4>
        </div>
      </a>
  
      <a href="/papers/aaai-pnaa" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Proxyless Neural Architecture Adaptation for Supervised Learning and Self-Supervised Learning</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">Learning Network Architecture during Training Workshop at AAAI 2022. 02</h4>
        </div>
      </a>
  
      <a href="/papers/arxiv-apeach" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">APEACH: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">Arxiv 2022. 02</h4>
        </div>
      </a>
  
      <a href="/papers/neurips-smoothmix" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">NeurIPS 2021. 12</h4>
        </div>
      </a>
  
      <a href="/papers/neurips-learning-debiased-representation" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Learning Debiased Representation via Disentangled Feature Augmentation</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">NeurIPS Oral 2021. 12</h4>
        </div>
      </a>
  
      <a href="/papers/wmt21-terminology-translation" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Kakao Enterprise’s WMT21 Machine Translation using Terminologies Task Submission</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">WMT 2021 System Papers 2021. 11</h4>
        </div>
      </a>
  
      <a href="/papers/newsum-csi" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Capturing Speaker Incorrectness: Speaker-Focused Post-Correction for Abstractive Dialogue Summarization</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">NewSum workshop, EMNLP 2021. 11</h4>
        </div>
      </a>
  
      <a href="/papers/emnlp-evaluation-dataset-and-strategy" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">An Evaluation Dataset and Strategy for Building Robust Multi-turn Response Selection Model</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">EMNLP 2021. 11</h4>
        </div>
      </a>
  
      <a href="/papers/emnlp-alignart" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">AligNART: Non-autoregressive Neural Machine Translation by Jointly Learning to Estimate Alignment and Translate</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">EMNLP 2021. 11</h4>
        </div>
      </a>
  
      <a href="/papers/iccv-distilling-global-and-local-logits" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Distilling Global and Local Logits with Densely Connected Relations</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICCV 2021. 10</h4>
        </div>
      </a>
  
      <a href="/papers/ieee-e2e-csr" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Improving End-to-End Contextual Speech Recognition via a Word-Matching Algorithm with Backward Search</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">IEEE Signal Processing Letters 2021. 10</h4>
        </div>
      </a>
  
      <a href="/papers/interspeech2021-univnet" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">INTERSPEECH 2021. 08</h4>
        </div>
      </a>
  
      <a href="/papers/interspeech2021-sl-tasks-for-disfluency-detection" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Auxiliary Sequence Labeling Tasks for Disfluency Detection</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">INTERSPEECH 2021. 08</h4>
        </div>
      </a>
  
      <a href="/papers/interspeech2021-se-conformer" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">SE-Conformer: Time-Domain Speech Enhancement using Conformer</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">INTERSPEECH 2021. 08</h4>
        </div>
      </a>
  
      <a href="/papers/sigkdd-t-gap" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Learning to Walk across Time for Interpretable Temporal Knowledge Graph Completion</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">SIGKDD Research Track Long Paper 2021. 08</h4>
        </div>
      </a>
  
      <a href="/papers/ieeeaccess-adaptive-batch-scheduling" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Adaptive Batch Scheduling for Open-Domain Question Answering</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">IEEE Access 2021. 08</h4>
        </div>
      </a>
  
      <a href="/papers/acl-ijcnlp2021-dcran" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Deep Context- and Relation-Aware Learning for Aspect-based Sentiment Analysis</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ACL-IJCNLP Main Conference 2021. 08</h4>
        </div>
      </a>
  
      <a href="/papers/acl-ijcnlp2021-outflip" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">OutFlip: Generating Examples for Unknown Intent Detection with Natural Language Attack</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ACL-IJCNLP Findings of ACL 2021. 08</h4>
        </div>
      </a>
  
      <a href="/papers/icml2021-vilt" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICML Long Talk 2021. 07</h4>
        </div>
      </a>
  
      <a href="/papers/icml2021-e2e-tts" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICML 2021. 07</h4>
        </div>
      </a>
  
      <a href="/papers/icassp2021-u-convolution-based-residual-eco-suppression" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">U-Convolution Based Residual Echo Suppression With Multiple Encoders</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICASSP 2021. 06</h4>
        </div>
      </a>
  
      <a href="/papers/icassp2021-transformer-rnn-tranducer-speech-recognition" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Multitask Learning and Joint Optimization For Transformer-Rnn-Tranducer Speech Recognition</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICASSP 2021. 06</h4>
        </div>
      </a>
  
      <a href="/papers/ieeeaccess2021-iee" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Korean Erroneous Sentence Classification with Integrated Eojeol Embedding</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">IEEE Access 2021. 06</h4>
        </div>
      </a>
  
      <a href="/papers/ieeeaccess2021-dasn" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Suppressing Spoof-irrelevant Factors for Domain-agnostic Face Anti-spoofing</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">IEEE Access 2021. 05</h4>
        </div>
      </a>
  
      <a href="/papers/cljournal2021-ryansql" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases</h1>
          <div class="catalogue-line"></div>

          <p>
            중첩된 SELECT문을 좀 더 정확하게 생성하는 SPC 기법을 적용한 Text-to-SQL 알고리즘 'RYANSQL' 제안
          </p>

          <h4 class="catalogue-publisher">Computational Linguistics 2021. 03</h4>
        </div>
      </a>
  
      <a href="/papers/ieee2020-fden" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">A Plug-in Method for Representation Factorization in Connectionist Models</h1>
          <div class="catalogue-line"></div>

          <p>
            딥러닝 모델에서 추출한 임베딩 벡터를 독립 요인으로 분해하는 기법 ‘FDEN’ 제안
          </p>

          <h4 class="catalogue-publisher">IEEE Transactions on Neural Networks and Learning Systems 2021. 02</h4>
        </div>
      </a>
  
      <a href="/papers/aaai2021-mdr" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Multi-level Distance Regularization for Deep Metric Learning</h1>
          <div class="catalogue-line"></div>

          <p>
            딥러닝 기반 거리 학습에 적합한 새로운 정규화 기법 ‘MDR’ 제안
          </p>

          <h4 class="catalogue-publisher">AAAI 2021. 02</h4>
        </div>
      </a>
  
      <a href="/papers/aaai2021-multi-turn-response-selection" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Do Response Selection Models Really Know What's Next? Utterance Manipulation Strategies for Multi-turn Response Selection</h1>
          <div class="catalogue-line"></div>

          <p>
            응답 선택에서 대화 맥락에 호응하면서도 의미적 유사도가 높은 문장을 선택하는 기법 'UMS' 제안
          </p>

          <h4 class="catalogue-publisher">AAAI 2021. 02</h4>
        </div>
      </a>
  
      <a href="/papers/neurips2020-hifi-gan" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</h1>
          <div class="catalogue-line"></div>

          <p>
            고품질의 음성 오디오를 빠르게 합성하는 TTS 모델 'Hi-Fi GAN' 제안
          </p>

          <h4 class="catalogue-publisher">NeurIPS 2020. 12</h4>
        </div>
      </a>
  
      <a href="/papers/neurips2020-glow-tts" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search</h1>
          <div class="catalogue-line"></div>

          <p>
            플로우 기반 생성 모델과 동적 프로그래밍을 활용한 TTS 모델 'Glow-TTS' 제안
          </p>

          <h4 class="catalogue-publisher">NeurIPS Oral 2020. 12</h4>
        </div>
      </a>
  
      <a href="/papers/inlg2020-stable-style-transformer" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Stable Style Transformer: Delete and Generate Approach with Encoder-Decoder for Text Style Transfer</h1>
          <div class="catalogue-line"></div>

          <p>
            비병렬 데이터셋을 활용한 새로운 텍스트 스타일 변환 모델 'SST' 제안
          </p>

          <h4 class="catalogue-publisher">INLG 2020. 12</h4>
        </div>
      </a>
  
      <a href="/papers/coling2020-rdass" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Reference and Document Aware Semantic Evaluation Methods for Korean Language Summarization</h1>
          <div class="catalogue-line"></div>

          <p>
            텍스트 요약 모델을 평가하는 새로운 척도 'RDASS' 제안
          </p>

          <h4 class="catalogue-publisher">COLING 2020. 12</h4>
        </div>
      </a>
  
      <a href="/papers/ieee2020-face-video-retrieval" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Face Video Retrieval Based on the Deep CNN With RBF Loss</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">IEEE Transactions on Image Processing 2020. 12</h4>
        </div>
      </a>
  
      <a href="/papers/emnlp2020-stable-zero-shot-nmt" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Sparse and Decorrelated Representations for Stable Zero-shot NMT</h1>
          <div class="catalogue-line"></div>

          <p>
            강건한 제로샷 번역 모델을 위해 정규화 기법 'SLNI' 도입 제안
          </p>

          <h4 class="catalogue-publisher">EMNLP Findings of ACL 2020. 11</h4>
        </div>
      </a>
  
      <a href="/papers/emnlp2020-m2nmt" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Revisiting modularized multilingual NMT to meet industrial demands</h1>
          <div class="catalogue-line"></div>

          <p>
            다국어 번역 모델 아키텍처인 'M2NMT'의 재발견
          </p>

          <h4 class="catalogue-publisher">EMNLP 2020. 11</h4>
        </div>
      </a>
  
      <a href="/papers/emnlp2020-attnio" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">AttnIO: Knowledge Graph Exploration with In-and-Out Attention Flow for Knowledge-Grounded Dialogue</h1>
          <div class="catalogue-line"></div>

          <p>
            대화 맥락에 따른 지식 그래프 경로 탐색 모델 'AttnIO' 제안
          </p>

          <h4 class="catalogue-publisher">EMNLP 2020. 11</h4>
        </div>
      </a>
  
      <a href="/papers/ieee2020-accelerating-neural-transducer-inference" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Accelerating RNN Transducer Inference via Adaptive Expansion Search</h1>
          <div class="catalogue-line"></div>

          <p>
            E2E 음성인식의 가속화를 위한 적응적 검색 기법 'AES' 제안
          </p>

          <h4 class="catalogue-publisher">IEEE Signal Processing Letters 2020. 11</h4>
        </div>
      </a>
  
      <a href="/papers/icip2020-effective-and-scalable-person-search" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Learning Discriminative Part Features Through Attentions For Effective And Scalable Person Search</h1>
          <div class="catalogue-line"></div>

          <p>
            한 번의 딥러닝 추론으로 사람 검출과 검색을 한꺼번에 구현하는 기법 제안
          </p>

          <h4 class="catalogue-publisher">ICIP 2020. 10</h4>
        </div>
      </a>
  
      <a href="/papers/interspeech2020-jdi-t" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">JDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech without Explicit Alignment</h1>
          <div class="catalogue-line"></div>

          <p>
            음성합성 모델과 음소-오디오 정렬 모델을 한꺼번에 훈련하는 아키텍처 'JDI-T' 제안
          </p>

          <h4 class="catalogue-publisher">INTERSPEECH 2020. 10</h4>
        </div>
      </a>
  
      <a href="/papers/eccv2020-deep-metric-learning" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Diversified Mutual Learning for Deep Metric Learning</h1>
          <div class="catalogue-line"></div>

          <p>
            여러 모델간 상호학습 방식으로 이미지 검색 성능을 높이는 기법 제안
          </p>

          <h4 class="catalogue-publisher">ECCV workshop on TASK-CV 2020. 09</h4>
        </div>
      </a>
  
      <a href="/papers/eccv2020-broadface" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">BroadFace: Looking at Tens of Thousands of People at Once for Face Recognition</h1>
          <div class="catalogue-line"></div>

          <p>
            수많은 사람의 얼굴을 효과적으로 학습하는 기법 'BroadFace' 제안
          </p>

          <h4 class="catalogue-publisher">ECCV 2020. 08</h4>
        </div>
      </a>
  
      <a href="/papers/cvpr2020-deep-metric-learning" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Deep Metric Learning with Multi-Objective Functions</h1>
          <div class="catalogue-line"></div>

          <p>
            패션 이미지를 효율적으로 검색하는 새로운 거리학습 기법 제안
          </p>

          <h4 class="catalogue-publisher">CVPR workshop on CVFAD 2020. 06</h4>
        </div>
      </a>
  
      <a href="/papers/cvpr2020-groupface" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">GroupFace: Learning Latent Groups and Constructing Group-based Representations for Face Recognition</h1>
          <div class="catalogue-line"></div>

          <p>
            얼굴 인식에 전문화된 새로운 아키텍처 'GroupFace' 제안
          </p>

          <h4 class="catalogue-publisher">CVPR 2020. 06</h4>
        </div>
      </a>
  
      <a href="/papers/sensors2020-emotion-recognition" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Affective Latent Representation of Acoustic and Lexical Features for Emotion Recognition</h1>
          <div class="catalogue-line"></div>

          <p>
            음성의 음향・어휘 특성을 동시에 반영해 사람의 감정을 효과적으로 인식하는 아키텍처 제안
          </p>

          <h4 class="catalogue-publisher">SENSORS 2020. 05</h4>
        </div>
      </a>
  
      <a href="/papers/icassp2020-many-to-many-voice-conversion" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Many-to-Many Voice Conversion using Conditional Cycle-Consistent Adversarial Networks</h1>
          <div class="catalogue-line"></div>

          <p>
            CycleGAN을 활용해 다자 간의 음성 스타일을 변환하는 기법 제안
          </p>

          <h4 class="catalogue-publisher">ICASSP 2020. 02</h4>
        </div>
      </a>
  
      <a href="/papers/iccv2019-face-recognition" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Attentional Feature-Pair Relation Networks for Accurate Face Recognition</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICCV 2019. 10</h4>
        </div>
      </a>
  
      <a href="/papers/iccv2019-basn" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">BASN: Enriching Feature Representation Using Bipartite Auxiliary Supervision for Face Anti-Spoofing</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICCV Workshop on DFW 2019. 10</h4>
        </div>
      </a>
  
      <a href="/papers/hclt2019-web-scale-open-domain-korean-question-answering" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">기계 독해를 이용한 웹 기반 오픈 도메인 한국어 질의응답</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">한글 및 한국어정보처리 학술대회 2019. 10</h4>
        </div>
      </a>
  
      <a href="/papers/hclt2019-eojeol-based-embedding" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">한국어 챗봇에서의 오류에 강건한 한국어 문장 분류를 위한 어절 단위 임베딩</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">한글 및 한국어정보처리 학술대회 2019. 10</h4>
        </div>
      </a>
  
      <a href="/papers/hclt2019-construction-of-annotated-corpora" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">오픈도메인 질의문 자동 분류를 위한 주석 말뭉치 구축 연구</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">한글 및 한국어정보처리 학술대회 2019. 10</h4>
        </div>
      </a>
  
      <a href="/papers/hclt2019-answer-type-classifier" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">한국어 질의 응답에서의 화제성을 고려한 딥러닝 기반 정답 유형 분류기</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">한글 및 한국어정보처리 학술대회 2019. 10</h4>
        </div>
      </a>
  
      <a href="/papers/icassp2019-speech-enhancement" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Speech Enhancement Using a Two-Stage Network for an Efficient Boosting Strategy</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICASSP 2019. 05</h4>
        </div>
      </a>
  
      <a href="/papers/icassp2019-emotion-recognition" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">DNN-based Emotion Recognition based on Bottleneck Acoustic Features and Lexical Features</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICASSP 2019. 05</h4>
        </div>
      </a>
  
      <a href="/papers/uncorrelated-feature-encoding-for-faster-image-style-transfer" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Uncorrelated Feature Encoding for Faster Image Style Transfer</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">arXiv 2018. 07</h4>
        </div>
      </a>
  
      <a href="/papers/iapr-mva2017-faster-rnnn-for-object-detection" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Refining faster-RCNN for accurate object detection</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">IAPR MVA 2017. 05</h4>
        </div>
      </a>
  
</div>

    </main>
    <footer>
  <a class="footer-link" href="https://github.com/kakaoenterprise" target="_blank">
    <img src="/assets/GitHub-Mark.png" alt="Kakao Enterprise GitHub" />GitHub</a>
  <br/>
  <a class="footer-copyright">Copyright © Kakao Enterprise All rights reserved.</a>

</footer>


    <!-- Naver Analytics -->
    <script type="text/javascript" src="//wcs.naver.net/wcslog.js"></script>
    <script type="text/javascript">
    if(!wcs_add) var wcs_add = {};
    wcs_add["wa"] = "d6495f190ca3e0";
    if(window.wcs) {
    wcs_do();
    }
    </script>
  </body>
</html>
