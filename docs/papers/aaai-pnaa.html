<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Proxyless Neural Architecture Adaptation for Supervised Learning and Self-Supervised Learning" />
<meta name="author" content="ê¹€ë„êµ­:ì¸í•˜ëŒ€í•™êµ" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Abstract" />
<meta property="og:description" content="Abstract" />
<link rel="canonical" href="https://kakaoenterprise.github.io/papers/aaai-pnaa" />
<meta property="og:url" content="https://kakaoenterprise.github.io/papers/aaai-pnaa" />
<meta property="og:site_name" content="ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ AI Research" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-02-28T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Proxyless Neural Architecture Adaptation for Supervised Learning and Self-Supervised Learning" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"ê¹€ë„êµ­:ì¸í•˜ëŒ€í•™êµ"},"description":"Abstract","@type":"BlogPosting","url":"https://kakaoenterprise.github.io/papers/aaai-pnaa","headline":"Proxyless Neural Architecture Adaptation for Supervised Learning and Self-Supervised Learning","dateModified":"2022-02-28T00:00:00-06:00","datePublished":"2022-02-28T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://kakaoenterprise.github.io/papers/aaai-pnaa"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  
  <title> Proxyless Neural Architecture Adaptation for Supervised Learning and Self-Supervised Learning | ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ AI Research </title>
  

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link  rel="stylesheet" href="https://fonts.googleapis.com/css?family=Nanum+Gothic:400,700,800&amp;subset=korean">

  <!-- Favicon -->
  <link rel="shortcut icon" href="/assets/favicon-96x96.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-icon-180x180.png">

  <!-- Icon -->
  <script src="https://kit.fontawesome.com/29661d1774.js" crossorigin="anonymous"></script>

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="https://kakaoenterprise.github.io/feed.xml" title="ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ AI Research" />

  <!-- Google Analytics-->
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YVX7R4680W"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-YVX7R4680W');
</script>

  

  <!-- Google Search -->
  <meta name="google-site-verification" content="g1aJ_c07rYqVQwi6hpDDBI9jGk1wrEqOOj2bJI_CWHE" />

  <!-- Naver Search-->
  <meta name="naver-site-verification" content="faa46269506eaffea0caefdeeb1feb5166961947" />

  <!-- katex -->
  
</head>

  <body>
    <nav class="nav">
  <div class="nav-container">
    <a href="/">
      <h2 class="nav-title">Kakao Enterprise AI Research</h2>
    </a>
    <ul>
      <li><a href="/papers">Papers</a></li>
      <li><a href="https://tech.kakaoenterprise.com/" target="_blank">Tech&</a></li>
    </ul>
  </div>
</nav>

    <main>
      <article class="post">
  <header class="post-header">
    <h4 class="catalogue-research-area">COMPUTER VISION</h4>
    <h1 class="post-title">Proxyless Neural Architecture Adaptation for Supervised Learning and Self-Supervised Learning</h1>

    

    

    ê¹€ë„êµ­(ì¸í•˜ëŒ€í•™êµ), ì´í¥ì°½(ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ)

    <h4>
        
          Learning Network Architecture during Training Workshop at AAAI
        
    </h4>

    <h4>2022-02-28</h4>

    
      <div class="link-button-group">
        
          <a href="https://arxiv.org/pdf/2205.07168.pdf" target="_blank">
            <button class="link-button">
              <i class="far fa-file-alt"></i> Paper
            </button>
          </a>
        

        

        
      </div>
    
  </header>

  <div class="post-line"></div>

  <div class="post-body">
    <h1 id="abstract">Abstract</h1>

<p>Recently, Neural Architecture Search (NAS) methods are introduced and show impressive performance on many benchmarks.
Among those NAS studies, Neural Architecture Transformer (NAT) aims to adapt the given neural architecture to improve performance while maintaining computational costs.
However, NAT lacks reproducibility and it requires an additional architecture adaptation process before network weight training.
In this paper, we propose proxyless neural architecture adaptation that is reproducible and efficient.
Our method can be applied to both supervised learning and self-supervised learning.
The proposed method shows stable performance on various architectures.
Extensive reproducibility experiments on two datasets, i.e., CIFAR-10 and Tiny Imagenet, present that the proposed method definitely outperforms NAT and be applicable to other models and datasets.</p>

<p><br /></p>

<hr />

<p><br /></p>

<p>ë³¸ ê¸€ì—ì„œëŠ” ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆì™€ ì¸í•˜ëŒ€ ê³µë™ ì—°êµ¬íŒ€ì´ ì—°ì‚° ìì›ì„ ë§ì´ ì‚¬ìš©í•˜ëŠ” ê¸°ì¡´ NASì˜ ë‹¨ì ì„ ë³´ì™„í•˜ê³ ì, ìƒˆë¡­ê²Œ ì œì•ˆí•œ ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•´ ì†Œê°œë“œë¦¬ë ¤ê³  í•©ë‹ˆë‹¤. í•´ë‹¹ ì—°êµ¬ ê²°ê³¼ëŠ” AAAI 2022 í•™íšŒì—ì„œ Workshopìœ¼ë¡œ ê°œìµœëœ <strong>Learning Network Architecture during Training</strong> ì„ í†µí•´ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤.</p>

<p><br /></p>

<h1 id="1-nasneural-architecture-searchì˜-ë“±ì¥">1. NAS(Neural Architecture Search)ì˜ ë“±ì¥</h1>

<p>ì¼ë°˜ì ìœ¼ë¡œ ë”¥ëŸ¬ë‹ì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ì–»ê¸° ìœ„í•´ì„œëŠ” ì£¼ì–´ì§„ taskì™€ ë°ì´í„°ì…‹ì— ìµœì í™”ëœ ëª¨ë¸ êµ¬ì¡°ë¥¼ ì°¾ëŠ” ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ì‚¬ëŒì´ ì§ì ‘ ê° ë ˆì´ì–´ì™€ í•„í„° ê°œìˆ˜ ë“± ì—¬ëŸ¬ ì„¤ì •ì„ ì¼ì¼ì´ ë¯¸ì„¸ì¡°ì •í•˜ê³  ì„¤ê³„í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹˜ëŠ”ë°ìš”. ìµœì í™”ëœ ëª¨ë¸ êµ¬ì¡°ëŠ” ê° taskì™€ ë°ì´í„°ì…‹ì— ë”°ë¼ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì—, í•´ë‹¹ êµ¬ì¡°ì˜ ì„±ëŠ¥ì€ ì‹¤ì œ í•™ìŠµì„ ì§„í–‰í•œ ë’¤ ê·¸ ê²°ê³¼ë¡œë§Œ íŒë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p>ë°”ë¡œ ì´ëŸ¬í•œ ë¶ˆí¸í•¨ì„ ê°œì„ í•˜ê³ ì ë“±ì¥í•œ ì—°êµ¬ ë¶„ì•¼ê°€ <strong>NAS(Neural Architecture Search)</strong> ì…ë‹ˆë‹¤. NASëŠ” ìë™í™”ë¥¼ í†µí•´ ì£¼ì–´ì§„ taskì— ìµœì í™”ëœ ëª¨ë¸ êµ¬ì¡°ë¥¼ í¸ë¦¬í•˜ê³  ë¹ ë¥´ê²Œ íƒìƒ‰í•˜ëŠ” ë°©ë²•ë¡ ìœ¼ë¡œ, ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ ëˆˆì— ë„ëŠ” ìš°ìˆ˜í•œ ì—°êµ¬ì„±ê³¼ë“¤ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.</p>

<p>ì—¬ê¸°ì„œ ë” ë‚˜ì•„ê°€, ìµœê·¼ì—ëŠ” NASì˜ ì´ì ì€ ìœ ì§€í•˜ë©´ì„œ ì—°ì‚°ë¹„ìš©ì„ ì¤„ì¸ ì—¬ëŸ¬ ì—°êµ¬ê°€ ì£¼ëª©ë°›ê³  ìˆëŠ”ë°ìš”. ê·¸ ì¤‘ í•˜ë‚˜ë¡œëŠ”, ê¸°ì¡´ì— ë°©ëŒ€í•œ ì•„í‚¤í…ì²˜ í›„ë³´êµ°(Search Space)ì„ ì•„ì£¼ ì‘ê²Œ ì¤„ì—¬ì„œ ìµœì ì˜ ì•„í‚¤í…ì²˜ë¥¼ ì°¾ëŠ” <strong>NAT(Neural Architecture Transformer)</strong> ë°©ì‹ì´ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, NATì€ ì•Œê³ ë¦¬ì¦˜ì˜ ì¬í˜„ì„±(reproducibility)ì´ ë–¨ì–´ì§€ê³ , ë™ì¼í•œ ì…€ ì•„í‚¤í…ì²˜ êµ¬ì¡° í•˜ì—ì„œë§Œ íƒìƒ‰ì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ë‹¨ì ì´ ìˆëŠ”ë°ìš”.</p>

<p><br /></p>

<h1 id="2-proxyless-neural-architecture-adaption-ë°©ë²•ë¡ -ì†Œê°œ">2. Proxyless Neural Architecture Adaption ë°©ë²•ë¡  ì†Œê°œ</h1>

<p>ë³¸ ì—°êµ¬ì—ì„œëŠ” NATì˜ ë‹¨ì ì„ ê°œì„ í•œ <strong>Proxyless Neural Architecture Adaption</strong> ë°©ë²•ë¡ ì„ ìƒˆë¡­ê²Œ ì œì•ˆí•˜ì˜€ìŠµë‹ˆë‹¤.</p>

<p>ì´ ë°©ë²•ë¡ ì€ NATê³¼ ë¹„êµí•´ ì¬í˜„ì„±ì´ ë†’ê³ , íš¨ìœ¨ì ì´ë¼ëŠ” ì ì´ íŠ¹ì§•ì¸ë°ìš”. NATì—ì„œëŠ” ì¶”ê°€ì ì¸ ì•„í‚¤í…ì²˜ ì„œì¹˜ ê³¼ì •ì´ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— í•™ìŠµì‹œê°„ê³¼ GPU ìì› ì†Œëª¨ê°€ í°ë° ë°˜í•´, ë³¸ ë°©ë²•ë¡ ì€ ì•„í‚¤í…ì²˜ ì„œì¹˜ì™€ ëª¨ë¸ í•™ìŠµì„ ë™ì‹œì— ì§„í–‰í•˜ì—¬ ìì›ì„ í¬ê²Œ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p>ë˜í•œ, í•˜ë‚˜ì˜ ì…€(cell) ë‹¨ìœ„ê°€ ì•„ë‹Œ ë‹¤ì–‘í•œ ì…€ ì•„í‚¤í…ì²˜ë¥¼ ê°€ì§„ ë§¤í¬ë¡œë¸”ë¡(macroblock) ê¸°ë°˜ íƒìƒ‰ìœ¼ë¡œ ì „ì²´ ë²”ìœ„ë¥¼ íƒìƒ‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ë¿ë§Œ ì•„ë‹ˆë¼, ì§€ë„í•™ìŠµ(Supervised Learning)ê³¼ ìê¸°ì§€ë„í•™ìŠµ(Self-Supervised Learning)ì— ëª¨ë‘ ì ìš©ë  ìˆ˜ ìˆì–´ í™œìš©ë„ê°€ ë†’ì€ë°ìš”.</p>

<p><img src="/assets/img/2022-02-28-AAAI-PNAA/001.png" width="70%" align="" /></p>

<p><em class="center">ê·¸ë¦¼1. Proxyless Neural Architecture Adaption ë°©ë²•ë¡ ì„ ì ìš©í•œ ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ ê²€ìƒ‰ êµ¬ì¡°</em></p>

<p><br /></p>

<h1 id="3-ì„±ëŠ¥-ë¹„êµ">3. ì„±ëŠ¥ ë¹„êµ</h1>

<p>ì´ ë°©ë²•ë¡ ì˜ ì„±ëŠ¥ê³¼ ê´‘ë²”ìœ„í•œ ì¬í˜„ì„±ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ <strong>CIFAR-10</strong>ê³¼ <strong>Tiny Imagenet</strong> ë°ì´í„°ì…‹ì— ì—¬ëŸ¬ê°€ì§€ ëª¨ë¸ë¡œ ì‹¤í—˜ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.</p>

<p>ë¨¼ì € ì§€ë„í•™ìŠµ í™˜ê²½ì—ì„œ ìˆ˜ì‘ì—…ìœ¼ë¡œ ì„¤ê³„ëœ Resnet20ê³¼ MobilentV2, NAS ëª¨ë¸ì¸ DARTSì™€ Proxyless NAS ëª¨ë¸ì„ í™œìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. ê¸°ì¡´ ë°©ì‹ê³¼ NAT, ë³¸ ë°©ë²•ë¡ ìœ¼ë¡œ ì‹¤í—˜ì„ ì§„í–‰í•œ ê²°ê³¼, [í‘œ1]ê³¼ ê°™ì´ ë‹¤ì–‘í•œ ì•„í‚¤í…ì²˜ì—ì„œ ê¸°ì¡´ ë°©ë²•ë¡  ëŒ€ë¹„ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë”ë¶ˆì–´ ì „ì²´ì ì¸ ì—°ì‚°ë¹„ìš© ì¸¡ë©´ì—ì„œë„ NATê³¼ ë¹„êµí•´ ë” ì ì€ ë¹„ìš©ì„ ì‚¬ìš©í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p>

<p><img src="/assets/img/2022-02-28-AAAI-PNAA/002.png" width="50%" align="" /></p>

<p><em class="center">í‘œ1. ì§€ë„í•™ìŠµì—ì„œì˜ í‰ê·  ì •í™•ë„, í‘œì¤€í¸ì°¨, ì—°ì‚°ì‹œê°„ ë¹„êµ (CIFAR-10 ê¸°ì¤€)</em></p>

<p>í‘œ2ì—ì„œëŠ” ë§ˆì°¬ê°€ì§€ë¡œ CIFAR-10 ë°ì´í„°ì…‹ ìƒì—ì„œ 5ë²ˆì˜ ë¬´ì‘ìœ„ ì‹œë„ë¥¼ ê±°ì³ ì¬í˜„ì„±ì„ í…ŒìŠ¤íŠ¸ ì§„í–‰í•˜ì˜€ê³ , ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p>

<p><img src="/assets/img/2022-02-28-AAAI-PNAA/003.png" width="50%" align="" /></p>

<p><em class="center">í‘œ2. ì§€ë„í•™ìŠµì—ì„œì˜ ì¬í˜„ì„± ë¹„êµ (CIFAR-10 ê¸°ì¤€)</em></p>

<p><img src="/assets/img/2022-02-28-AAAI-PNAA/004.png" width="50%" align="" /></p>

<p><em class="center">í‘œ3. ì§€ë„í•™ìŠµì—ì„œì˜ í‰ê·  ì •í™•ë„, í‘œì¤€í¸ì°¨, ì—°ì‚°ì‹œê°„ ë¹„êµ (Tiny Imagenet ê¸°ì¤€)</em></p>

<p>ë˜í•œ, ìê¸°ì§€ë„í•™ìŠµ í™˜ê²½ì—ì„œë„ ì„±ëŠ¥ì„ í™•ì¸í•˜ê¸° ìœ„í•´ NASëª¨ë¸ì¸ DARTSì™€ Proxyless NASì— ì¶”ê°€ì ì¸ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ì˜€ê³ , ì—¬ê¸°ì—ì„œë„ ê¸°ì¡´ ë°©ì‹ ëŒ€ë¹„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤.</p>

<p><img src="/assets/img/2022-02-28-AAAI-PNAA/005.png" width="50%" align="" /></p>

<p><em class="center">í‘œ4. ìê¸°ì§€ë„í•™ìŠµì—ì„œì˜ ì •í™•ë„ ë¹„êµ (CIFAR-10 ê¸°ì¤€)</em></p>

<p><br /></p>

<h1 id="4-í–¥í›„-ì—°êµ¬-ê³„íš">4. í–¥í›„ ì—°êµ¬ ê³„íš</h1>

<p>ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ ì—°êµ¬íŒ€ì€ í•´ë‹¹ ë°©ë²•ë¡ ì„ í™œìš©í•˜ì—¬ ì •í™•ë„ë¥¼ ë„˜ì–´, ê²°ê³¼ê°€ ë„ì¶œë˜ëŠ” ì‹œê°„, ì†ë„(latency)ê¹Œì§€ ê³ ë ¤í•œ ëª¨ë¸ì„ ë§Œë“¤ê³ ì í•©ë‹ˆë‹¤. íŠ¹íˆ ì»´í“¨í„°ë¹„ì „ ë¶„ì•¼ ì—°êµ¬ì— ì ìš©í•´ ìµœì ì˜ ëª¨ë¸ êµ¬ì¡°ë¥¼ ë¹ ë¥´ê³ , ì €ë¹„ìš©ìœ¼ë¡œ íƒìƒ‰í•˜ëŠ” ë°ì— ì¤‘ì ì„ ë‘˜ ê³„íšì…ë‹ˆë‹¤.</p>

<p>ì•ìœ¼ë¡œë„ ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆì˜ AI ì—°êµ¬ì— ë§ì€ ê´€ì‹¬ ë¶€íƒë“œë¦¬ë©°, <strong>ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ AI Lab &amp; Service</strong>ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹œë‹¤ë©´ ì•„ë˜ ë§í¬ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”!</p>

<p>ğŸ‘¨ğŸ»â€ğŸ’» <a href="http://kko.to/ailab_career">ì¸ì¬ì˜ì…</a></p>

  </div>

  <div class="post-line"></div>

  <div class="post-tag-box-container">
    
  </div>
</article>
<div class="pagination">
    <a onclick="window.history.back()" class="left arrow" style="cursor: pointer;">&#8592; ëª©ë¡ìœ¼ë¡œ</a>
</div>

    </main>
    <footer>
  <a class="footer-link" href="https://github.com/kakaoenterprise" target="_blank">
    <img src="/assets/GitHub-Mark.png" alt="Kakao Enterprise GitHub" />GitHub</a>
  <br/>
  <a class="footer-copyright">Copyright Â© Kakao Enterprise All rights reserved.</a>

</footer>


    <!-- Naver Analytics -->
    <script type="text/javascript" src="//wcs.naver.net/wcslog.js"></script>
    <script type="text/javascript">
    if(!wcs_add) var wcs_add = {};
    wcs_add["wa"] = "d6495f190ca3e0";
    if(window.wcs) {
    wcs_do();
    }
    </script>
  </body>
</html>
