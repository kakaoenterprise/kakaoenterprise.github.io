<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Papers | Kakao Enterprise AI Research</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Papers" />
<meta name="author" content="카카오엔터프라이즈" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="카카오엔터프라이즈 연구 성과를 공개하는 리서치 플랫폼" />
<meta property="og:description" content="카카오엔터프라이즈 연구 성과를 공개하는 리서치 플랫폼" />
<link rel="canonical" href="https://kakaoenterprise.github.io/papers/" />
<meta property="og:url" content="https://kakaoenterprise.github.io/papers/" />
<meta property="og:site_name" content="Kakao Enterprise AI Research" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Papers" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"카카오엔터프라이즈"},"description":"카카오엔터프라이즈 연구 성과를 공개하는 리서치 플랫폼","@type":"WebPage","headline":"Papers","url":"https://kakaoenterprise.github.io/papers/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link  rel="stylesheet" href="https://fonts.googleapis.com/css?family=Nanum+Gothic:400,700,800&amp;subset=korean">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png">

  <!-- Icon -->
  <script src="https://kit.fontawesome.com/29661d1774.js" crossorigin="anonymous"></script>

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="https://kakaoenterprise.github.io/feed.xml" title="Kakao Enterprise AI Research" />

  <!-- Google Analytics-->
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YVX7R4680W"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-YVX7R4680W');
</script>

  

  <!-- Google Search -->
  <meta name="google-site-verification" content="wjM0-ayVnmSnH6JrvoDSaK75Yy8x0y8RBJpuF3JaO9E" />

  <!-- Naver Search-->
  <meta name="naver-site-verification" content="1960bd91e47ca89bc4201d4e49f5de5062229786"/>

  <!-- katex -->
  
</head>

  <body>
    <nav class="nav">
  <div class="nav-container">
    <a href="/">
      <h2 class="nav-title">Kakao Enterprise AI Research</h2>
    </a>
    <ul>
      <li><a href="/papers">Papers</a></li>
    </ul>
  </div>
</nav>

    <main>
      <div class="catalogue">
  
      <a href="/papers/interspeech2021-univnet" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">INTERSPEECH 2021. 08</h4>
        </div>
      </a>
  
      <a href="/papers/interspeech2021-sl-tasks-for-disfluency-detection" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Auxiliary Sequence Labeling Tasks for Disfluency Detection</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">INTERSPEECH 2021. 08</h4>
        </div>
      </a>
  
      <a href="/papers/interspeech2021-se-conformer" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">SE-Conformer: Time-Domain Speech Enhancement using Conformer</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">INTERSPEECH 2021. 08</h4>
        </div>
      </a>
  
      <a href="/papers/sigkdd-t-gap" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Learning to Walk across Time for Interpretable Temporal Knowledge Graph Completion</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">SIGKDD Research Track Long Paper 2021. 08</h4>
        </div>
      </a>
  
      <a href="/papers/acl-ijcnlp2021-dcran" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Deep Context- and Relation-Aware Learning for Aspect-based Sentiment Analysis</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ACL-IJCNLP Main Conference 2021. 08</h4>
        </div>
      </a>
  
      <a href="/papers/acl-ijcnlp2021-outflip" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">OutFlip: Generating Examples for Unknown Intent Detection with Natural Language Attack</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ACL-IJCNLP Findings of ACL 2021. 08</h4>
        </div>
      </a>
  
      <a href="/papers/icml2021-vilt" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICML Long Talk 2021. 07</h4>
        </div>
      </a>
  
      <a href="/papers/icml2021-e2e-tts" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICML 2021. 07</h4>
        </div>
      </a>
  
      <a href="/papers/icassp2021-u-convolution-based-residual-eco-suppression" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">U-Convolution Based Residual Echo Suppression With Multiple Encoders</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICASSP 2021. 06</h4>
        </div>
      </a>
  
      <a href="/papers/icassp2021-transformer-rnn-tranducer-speech-recognition" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Multitask Learning and Joint Optimization For Transformer-Rnn-Tranducer Speech Recognition</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICASSP 2021. 06</h4>
        </div>
      </a>
  
      <a href="/papers/ieeeaccess2021-iee" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Korean Erroneous Sentence Classification with Integrated Eojeol Embedding</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">IEEE Access 2021. 06</h4>
        </div>
      </a>
  
      <a href="/papers/ieeeaccess2021-dasn" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Suppressing Spoof-irrelevant Factors for Domain-agnostic Face Anti-spoofing</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">IEEE Access 2021. 05</h4>
        </div>
      </a>
  
      <a href="/papers/cljournal2021-ryansql" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases</h1>
          <div class="catalogue-line"></div>

          <p>
            중첩된 SELECT문을 좀 더 정확하게 생성하는 SPC 기법을 적용한 Text-to-SQL 알고리즘 'RYANSQL' 제안
          </p>

          <h4 class="catalogue-publisher">Computational Linguistics 2021. 03</h4>
        </div>
      </a>
  
      <a href="/papers/ieee2020-fden" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">A Plug-in Method for Representation Factorization in Connectionist Models</h1>
          <div class="catalogue-line"></div>

          <p>
            딥러닝 모델에서 추출한 임베딩 벡터를 독립 요인으로 분해하는 기법 ‘FDEN’ 제안
          </p>

          <h4 class="catalogue-publisher">IEEE Transactions on Neural Networks and Learning Systems 2021. 02</h4>
        </div>
      </a>
  
      <a href="/papers/aaai2021-multi-turn-response-selection" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Do Response Selection Models Really Know What's Next? Utterance Manipulation Strategies for Multi-turn Response Selection</h1>
          <div class="catalogue-line"></div>

          <p>
            응답 선택에서 대화 맥락에 호응하면서도 의미적 유사도가 높은 문장을 선택하는 기법 'UMS' 제안
          </p>

          <h4 class="catalogue-publisher">AAAI 2021. 02</h4>
        </div>
      </a>
  
      <a href="/papers/aaai2021-mdr" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Multi-level Distance Regularization for Deep Metric Learning</h1>
          <div class="catalogue-line"></div>

          <p>
            딥러닝 기반 거리 학습에 적합한 새로운 정규화 기법 ‘MDR’ 제안
          </p>

          <h4 class="catalogue-publisher">AAAI 2021. 02</h4>
        </div>
      </a>
  
      <a href="/papers/neurips2020-hifi-gan" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</h1>
          <div class="catalogue-line"></div>

          <p>
            고품질의 음성 오디오를 빠르게 합성하는 TTS 모델 'Hi-Fi GAN' 제안
          </p>

          <h4 class="catalogue-publisher">NeurIPS 2020. 12</h4>
        </div>
      </a>
  
      <a href="/papers/neurips2020-glow-tts" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search</h1>
          <div class="catalogue-line"></div>

          <p>
            플로우 기반 생성 모델과 동적 프로그래밍을 활용한 TTS 모델 'Glow-TTS' 제안
          </p>

          <h4 class="catalogue-publisher">NeurIPS Oral 2020. 12</h4>
        </div>
      </a>
  
      <a href="/papers/inlg2020-stable-style-transformer" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Stable Style Transformer: Delete and Generate Approach with Encoder-Decoder for Text Style Transfer</h1>
          <div class="catalogue-line"></div>

          <p>
            비병렬 데이터셋을 활용한 새로운 텍스트 스타일 변환 모델 'SST' 제안
          </p>

          <h4 class="catalogue-publisher">INLG 2020. 12</h4>
        </div>
      </a>
  
      <a href="/papers/coling2020-rdass" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Reference and Document Aware Semantic Evaluation Methods for Korean Language Summarization</h1>
          <div class="catalogue-line"></div>

          <p>
            텍스트 요약 모델을 평가하는 새로운 척도 'RDASS' 제안
          </p>

          <h4 class="catalogue-publisher">COLING 2020. 12</h4>
        </div>
      </a>
  
      <a href="/papers/ieee2020-accelerating-neural-transducer-inference" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Accelerating Neural Transducer Inference via Adaptive Expansion Search</h1>
          <div class="catalogue-line"></div>

          <p>
            E2E 음성인식의 가속화를 위한 적응적 검색 기법 'AES' 제안
          </p>

          <h4 class="catalogue-publisher">IEEE Signal Processing Letters 2020. 11</h4>
        </div>
      </a>
  
      <a href="/papers/ieee2020-face-video-retrieval" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Face Video Retrieval Based on the Deep CNN With RBF Loss</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">IEEE Transactions on Image Processing 2020. 12</h4>
        </div>
      </a>
  
      <a href="/papers/emnlp2020-stable-zero-shot-nmt" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Sparse and Decorrelated Representations for Stable Zero-shot NMT</h1>
          <div class="catalogue-line"></div>

          <p>
            강건한 제로샷 번역 모델을 위해 정규화 기법 'SLNI' 도입 제안
          </p>

          <h4 class="catalogue-publisher">EMNLP Findings of ACL 2020. 11</h4>
        </div>
      </a>
  
      <a href="/papers/emnlp2020-m2nmt" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">Revisiting modularized multilingual NMT to meet industrial demands</h1>
          <div class="catalogue-line"></div>

          <p>
            다국어 번역 모델 아키텍처인 'M2NMT'의 재발견
          </p>

          <h4 class="catalogue-publisher">EMNLP 2020. 11</h4>
        </div>
      </a>
  
      <a href="/papers/emnlp2020-attnio" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">AttnIO: Knowledge Graph Exploration with In-and-Out Attention Flow for Knowledge-Grounded Dialogue</h1>
          <div class="catalogue-line"></div>

          <p>
            대화 맥락에 따른 지식 그래프 경로 탐색 모델 'AttnIO' 제안
          </p>

          <h4 class="catalogue-publisher">EMNLP 2020. 11</h4>
        </div>
      </a>
  
      <a href="/papers/icip2020-effective-and-scalable-person-search" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Learning Discriminative Part Features Through Attentions For Effective And Scalable Person Search</h1>
          <div class="catalogue-line"></div>

          <p>
            한 번의 딥러닝 추론으로 사람 검출과 검색을 한꺼번에 구현하는 기법 제안
          </p>

          <h4 class="catalogue-publisher">ICIP 2020. 10</h4>
        </div>
      </a>
  
      <a href="/papers/interspeech2020-jdi-t" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">JDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech without Explicit Alignment</h1>
          <div class="catalogue-line"></div>

          <p>
            음성합성 모델과 음소-오디오 정렬 모델을 한꺼번에 훈련하는 아키텍처 'JDI-T' 제안
          </p>

          <h4 class="catalogue-publisher">INTERSPEECH 2020. 10</h4>
        </div>
      </a>
  
      <a href="/papers/eccv2020-deep-metric-learning" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Diversified Mutual Learning for Deep Metric Learning</h1>
          <div class="catalogue-line"></div>

          <p>
            여러 모델간 상호학습 방식으로 이미지 검색 성능을 높이는 기법 제안
          </p>

          <h4 class="catalogue-publisher">ECCV workshop on TASK-CV 2020. 09</h4>
        </div>
      </a>
  
      <a href="/papers/eccv2020-broadface" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">BroadFace: Looking at Tens of Thousands of People at Once for Face Recognition</h1>
          <div class="catalogue-line"></div>

          <p>
            수많은 사람의 얼굴을 효과적으로 학습하는 기법 'BroadFace' 제안
          </p>

          <h4 class="catalogue-publisher">ECCV 2020. 08</h4>
        </div>
      </a>
  
      <a href="/papers/cvpr2020-deep-metric-learning" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Deep Metric Learning with Multi-Objective Functions</h1>
          <div class="catalogue-line"></div>

          <p>
            패션 이미지를 효율적으로 검색하는 새로운 거리학습 기법 제안
          </p>

          <h4 class="catalogue-publisher">CVPR workshop on CVFAD 2020. 06</h4>
        </div>
      </a>
  
      <a href="/papers/cvpr2020-groupface" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">GroupFace: Learning Latent Groups and Constructing Group-based Representations for Face Recognition</h1>
          <div class="catalogue-line"></div>

          <p>
            얼굴 인식에 전문화된 새로운 아키텍처 'GroupFace' 제안
          </p>

          <h4 class="catalogue-publisher">CVPR 2020. 06</h4>
        </div>
      </a>
  
      <a href="/papers/sensors2020-emotion-recognition" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Affective Latent Representation of Acoustic and Lexical Features for Emotion Recognition</h1>
          <div class="catalogue-line"></div>

          <p>
            음성의 음향・어휘 특성을 동시에 반영해 사람의 감정을 효과적으로 인식하는 아키텍처 제안
          </p>

          <h4 class="catalogue-publisher">SENSORS 2020. 05</h4>
        </div>
      </a>
  
      <a href="/papers/icassp2020-many-to-many-voice-conversion" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Many-to-Many Voice Conversion using Conditional Cycle-Consistent Adversarial Networks</h1>
          <div class="catalogue-line"></div>

          <p>
            CycleGAN을 활용해 다자 간의 음성 스타일을 변환하는 기법 제안
          </p>

          <h4 class="catalogue-publisher">ICASSP 2020. 02</h4>
        </div>
      </a>
  
      <a href="/papers/iccv2019-face-recognition" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Attentional Feature-Pair Relation Networks for Accurate Face Recognition</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICCV 2019. 10</h4>
        </div>
      </a>
  
      <a href="/papers/iccv2019-basn" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">BASN: Enriching Feature Representation Using Bipartite Auxiliary Supervision for Face Anti-Spoofing</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICCV Workshop on DFW 2019. 10</h4>
        </div>
      </a>
  
      <a href="/papers/hclt2019-web-scale-open-domain-korean-question-answering" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">기계 독해를 이용한 웹 기반 오픈 도메인 한국어 질의응답</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">한글 및 한국어정보처리 학술대회 2019. 10</h4>
        </div>
      </a>
  
      <a href="/papers/hclt2019-eojeol-based-embedding" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">한국어 챗봇에서의 오류에 강건한 한국어 문장 분류를 위한 어절 단위 임베딩</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">한글 및 한국어정보처리 학술대회 2019. 10</h4>
        </div>
      </a>
  
      <a href="/papers/hclt2019-construction-of-annotated-corpora" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">오픈도메인 질의문 자동 분류를 위한 주석 말뭉치 구축 연구</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">한글 및 한국어정보처리 학술대회 2019. 10</h4>
        </div>
      </a>
  
      <a href="/papers/hclt2019-answer-type-classifier" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">한국어 질의 응답에서의 화제성을 고려한 딥러닝 기반 정답 유형 분류기</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">한글 및 한국어정보처리 학술대회 2019. 10</h4>
        </div>
      </a>
  
      <a href="/papers/icassp2019-speech-enhancement" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
          <h1 class="catalogue-title">Speech Enhancement Using a Two-Stage Network for an Efficient Boosting Strategy</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICASSP 2019. 05</h4>
        </div>
      </a>
  
      <a href="/papers/icassp2019-emotion-recognition" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">NLP</h4>
          <h1 class="catalogue-title">DNN-based Emotion Recognition based on Bottleneck Acoustic Features and Lexical Features</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">ICASSP 2019. 05</h4>
        </div>
      </a>
  
      <a href="/papers/uncorrelated-feature-encoding-for-faster-image-style-transfer" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Uncorrelated Feature Encoding for Faster Image Style Transfer</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">arXiv 2018. 07</h4>
        </div>
      </a>
  
      <a href="/papers/iapr-mva2017-faster-rnnn-for-object-detection" class="catalogue-item">
        <div>
          <h4 class="catalogue-research-area">COMPUTER VISION</h4>
          <h1 class="catalogue-title">Refining faster-RCNN for accurate object detection</h1>
          <div class="catalogue-line"></div>

          <p>
            
          </p>

          <h4 class="catalogue-publisher">IAPR MVA 2017. 05</h4>
        </div>
      </a>
  
</div>

    </main>
    <footer>
  <a class="footer-link" href="https://github.com/kakaoenterprise" target="_blank">
    <img src="/assets/GitHub-Mark.png" alt="Kakao Enterprise GitHub" />GitHub</a>
  <br/>
  <a class="footer-copyright">Copyright © Kakao Enterprise All rights reserved.</a>

</footer>


    <!-- Naver Analytics -->
    <script type="text/javascript" src="//wcs.naver.net/wcslog.js"></script>
    <script type="text/javascript">
    if(!wcs_add) var wcs_add = {};
    wcs_add["wa"] = "d6495f190ca3e0";
    if(window.wcs) {
    wcs_do();
    }
    </script>
  </body>
</html>
