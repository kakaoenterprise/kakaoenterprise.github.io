<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Revisiting modularized multilingual NMT to meet industrial demands | Kakao Enterprise AI Research</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Revisiting modularized multilingual NMT to meet industrial demands" />
<meta name="author" content="james:카카오엔터프라이즈" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="다국어 번역 모델 아키텍처인 ‘M2NMT’의 재발견" />
<meta property="og:description" content="다국어 번역 모델 아키텍처인 ‘M2NMT’의 재발견" />
<link rel="canonical" href="https://kakaoenterprise.github.io/papers/emnlp2020-m2nmt" />
<meta property="og:url" content="https://kakaoenterprise.github.io/papers/emnlp2020-m2nmt" />
<meta property="og:site_name" content="Kakao Enterprise AI Research" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-16T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Revisiting modularized multilingual NMT to meet industrial demands" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"james:카카오엔터프라이즈"},"headline":"Revisiting modularized multilingual NMT to meet industrial demands","dateModified":"2020-11-16T00:00:00-06:00","description":"다국어 번역 모델 아키텍처인 ‘M2NMT’의 재발견","datePublished":"2020-11-16T00:00:00-06:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kakaoenterprise.github.io/papers/emnlp2020-m2nmt"},"url":"https://kakaoenterprise.github.io/papers/emnlp2020-m2nmt","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link  rel="stylesheet" href="https://fonts.googleapis.com/css?family=Nanum+Gothic:400,700,800&amp;subset=korean">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png">

  <!-- Icon -->
  <script src="https://kit.fontawesome.com/29661d1774.js" crossorigin="anonymous"></script>

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="https://kakaoenterprise.github.io/feed.xml" title="Kakao Enterprise AI Research" />

  <!-- Google Analytics-->
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YVX7R4680W"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-YVX7R4680W');
</script>

  

  <!-- Naver Search-->
  <meta name="naver-site-verification" content="1960bd91e47ca89bc4201d4e49f5de5062229786"/>

  <!-- katex -->
  
</head>

  <body>
    <nav class="nav">
  <div class="nav-container">
    <a href="/">
      <h2 class="nav-title">Kakao Enterprise AI Research</h2>
    </a>
    <ul>
      <li><a href="/papers">Papers</a></li>
    </ul>
  </div>
</nav>

    <main>
      <article class="post">
  <header class="post-header">
    <h4 class="catalogue-research-area">NLP</h4>
    <h1 class="post-title">Revisiting modularized multilingual NMT to meet industrial demands</h1>

    

    

    류성원(카카오엔터프라이즈), 손보경(카카오엔터프라이즈), 양기창(카카오엔터프라이즈), 배재경(카카오엔터프라이즈)

    <h4>
        
          Empirical Methods in Natural Language Processing (EMNLP)
        
    </h4>

    <h4>2020-11-16</h4>

    
      <div class="link-button-group">
        
          <a href="https://www.aclweb.org/anthology/2020.emnlp-main.476.pdf" target="_blank">
            <button class="link-button">
              <i class="far fa-file-alt"></i> Paper
            </button>
          </a>
        

        

        
          <a href="/deepdive/201217" target="_self">
            <button class="link-button">
              <i class="far fa-newspaper"></i> DeepDive
            </button>
          </a>
        
      </div>
    
  </header>

  <div class="post-line"></div>

  <div class="post-body">
    <p>카카오엔터프라이즈는 M2NMT<sup>Modularized Multilingual Neural Machine Translation Model</sup><sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>의 가치를 재발견했습니다. 여러 번역 조건에서 성능 저하를 보이는 1-1 MNMT<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>와는 달리, M2NMT에서는 성능이 유지됐습니다. 새로 추가된 언어를 포함한 태스크에서 NMT<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>보다 좋은 성능을 보일 수 있음을 확인하였습니다. 또한, 제로샷<sup>zero-shot</sup><sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup> 에서 피벗 방식<sup>pivot translation</sup><sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">5</a></sup> 보다 더 좋은 성능을 달성했습니다. 카카오엔터프라이즈는 다국어 학습으로 인한 시너지<sup>data-diversification, and regularization effect</sup>가 주된 요인이라 분석했습니다.</p>

<p>카카오엔터프라이즈는 향후 이 모델이 생성한 ‘언어에 독립적인 특징 공간<sup>interlingual space</sup>‘의 여러 효용을 검증하는 연구를 진행할 계획입니다.</p>

<p><br /></p>

<h1 id="abstract">Abstract</h1>

<p>The complete sharing of parameters for multilingual translation (1-1) has been the mainstream approach in current research. However, degraded performance due to the capacity bot- tleneck and low maintainability hinders its extensive adoption in industries. In this study, we revisit the multilingual neural machine translation model that only shares modules among the same languages (M2) as a practical alternative to 1-1 to satisfy industrial requirements. Through comprehensive experiments, we identify the benefits of multi-way training and demonstrate that the M2 can enjoy these benefits without suffering from the capacity bottleneck. Furthermore, the interlingual space of the M2 allows convenient modification of the model. By leveraging trained modules, we find that incrementally added modules exhibit better performance than singly trained models. The zero-shot performance of the added modules is even comparable to supervised models. Our findings suggest that the M2 can be a competent candidate for multilingual translation in industries.</p>

<p><br /></p>

<h1 id="experiments">Experiments</h1>

<p>By extensively comparing the single models, 1-1 model, and M2 in varying conditions, we find that the M2 can benefit from multi-way training through data-diversification and regularization while suffering less from capacity bottlenecks.</p>

<p><img src="/assets/img/2020-11-16-EMNLP-M2NMT/001.png" width="" align="" /></p>

<p><em>[ Table 1 ] Averaged SacreBLEU test scores of single models, 1-1, and M2 trained using a balanced dataset of different configurations.  M2M  indicates the training of full many-to-many directions among languages (12 directions), whereas  JM2M  represents the training of directions that only include English on one side(6 directions). * indicates that the score is averaged only on English-centric.</em></p>

<p><br /></p>

<hr />

<h3 id="footnotes">Footnotes</h3>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>다국어 번역을 위해 모든 언어마다 인코더와 디코더를 둔 아키텍처 <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>다국어 번역을 위해 한쌍의 인코더와 디코더를 둔 아키텍처 <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>두 언어간 번역을 위해 한쌍의 인코더와 디코더를 둔 아키텍처 <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>학습되지 않은 방향의 번역 <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>두 언어쌍에 대한 병렬 말뭉치(parallel corpus)를 구하기가 상대적으로 어려운 상황적 특성을 반영해, 전세계적으로 가장 많이 쓰이는 언어인 ‘영어’로 두번 번역한다. 예를 들어, 한국어↔︎중국어 번역 시 한국어↔︎영어로, 영어↔︎중국어로 번역한다. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div>

  <div class="post-line"></div>

  <div class="post-tag-box-container">
    
      <div class="post-tag-box">#NMT</div>
    
  </div>
</article>
<div class="pagination">
    <a onclick="window.history.back()" class="left arrow" style="cursor: pointer;">&#8592; 목록으로</a>
</div>

    </main>
    <footer>
  <a class="footer-link" href="https://github.com/kakaoenterprise" target="_blank">
    <img src="/assets/GitHub-Mark.png" alt="Kakao Enterprise GitHub" />GitHub</a>
  <br/>
  <a class="footer-copyright">Copyright © Kakao Enterprise All rights reserved.</a>

</footer>

  </body>
</html>
