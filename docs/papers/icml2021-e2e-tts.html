<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech | Kakao Enterprise AI Research</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech" />
<meta name="author" content="jay:카카오엔터프라이즈" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Abstract" />
<meta property="og:description" content="Abstract" />
<link rel="canonical" href="https://kakaoenterprise.github.io/papers/icml2021-e2e-tts" />
<meta property="og:url" content="https://kakaoenterprise.github.io/papers/icml2021-e2e-tts" />
<meta property="og:site_name" content="Kakao Enterprise AI Research" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-07-18T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"jay:카카오엔터프라이즈"},"description":"Abstract","@type":"BlogPosting","url":"https://kakaoenterprise.github.io/papers/icml2021-e2e-tts","headline":"Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech","dateModified":"2021-07-18T00:00:00-05:00","datePublished":"2021-07-18T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://kakaoenterprise.github.io/papers/icml2021-e2e-tts"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link  rel="stylesheet" href="https://fonts.googleapis.com/css?family=Nanum+Gothic:400,700,800&amp;subset=korean">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png">

  <!-- Icon -->
  <script src="https://kit.fontawesome.com/29661d1774.js" crossorigin="anonymous"></script>

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="https://kakaoenterprise.github.io/feed.xml" title="Kakao Enterprise AI Research" />

  <!-- Google Analytics-->
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YVX7R4680W"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-YVX7R4680W');
</script>

  

  <!-- Google Search -->
  <meta name="google-site-verification" content="wjM0-ayVnmSnH6JrvoDSaK75Yy8x0y8RBJpuF3JaO9E" />

  <!-- Naver Search-->
  <meta name="naver-site-verification" content="1960bd91e47ca89bc4201d4e49f5de5062229786"/>

  <!-- katex -->
  
</head>

  <body>
    <nav class="nav">
  <div class="nav-container">
    <a href="/">
      <h2 class="nav-title">Kakao Enterprise AI Research</h2>
    </a>
    <ul>
      <li><a href="/papers">Papers</a></li>
      <li><a href="/deepdive">Deepdive</a></li>
    </ul>
  </div>
</nav>

    <main>
      <article class="post">
  <header class="post-header">
    <h4 class="catalogue-research-area">SPEECH/AUDIO</h4>
    <h1 class="post-title">Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</h1>

    

    

    김재현(카카오엔터프라이즈), 공정일(카카오엔터프라이즈), 손주희(카카오엔터프라이즈/KAIST)

    <h4>
        
          International Conference on Machine Learning (ICML)
        
    </h4>

    <h4>2021-07-18</h4>

    
  </header>

  <div class="post-line"></div>

  <div class="post-body">
    <h1 id="abstract">Abstract</h1>

<p>Several recent end-to-end text-to-speech (TTS) models enabling single-stage training and parallel sampling have been proposed, but their sample quality does not match that of two-stage TTS systems. In this work, we present a parallel end-to-end TTS method that generates more natural sounding audio than current two-stage models. Our method adopts variational inference augmented with normalizing flows and an adversarial training process, which improves the expressive power of generative modeling. We also propose a stochastic duration predictor to synthesize speech with diverse rhythms from input text. With the uncertainty modeling over latent variables and the stochastic duration predictor, our method expresses the natural one-to-many relationship in which a text input can be spoken in multiple ways with different pitches and rhythms. A subjective human evaluation (mean opinion score, or MOS) on the LJ Speech, a single speaker dataset, shows that our method outperforms the best publicly available TTS systems and achieves a MOS comparable to ground truth.</p>

  </div>

  <div class="post-line"></div>

  <div class="post-tag-box-container">
    
  </div>
</article>
<div class="pagination">
    <a onclick="window.history.back()" class="left arrow" style="cursor: pointer;">&#8592; 목록으로</a>
</div>

    </main>
    <footer>
  <a class="footer-link" href="https://github.com/kakaoenterprise" target="_blank">
    <img src="/assets/GitHub-Mark.png" alt="Kakao Enterprise GitHub" />GitHub</a>
  <br/>
  <a class="footer-copyright">Copyright © Kakao Enterprise All rights reserved.</a>

</footer>


    <!-- Naver Analytics -->
    <script type="text/javascript" src="//wcs.naver.net/wcslog.js"></script>
    <script type="text/javascript">
    if(!wcs_add) var wcs_add = {};
    wcs_add["wa"] = "d6495f190ca3e0";
    if(window.wcs) {
    wcs_do();
    }
    </script>
  </body>
</html>
