<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://kakaoenterprise.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://kakaoenterprise.github.io/" rel="alternate" type="text/html" /><updated>2021-05-28T06:32:38-05:00</updated><id>https://kakaoenterprise.github.io/feed.xml</id><title type="html">Kakao Enterprise AI Research</title><subtitle>카카오엔터프라이즈 연구 성과를 공개하는 리서치 플랫폼</subtitle><author><name>카카오엔터프라이즈</name></author><entry><title type="html">Learning to Walk across Time for Interpretable Temporal Knowledge Graph Completion</title><link href="https://kakaoenterprise.github.io/papers/sigkdd-t-gap" rel="alternate" type="text/html" title="Learning to Walk across Time for Interpretable Temporal Knowledge Graph Completion" /><published>2021-08-14T00:00:00-05:00</published><updated>2021-08-14T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/sigkdd-t-gap</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/sigkdd-t-gap">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Static knowledge graphs(KGs), despite their wide usage in relational reasoning and downstream tasks, fall short of realistic modeling of knowledge and facts that are only temporarily valid. Compared to static knowledge graphs, temporal knowledge graphs(TKGs) inherently reflect the transient nature of real-world knowledge. Naturally, automatic TKG completion has drawn much research interests for a more realistic modeling of relational reasoning. However, most of the existing models for TKG completion extend static KG embeddings that do not fully exploit TKG structure, thus lacking in 1) accounting for temporally relevant events already residing in the local neighborhood of a query, and 2) path-based inference that facilitates multi-hop reasoning and better interpretability. In this paper, we propose T-GAP, a novel model for TKG completion that maximally utilizes both temporal information and graph structure in its encoder and decoder. T-GAP encodes query-specific substructure of TKG by focusing on the temporal displacement between each event and the query timestamp, and performs path-based inference by propagating attention through the graph. Our empirical experiments demonstrate that T-GAP not only achieves superior performance against state-of-the-art baselines, but also competently generalizes to queries with unseen timestamps. Through extensive qualitative analyses, we also show that T-GAP enjoys transparent interpretability, and follows human intuition in its reasoning process.&lt;/p&gt;</content><author><name>hoony:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Deep Context- and Relation-Aware Learning for Aspect-based Sentiment Analysis</title><link href="https://kakaoenterprise.github.io/papers/acl-ijcnlp2021-dcran" rel="alternate" type="text/html" title="Deep Context- and Relation-Aware Learning for Aspect-based Sentiment Analysis" /><published>2021-08-01T00:00:00-05:00</published><updated>2021-08-01T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/acl-ijcnlp2021-dcran</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/acl-ijcnlp2021-dcran">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Existing works for aspect-based sentiment analysis (ABSA) have adopted a unified approach, which allows the interactive relations among subtasks. However, we observe that these methods tend to predict polarities based on the literal meaning of aspect and opinion terms and mainly consider relations implicitly among subtasks at the word level. In addition, identifying multiple aspect–opinion pairs with their polarities is much more challenging. Therefore, a comprehensive understanding of contextual information w.r.t. the aspect and opinion is further required in ABSA. In this paper, we propose Deep Contextualized Relation-Aware Network (DCRAN), which allows interactive relations among subtasks with deep contextual information based on two modules (i.e., Aspect and Opinion Propagation and Explicit Self-Supervised Strategies). Especially, we design novel self-supervised strategies for ABSA, which have strengths in dealing with multiple aspects. Experimental results show that DCRAN significantly outperforms previous state-of-the-art methods by large margins on three widely used benchmarks.&lt;/p&gt;</content><author><name>오신혁:넷마블</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">OutFlip: Generating Examples for Unknown Intent Detection with Natural Language Attack</title><link href="https://kakaoenterprise.github.io/papers/acl-ijcnlp2021-outflip" rel="alternate" type="text/html" title="OutFlip: Generating Examples for Unknown Intent Detection with Natural Language Attack" /><published>2021-08-01T00:00:00-05:00</published><updated>2021-08-01T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/acl-ijcnlp2021-outflip</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/acl-ijcnlp2021-outflip">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Out-of-domain (OOD) input detection is vital in a task-oriented dialogue system since the acceptance of unsupported inputs could lead to an incorrect response of the system. This paper proposes OutFlip, a method to generate out-of-domain samples using only in-domain training dataset automatically. A white-box natural language attack method HotFlip is revised to generate out-of-domain samples instead of adversarial examples. Our evaluation results showed that integrating OutFlip-generated out-of-domain samples into the training dataset could significantly improve an intent classification model’s out-of-domain detection performance.&lt;/p&gt;</content><author><name>heuristic:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</title><link href="https://kakaoenterprise.github.io/papers/icml2021-e2e-tts" rel="alternate" type="text/html" title="Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech" /><published>2021-07-18T00:00:00-05:00</published><updated>2021-07-18T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/icml2021-e2e-tts</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/icml2021-e2e-tts">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Several recent end-to-end text-to-speech (TTS) models enabling single-stage training and parallel sampling have been proposed, but their sample quality does not match that of two-stage TTS systems. In this work, we present a parallel end-to-end TTS method that generates more natural sounding audio than current two-stage models. Our method adopts variational inference augmented with normalizing flows and an adversarial training process, which improves the expressive power of generative modeling. We also propose a stochastic duration predictor to synthesize speech with diverse rhythms from input text. With the uncertainty modeling over latent variables and the stochastic duration predictor, our method expresses the natural one-to-many relationship in which a text input can be spoken in multiple ways with different pitches and rhythms. A subjective human evaluation (mean opinion score, or MOS) on the LJ Speech, a single speaker dataset, shows that our method outperforms the best publicly available TTS systems and achieves a MOS comparable to ground truth.&lt;/p&gt;</content><author><name>jay:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision</title><link href="https://kakaoenterprise.github.io/papers/icml2021-vilt" rel="alternate" type="text/html" title="ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision" /><published>2021-07-18T00:00:00-05:00</published><updated>2021-07-18T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/icml2021-vilt</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/icml2021-vilt">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Vision-and-Language Pretraining(VLP) has improved performance on various joint vision-and language downstream tasks. Current approaches to VLP heavily rely on image feature extraction processes, most of which involve region supervision (e.g., object detection) and the convolutional architecture (e.g., ResNet). Although disregarded in the literature, we find it problematic in terms of both (1) efficiency/speed, that simply extracting input features requires much more computation than the multimodal interaction steps; and (2) expressive power, as it is upper bounded to the expressive power of the visual encoder and its predefined visual vocabulary. In this paper, we present a minimal VLP model, Vision-andLanguage Transformer (ViLT), monolithic in the sense that processing of visual inputs is drastically simplified to just the same convolution-free manner that we process textual inputs. We show that ViLT is up to 60 times faster than previous VLP models, yet with competitive or better downstream task performance.&lt;/p&gt;</content><author><name>김원재:카카오</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Multitask Learning and Joint Optimization For Transformer-Rnn-Tranducer Speech Recognition</title><link href="https://kakaoenterprise.github.io/papers/icassp2021-transformer-rnn-tranducer-speech-recognition" rel="alternate" type="text/html" title="Multitask Learning and Joint Optimization For Transformer-Rnn-Tranducer Speech Recognition" /><published>2021-06-13T00:00:00-05:00</published><updated>2021-06-13T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/icassp2021-transformer-rnn-tranducer-speech-recognition</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/icassp2021-transformer-rnn-tranducer-speech-recognition">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Recently, several types of end-to-end speech recognition methods named transformer-transducer were introduced. According to those kinds of methods, transcription networks are generally modeled by transformer-based neural networks, while prediction networks could be modeled by either transformers or recurrent neural networks (RNN). This paper explores multitask learning, joint optimization, and joint decoding methods for transformer-RNN-transducer systems. Our proposed methods have the main advantage in that the model can maintain information on the large text corpus. We prove their effectiveness by performing experiments utilizing the well-known ESPNET toolkit for the widely used Librispeech datasets. We also show that the proposed meth- ods can reduce word error rate (WER) by 16.6 % and 13.3 % for test-clean and test-other datasets, respectively, with- out changing the overall model structure nor exploiting an external LM.&lt;/p&gt;</content><author><name>jeffrey:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">U-Convolution Based Residual Echo Suppression With Multiple Encoders</title><link href="https://kakaoenterprise.github.io/papers/icassp2021-u-convolution-based-residual-eco-suppression" rel="alternate" type="text/html" title="U-Convolution Based Residual Echo Suppression With Multiple Encoders" /><published>2021-06-13T00:00:00-05:00</published><updated>2021-06-13T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/icassp2021-u-convolution-based-residual-eco-suppression</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/icassp2021-u-convolution-based-residual-eco-suppression">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;In this paper, we propose an efficient end-to-end neural network that can estimate near-end speech using a U- convolution block by exploiting various signals to achieve residual echo suppression (RES). Specifically, the proposed model employs multiple encoders and an integration block to utilize complete signal information in an acoustic echo can- cellation system and also applies the U-convolution blocks to separate near-end speech efficiently. The proposed network affords an improvement in the perceptual evaluation of speech quality (PESQ) and the short-time objective intelligi- bility (STOI), as compared to baselines, in scenarios involving smart audio devices. The experimental results show that the proposed method outperforms the baselines for various types of mismatched background noise and environmental reverberation, while requiring low computational resources.&lt;/p&gt;</content><author><name>chris:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">텍스트 스타일을 바꾸는 딥러닝 기술</title><link href="https://kakaoenterprise.github.io/deepdive/210525" rel="alternate" type="text/html" title="텍스트 스타일을 바꾸는 딥러닝 기술" /><published>2021-05-25T00:00:00-05:00</published><updated>2021-05-25T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/deepdive/210525</id><content type="html" xml:base="https://kakaoenterprise.github.io/deepdive/210525">&lt;p&gt;오늘날 많은 기업에서는 챗봇을 이용한 고객 응대 서비스도 제공하고 있습니다. 콜센터를 구축하는 비용보다 훨씬 더 저렴하고, 더 많은 고객을 동시에 응대할 수 있는 효용성을 갖춘 덕분입니다. 그 결과, 고객은 대기자가 많아 상담사 연결까지 한참을 기다리거나 수많은 상품 소개 메뉴를 찾아다닐 수고를 조금은 덜게 됐습니다.&lt;/p&gt;

&lt;p&gt;보통 이런 챗봇은 매뉴얼에 따라 질문을 입력해야만 사용자가 원하는 답을 하도록 구현돼 있습니다. 자신이 가진 문제나 질문을 해결하려는 용도로 챗봇을 이용하는 사용자에게 ‘챗봇과의 교감적 대화’는 별로 중요한 기능이 아니기 때문입니다.&lt;/p&gt;

&lt;p&gt;하지만 과중한 업무에 치이는 상담사의 완벽한 업무 파트너로 발전하기 위해서는 챗봇에 공감적 대화 능력이 요구될 거로 보입니다. 누군가와 대화를 하고 사회적인 관계를 맺는 데 핵심 역할을 하는 ‘감정’을 보여준다면 사용자는 대화할 맛을 느끼게 되겠죠. 앵무새같이 말하는 무심한 챗봇보다는, 내가 처한 상황에 적절한 감정적 반응’도’ 보이는 챗봇에 누구라도 더 큰 호의를 가질 수밖에 없으리라는 판단은 바로 이런 이유 때문입니다.&lt;/p&gt;

&lt;p&gt;감정 교감형 챗봇을 만드는 첫걸음은 &lt;a href=&quot;https://obs.yonsei.ac.kr/ibody/myhome/philosophy/ph03.htm&quot;&gt;처지와 상황이 다른 두 제자의 똑같은 질문에 각기 다른 답을 내어준 공자&lt;/a&gt;처럼&lt;sup&gt;&lt;a href=&quot;#72ac:fn:1&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, 같은 질문이더라도 맥락과 상황, 또는 대화 대상자에 따라 다른 반응을 보이도록 설계하는 데 있습니다. 하지만 현재의 챗봇 시스템은 특정 문장에 항상 같은 반응을 보입니다. 모든 이에게 같은 답변을 내주는 일은 교장님 훈화 말씀처럼 소통이 쌍방향이 아닌 한방향으로만 진행된다면 사용자는 챗봇을 지루하게 느낄 수밖에 없을 겁니다.&lt;/p&gt;

&lt;p&gt;이런 한계를 해결하고자 많은 곳에서는 챗봇의 답변 내용은 유지하되, 사용자의 나이나 인종, 성격 등 다양한 요소로 조합된 그룹을 대표하는 스타일의 문장을 생성하는 기술 개발에 힘쓰고 있습니다. 카카오엔터프라이즈 또한 이 주제에 관한 연구를 진행하고 있으며, 최근에는 INLG&lt;sup&gt;International Natural Language Generation Conference&lt;/sup&gt;에 논문 ‘Stable Style Transformer: Delete and Generate Approach with Encoder-Decoder for Text Style Transfer&lt;a href=&quot;#72ac:rf:1&quot; class=&quot;reference&quot; id=&quot;72ac:rf-back:1&quot;&gt;[1]&lt;/a&gt;’을 내기도 했습니다.&lt;/p&gt;

&lt;p&gt;이번 시간에는 텍스트 스타일 변환에 관한 선행 연구와 카카오엔터프라이즈가 제안한 모델인 SST&lt;sup&gt;Stable Style Transformer&lt;/sup&gt;의 작동 원리와 성능, 그리고 향후 연구 계획에 관한 내용을 상세히 다뤄보고자 합니다. 카카오엔터프라이즈 AI기술실 자연어처리팀 소속의 이주성 연구원을 만나 이야기를 들어봤습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p class=&quot;notice&quot;&gt;※텍스트의 스타일을 변환하는 모델의 성능 평가에는 긍정문을 부정문으로, 또는 부정문을 긍정문으로 바꾸는 벤치마크 데이터셋이 주로 활용됩니다. 이에 따라 본문에서는 명료한 설명을 위해 스타일 속성값을 긍정 또는 부정으로만 바꾸는 태스크를 수행하는 모델로 한정했습니다.
&lt;/p&gt;
&lt;p class=&quot;notice&quot;&gt;※반복적으로 등장하는 “스타일에 해당하는 토큰”, “내용에 해당하는 토큰”은 각각 “‘스타일’ 토큰”, “‘텍스트’ 토큰”으로 보다 간단하게 표현했습니다. 아울러 두 대상을 지칭할 때는 맥락에 따라 토큰 또는 텍스트로 적었습니다.
&lt;/p&gt;
&lt;p class=&quot;notice&quot;&gt;※내용 이해를 돕기 위해 실제 모델 훈련에 쓰이는 영어 문장 대신 한글 문장을 예시로 들었으며, 모든 예문에서는 띄어쓰기를 기준으로 토큰을 나눴다고 가정했습니다.
&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p class=&quot;dot-line&quot;&gt;∙  ∙  ∙  ∙  ∙  ∙  ∙&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;선행연구-소개&quot;&gt;선행연구 소개&lt;/h1&gt;

&lt;p&gt;텍스트 스타일 변환(TST&lt;sup&gt;Text Style Transfer&lt;/sup&gt;)은 입력 문장의 내용&lt;sup&gt;content&lt;/sup&gt;은 보존하고, 스타일&lt;sup&gt;style&lt;/sup&gt;&lt;sup&gt;&lt;a href=&quot;#72ac:fn:2&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:2&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;에 해당하는 텍스트를 바꾸는 태스크입니다. “그 레스토랑은 불친절해”라는 문장에서 내용에 해당하는 부분(‘그 레스토랑은’)은 그대로, 스타일에 해당하는 부분(불친절해)과는 반대되는 의미를 지닌 텍스트(‘친절해’)로 바꾸는 긍·부정 전환이 대표적인 예입니다. 최근에는 여러 스타일 속성을 동시에 변환하는 연구&lt;a href=&quot;#72ac:rf:2&quot; class=&quot;reference&quot; id=&quot;72ac:rf-back:2&quot;&gt;[2]&lt;/a&gt;도 활발하게 진행되고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-05-25-210525/001.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ 표 1 ] 텍스트 스타일 변환 예시 문장. (슬픔), (기쁨), (화남), (크리스마스)처럼 텍스트로 표현하는 이모지도 전환할 수 있다. (출처 : &lt;a href=&quot;#72ac:rf:2&quot; class=&quot;reference&quot; id=&quot;72ac:rf-back:2&quot;&gt;[2]&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;딥러닝 모델에 TST 태스크를 가르치기 위해서는 “그 음식 맛없어(부정)”와 “그 음식 맛있어(긍정)”처럼 한 속성에 대한 상반된 값이 쌍으로 존재하는 병렬 말뭉치&lt;sup&gt;parallel corpus&lt;/sup&gt;를 이용한 감독학습&lt;sup&gt;supervised learning&lt;/sup&gt;을 고려해볼 수 있습니다. 하지만 이런 형태의 병렬 말뭉치 구축에는 시간과 비용이 많이 들죠. 이에 많은 연구에서는 긍정 문장 또는 부정 문장으로만 구성된 단일 말뭉치를 이용한 비감독학습&lt;sup&gt;unsupervised learning&lt;/sup&gt;을 시도합니다.&lt;/p&gt;

&lt;p&gt;초기 연구에서는 적대적 학습&lt;sup&gt;adversarial learning&lt;/sup&gt;&lt;sup&gt;&lt;a href=&quot;#72ac:fn:3&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:3&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;을 통한 해석 가능한 표현&lt;sup&gt;disentangled latent representation&lt;/sup&gt;을 생성하는 데 집중했습니다&lt;a href=&quot;#72ac:rf:3&quot; class=&quot;reference&quot; id=&quot;72ac:rf-back:3&quot;&gt;[3]&lt;/a&gt;. 과정은 다음과 같습니다. 입력 문장이 긍정인지 부정인지를 구분하지 못할 때까지 학습을 반복하면, 생성 모델의 인코더&lt;sup&gt;encoder&lt;/sup&gt;가 입력 문장에서 ‘스타일’ 토큰을 제외한 나머지를 보고 ‘내용’ 벡터를 효과적으로 표현하리라 가정했습니다([그림1]). 그러고 나면, 이 벡터와 타깃 스타일 속성값을 디코더&lt;sup&gt;decoder&lt;/sup&gt;에 입력하면 사용자가 원하는 스타일의 문장이 생성할 수 있다고 본 거죠. 하지만 실제 실험에서는 적대적 학습을 통해 입력 문장에서 ‘내용’ 벡터만을 분리하기가 쉽지 않았습니다&lt;a href=&quot;#72ac:rf:4&quot; class=&quot;reference&quot; id=&quot;72ac:rf-back:4&quot;&gt;[4]&lt;/a&gt;. 또한, 다양한 길이의 문장을 항상 같은 크기의 벡터로 변환하는 데에도 한계가 있음이 발견됐습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-05-25-210525/002.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ 그림 1 ] 적대적 학습으로 TST 모델을 훈련하는 과정&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이처럼 입력 문장을 보고 ‘내용’ 토큰만을 벡터로 표현하는 대신, ‘스타일’ 토큰을 아예 삭제하는 방법론&lt;a href=&quot;#72ac:rf:5&quot; class=&quot;reference&quot; id=&quot;72ac:rf-back:5&quot;&gt;[5]&lt;/a&gt;이 제안됐습니다. 이를 위해 ‘스타일’ 토큰을 삭제하는 모듈과 나머지 문장 요소(내용)만을 가지고 타깃 스타일 속성값에 해당하는 문장을 생성하는 모듈을 각기 따로 둡니다. 이 방식은 앞서 설명한 방식보다 ‘내용’ 토큰을 더 잘 보존하고, ‘스타일’ 토큰은 더 효과적으로 바꿨습니다. 그러나 문장을 구성하는 모든 텍스트가 상호 작용하는 그 특성상, ‘스타일’ 토큰을 효과적으로 삭제하는 데 한계가 있었습니다&lt;a href=&quot;#72ac:rf:6&quot; class=&quot;reference&quot; id=&quot;72ac:rf-back:6&quot;&gt;[6]&lt;/a&gt;. 이에 ‘스타일’ 토큰을 임의로 삭제하지 않고도 스타일을 변환하는 E2E&lt;sup&gt;end-to-end&lt;/sup&gt; 방식이 제안되기도 했습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;sst가-문제를-해결한-방식&quot;&gt;SST가 문제를 해결한 방식&lt;/h1&gt;

&lt;p&gt;카카오엔터프라이즈는 입력 문장에서 ‘스타일’ 토큰을 명시적으로 삭제하고, ‘내용 토큰과 타깃 스타일 속성값만을 가지고 문장 벡터를 생성하는 접근 방식에서 영감을 얻었습니다. 카카오엔터프라이즈가 고안한 SST 모델 또한 1)문장에서 ‘스타일’ 토큰을 삭제한 뒤, 2)’콘텐츠’ 토큰만을 가지고 입력 문장과는 반대되는 스타일 속성값을 가진 문장을 생성합니다. 다만 기존과는 다른 방식으로 각 모듈을 구현했는데, 이는 각 단락에서 이어 하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-05-25-210525/003.png&quot; width=&quot;80%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ 그림 2 ] 문장의 스타일 속성값을 긍정에서 부정, 또는 부정에서 긍정으로 전환해 문장을 생성하는 STT 모델의 동작 과정&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-스타일-삭제-프로세스&quot;&gt;(1) 스타일 삭제 프로세스&lt;/h2&gt;

&lt;p&gt;카카오엔터프라이즈가 제안한 스타일 삭제기의 동작 방식을 설명하는 데 앞서, 기존에 제안한 방식의 동작 원리와 그 한계에 대해 먼저 간단하게 짚어보겠습니다.&lt;/p&gt;

&lt;p&gt;빈도비&lt;sup&gt;frequency-ratio&lt;/sup&gt;를 활용한 방식은 삭제기에 입력된 문장의 토큰 중, 사전&lt;sup&gt;&lt;a href=&quot;#72ac:fn:4&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:4&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;에 등록된 토큰과 일치한다면 이를 ‘스타일’ 토큰으로 판단해 삭제합니다. 이 방식의 한계는 사전에 등록되지 않은 ‘스타일’ 토큰을 인식하지 못할 가능성이 매우 크다는 데 있습니다. 그렇다고 해서 이 세상에 존재하는 ‘스타일’ 토큰을 모조리 찾아 등록할 수도 없습니다. 규칙 기반으로 동작하는 그 특성상 맥락을 파악해야 어느 부분이 ‘스타일’ 토큰인지 알 수 있는 문장&lt;sup&gt;&lt;a href=&quot;#72ac:fn:5&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:5&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;에서는 잘 동작하지 않을 가능성도 높습니다.&lt;/p&gt;

&lt;p&gt;이런 한계를 극복하고자 어텐션attention&lt;sup&gt;&lt;a href=&quot;#72ac:fn:6&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:6&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;을 활용해 스타일 토큰을 삭제하는 방식&lt;a href=&quot;#72ac:rf:7&quot; class=&quot;reference&quot; id=&quot;72ac:rf-back:7&quot;&gt;[7]&lt;/a&gt;이 고안됐습니다. 과정은 다음과 같습니다. 먼저, BERT에 문장을 입력해 [CLS&lt;sup&gt;Special Classification token&lt;/sup&gt;]&lt;sup&gt;&lt;a href=&quot;#72ac:fn:7&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:7&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;에 해당하는 벡터를 얻습니다. 그다음, 입력 문장의 각 토큰이 CLS 디코딩에 영향을 미친 정도(어텐션)를 점수로 환산합니다. 가장 높은 점수를 낸 토큰을 문장을 긍·부정으로 분류하는 데 영향을 미친 ‘스타일’ 토큰이라고 판단하고, 이를 삭제합니다.&lt;/p&gt;

&lt;p&gt;하지만 어텐션 점수를 사용하는 방식도 문장 전체의 의미를 파악하는 데 한계가 있습니다. “음식이 맛있다고 하는데 나는 그닥(부정)”이라는 문장을 한 번 보겠습니다. 이 문장은 부정의 의미를 담은 주절(나는 그닥)과 긍정의 의미를 담은 종속절(음식이 맛있다)로 이뤄져 있습니다. 모델은 핵심 내용을 담고 있는 주절에 집중해서 스타일 속성값을 파악해야 합니다. 하지만 어텐션 기반 모델은 ‘맛있다’와 [CLS]와의 관계, ‘그닥’과 [CLS]와의 관계를 각각 독립적으로 파악하고서는 ‘맛있다’에 더 많은 어텐션 값을 배정, 이 문장을 ‘긍정’으로 오 분류할 가능성이 높습니다.&lt;/p&gt;

&lt;p&gt;더불어 위 방식에서는 CLS 벡터를 출력하는 BERT 계열의 모델만을 분류기로 사용할 수 있다는 제약이 따릅니다.&lt;/p&gt;

&lt;p&gt;이에 카카오엔터프라이즈는 ‘스타일’ 토큰을 직관적으로 구분하면서도 특정 모델의 구조에 구애받지 않는&lt;sup&gt;model-agnostic&lt;/sup&gt; 삭제 프로세스를 제안했습니다. 문장을 구성하는 각 토큰을 차례대로 누락한 토큰 시퀀스를 분류기&lt;sup&gt;pre-trained classifier&lt;/sup&gt;&lt;sup&gt;&lt;a href=&quot;#72ac:fn:8&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:8&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;에 입력한 후, 확률값 변화에 큰 영향을 미친 토큰을 ‘스타일’로 인식하고 이를 삭제&lt;sup&gt;&lt;a href=&quot;#72ac:fn:9&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:9&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;합니다. 예를 들어 좀 더 쉽게 설명해보겠습니다.&lt;/p&gt;

&lt;p&gt;앞에서 언급한 예시 문장 x(음식이 맛있다고 하는데 나는 그닥)를 다시 보겠습니다([그림 3]). 문장을 구성하는 토큰을 순차적으로 누락한 문장을 분류기에 입력합니다. 그다음, 본래 문장 x를 입력해서 얻은 값과의 차이를 계산(IS)합니다. 여기서는 확률값 변화에 많은 영향을 미친 토큰은 ‘그닥’입니다. 따라서 삭제기는 이 토큰을 스타일로 인식하고 이를 삭제한 문장인 x’(음식이 맛있다고 하는데 나는)를 출력합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-05-25-210525/004.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ 그림 3 ] 입력 문장에서 ‘스타일’ 텍스트를 삭제하는 과정&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-스타일-전환-문장-생성-프로세스&quot;&gt;(2) 스타일 전환 문장 생성 프로세스&lt;/h2&gt;

&lt;p&gt;생성기는 RNN 기반의 모델보다 더 좋은 성능을 내는 Transformer의 인코더와 디코더로 구현했습니다. ’스타일’ 토큰을 삭제한 문장 x’ 앞에는 문장의 시작을 알려주는 [start]와 스타일 속성을 표현하는 [style]&lt;sup&gt;&lt;a href=&quot;#72ac:fn:10&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:10&quot;&gt;10&lt;/a&gt;&lt;/sup&gt; 두 스페셜 토큰&lt;sup&gt;special token&lt;/sup&gt;이 붙습니다. 생성기는 문장의 끝을 알리는 [end]가 출력될 때까지 동작합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-05-25-210525/005.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ 그림 4 ] ‘스타일’ 토큰을 삭제한 문장과 타깃 스타일 속성값을 이용해 원하는 스타일의 문장을 만드는 생성기의 작동 과정&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-모델-훈련&quot;&gt;(3) 모델 훈련&lt;/h2&gt;

&lt;p&gt;SST 또한 선행 연구에서와 마찬가지로 긍정 또는 부정의 말뭉치로 각각 구성된 비병렬 데이터셋만을 이용해야 합니다. 다시 말해, “그 레스토랑은 맛없어(부정)”라는 문장만 주어지고, 반대 속성의 문장인 “그 레스토랑은 맛있어(긍정)”가 없어서 감독학습을 불가능한 상황입니다.&lt;/p&gt;

&lt;p&gt;이에 카카오엔터프라이즈는 가장 확실하게 알고 있는 유일한 정보가 입력 문장의 스타일 속성값(부정)이라는 점을 고려해, 스타일 속성과 관련된 두 손실 함수를 정의하고 두 함수를 최소화하는 방향으로 생성기의 인코더와 디코더를 훈련&lt;sup&gt;&lt;a href=&quot;#72ac:fn:11&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:11&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;했습니다. 두 손실 함수를 이용해 학습을 마친 모델은 ‘콘텐츠’ 토큰을 활용해 타깃 스타일 속성값으로 전환된 문장을 생성할 수 있게 됩니다.&lt;/p&gt;

&lt;p&gt;우선, ‘스타일’ 토큰을 삭제한 문장(“그 레스토랑은”)과 입력 문장의 스타일 속성값(부정)을 입력받은 디코더가 본래 스타일로 분류될 수 있도록 하는 학습을 진행합니다. 여기에서는 크로스 엔트로피&lt;sup&gt;Cross Entropy&lt;/sup&gt;를 이용한 재구성 손실 함수&lt;sup&gt;reconstruction loss function&lt;/sup&gt;을 사용했습니다. 학습을 마치고 나면 디코더는 원래 주어진 스타일 속성값인 ‘부정’으로 분류되는 문장을 생성합니다.&lt;/p&gt;

&lt;p&gt;하지만 재구성 손실 함수만으로는 디코더가 스타일 속성값을 반전하는 데에는 한계가 있습니다. 모델이 입력 문장을 다시 복구하는 법만 익혔기 때문입니다. 원래 스타일 속성값과 반대되는 문장(긍정)을 생성하는 학습도 중요합니다. ‘콘텐츠’ 토큰(“그 레스토랑은”)과 원래 주어진 스타일 속성의 반대되는 값인 ‘긍정’으로 분류될 수 있도록 모델을 훈련합니다. 여기에는 스타일 손실 함수&lt;sup&gt;style loss function&lt;/sup&gt;을 이용했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-05-25-210525/006.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ 그림 5 ] STT 모델에서 두 손실 함수를 이용한 훈련 과정&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;성능-평가-및-결과&quot;&gt;성능 평가 및 결과&lt;/h1&gt;

&lt;p&gt;카카오엔터프라이즈는 음식점 리뷰를 모아 놓은 옐프(Yelp)와 상품 리뷰를 모아놓은 아마존(Amazon), 두 벤치마크 데이터셋&lt;a href=&quot;#72ac:rf:5&quot; class=&quot;reference&quot; id=&quot;72ac:rf-back:5&quot;&gt;[5]&lt;/a&gt;을 이용해 최신의 TTS 모델의 성능을 비교했습니다. ‘콘텐츠’ 토큰을 얼마나 잘 보존했는지(content), 스타일이 제대로 전환됐는지(style), 말이 자연스러운지(fluency), 그리고 두 문장(출력 문장, 정답 문장)의 의미가 얼마나 유사한지(semantic)를 판단하는 총 4가지의 평가 항목을 마련했습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;tr class=&quot;key&quot;&gt;
    &lt;td&gt;입력 문장&lt;/td&gt;
    &lt;td&gt;출력 문장&lt;/td&gt;
    &lt;td&gt;평가&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;“&lt;span style=&quot;background-color:#fff2cc;&quot;&gt;그 음식은&lt;/span&gt; &lt;span style=&quot;background-color:#d9ead3;&quot;&gt;맛없어&lt;/span&gt;”&lt;/td&gt;
    &lt;td&gt;“&lt;span style=&quot;background-color:#fff2cc;&quot;&gt;그 음식은&lt;/span&gt; &lt;span style=&quot;background-color:#d9ead3;&quot;&gt;별로야&lt;/span&gt;”&lt;/td&gt;
    &lt;td&gt;content는 보존, style은 못바꿈,&lt;br /&gt;fluency는 자연스러움&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;“&lt;span style=&quot;background-color:#fff2cc;&quot;&gt;서비스가&lt;/span&gt; &lt;span style=&quot;background-color:#d9ead3;&quot;&gt;별로고&lt;/span&gt; &lt;span style=&quot;background-color:#fff2cc;&quot;&gt;가격이&lt;/span&gt; &lt;span style=&quot;background-color:#d9ead3;&quot;&gt;매우 비싸&lt;/span&gt;”&lt;/td&gt;
    &lt;td&gt;“&lt;span style=&quot;background-color:#fff2cc;&quot;&gt;서비스가&lt;/span&gt; &lt;span style=&quot;background-color:#d9ead3;&quot;&gt;매우 좋았고&lt;/span&gt; &lt;span style=&quot;background-color:#fff2cc;&quot;&gt;가격이&lt;/span&gt; &lt;span style=&quot;background-color:#d9ead3;&quot;&gt;매우 비싸&lt;/span&gt;”&lt;/td&gt;
    &lt;td&gt;content는 보존, style은 애매함,&lt;br /&gt;fluency는 약간 이상함&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;“&lt;span style=&quot;background-color:#fff2cc;&quot;&gt;그것의 퀄리티는&lt;/span&gt; &lt;span style=&quot;background-color:#d9ead3;&quot;&gt;꽤 괜찮아 보이는데&lt;/span&gt; ”&lt;/td&gt;
    &lt;td&gt;“&lt;span style=&quot;background-color:#fff2cc;&quot;&gt;그 게임은&lt;/span&gt; &lt;span style=&quot;background-color:#d9ead3;&quot;&gt;재미없어 보이는데&lt;/span&gt;”&lt;/td&gt;
    &lt;td&gt;content는 미보존, style은 바꿈,&lt;br /&gt;fluency는 자연스러움&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;“&lt;span style=&quot;background-color:#fff2cc;&quot;&gt;그것의 퀄리티는&lt;/span&gt; &lt;span style=&quot;background-color:#d9ead3;&quot;&gt;꽤 괜찮아 보이는데&lt;/span&gt;”&lt;/td&gt;
    &lt;td&gt;“&lt;span style=&quot;background-color:#fff2cc;&quot;&gt;그 나무는&lt;/span&gt; &lt;span style=&quot;background-color:#d9ead3;&quot;&gt;맛없던데&lt;/span&gt;”&lt;/td&gt;
    &lt;td&gt;content는 미보존, style은 바꿈,&lt;br /&gt;fluency는 이상함&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ 표 2 ] TST 모델의 평가 결과 예시&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;각 항목 평가를 위해 총 8가지 자동화 평가 척도&lt;sup&gt;automatic evaluation metrics&lt;/sup&gt;([표 3])를 활용했습니다. 인간 평가&lt;sup&gt;human evaluation&lt;/sup&gt;가 더 정확하나, 시간과 비용이 많이 소모됩니다. 이에 카카오엔터프라이즈는 더 저렴하면서도 빠른 자동화 평가 척도를 가지고 안정적인 텍스트 스타일 변환 여부를 판단하고자 했습니다. 자동화 평가에서 상대적으로 좋지 않은 성능을 낸 모델이 인간에게도 좋은 평가를 받지 못한 실험적 결과가 이 선택을 뒷받침합니다.&lt;/p&gt;

&lt;table&gt;
  &lt;tr&gt;
    &lt;td class=&quot;key&quot; rowspan=&quot;3&quot;&gt;Content&lt;/td&gt;
    &lt;td&gt;self-BLEU&lt;/td&gt;
    &lt;td class=&quot;left&quot;&gt;입력 문장과 (시스템이) 생성 문장 간의 n-gram&lt;sup&gt;&lt;a href=&quot;#72ac:fn:12&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:12&quot;&gt;12&lt;/a&gt;&lt;/sup&gt; 중첩 정도를 이용한 평가&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;human-BLEU&lt;/td&gt;
    &lt;td class=&quot;left&quot;&gt;인간이 생성한 문장과 시스템이 생성한 문장 간의 n-gram 중첩도를 이용한 평가&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;geometric mean-BLEU&lt;/td&gt;
    &lt;td class=&quot;left&quot;&gt;self-BLEU와 human-BLEU의 기하평균&lt;sup&gt;geometric mean&lt;/sup&gt;&lt;sup&gt;&lt;a href=&quot;#72ac:fn:13&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:13&quot;&gt;13&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&quot;key&quot;&gt;Style&lt;/td&gt;
    &lt;td&gt;classification accuracy&lt;/td&gt;
    &lt;td class=&quot;left&quot;&gt;기학습된 분류기로 평가한 성능&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&quot;key&quot; rowspan=&quot;3&quot;&gt;Fluency&lt;/td&gt;
    &lt;td&gt;d-PPL&lt;sup&gt;perplexity&lt;/sup&gt;&lt;sup&gt;&lt;a href=&quot;#72ac:fn:14&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:14&quot;&gt;14&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
    &lt;td class=&quot;left&quot;&gt;평가 데이터셋에서 미세조정한 언어 모델을 이용한 지표&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;g-PPL&lt;/td&gt;
    &lt;td class=&quot;left&quot;&gt;사전학습된 언어 모델인 GPT를 이용한 지표&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;t-PPL&lt;/td&gt;
    &lt;td class=&quot;left&quot;&gt;d-PPL과 g-PPL의 기하평균&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&quot;key&quot;&gt;Semantic&lt;/td&gt;
    &lt;td&gt;BERTScore&lt;sup&gt;&lt;a href=&quot;#72ac:fn:15&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:15&quot;&gt;15&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
    &lt;td class=&quot;left&quot;&gt;사전학습된 BERT를 이용한 평가&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ 표 3 ] 성능 평가에 활용한 8가지 자동화 평가 척도&lt;sup&gt;&lt;a href=&quot;#72ac:fn:16&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:16&quot;&gt;16&lt;/a&gt;&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈는 8가지 자동화된 평가 척도를 이용해 여러 TST 모델의 성능을 비교했습니다([표 4], [표 5]). 핵심은 다른 모델에 표시된 빨간색 숫자입니다. 이 숫자는 다른 모델과 비교해 해당 평가 척도에서 현저히 낮은 성능을 의미합니다. 아주 단적인 예로, 문장은 이진 분류&lt;sup&gt;binary classification&lt;/sup&gt;이기 때문에 확률상 최소 50%의 성능은 나와야 합니다. 하지만 실제로는 이에 훨씬 못 미치는 성능을 내고 있죠. 이런 점에서 카카오엔터프라이즈가 고안한 STT 모델이 모든 평가 척도에서 두루 안정적인 결과를 냈다는 점에 주목할 만합니다.&lt;/p&gt;

&lt;p&gt;물론 이런 안정성 판별은 상대적인 척도라서 완벽하다고 할 수는 없습니다. 특정 척도만을 이용한 평가로 어느 시스템의 절대적인 우수성을 말할 수 없을 뿐만 아니라, 자동화 평가에서 좋은 성능을 시스템을 선별해 인간 평가를 진행한다고 하더라도 좋은 결과를 기대할 수 없기 때문입니다. 향후 모델의 성능을 다각도로 측정할 수 있는 평가 척도가 나온다면, 여러 환경에 더 적합한 시스템 개발 및 평가가 한결 더 수월해질 거로 보입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-05-25-210525/007.png&quot; width=&quot;90%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ 표 4 ] 옐프 데이터셋에서의 성능 평가 실험&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-05-25-210525/008.png&quot; width=&quot;90%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ 표 5 ] 아마존 데이터셋에서의 성능 평가 실험&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;한편, 카카오엔터프라이즈는 ‘스타일’ 벡터를 부정에서 긍정 또는 긍정에서 부정으로 조금씩 바꾸면서 생성되는 문장을 확인하는 잠재 공간 탐색&lt;sup&gt;latent space walking&lt;/sup&gt;에 관한 실험도 진행했습니다. 텍스트 스타일 변환 모델이 문장의 스타일 속성값을 긍정과 부정을 전환할 수 있다면, 그 중간에 중립&lt;sup&gt;neutral&lt;/sup&gt; 문장도 생성되리라는 가정을 증명하려는 목적이었습니다. 하지만 아쉽게도 중립 문장이 생성됨을 확인하지는 못했습니다. 이런 측면을 고려해 모델링을 한다면 문장 스타일을 좀 더 세밀하게 조절할 수 있을 거로 보입니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;향후-계획&quot;&gt;향후 계획&lt;/h1&gt;

&lt;p&gt;카카오엔터프라이즈는 이후 텍스트 스타일 변환뿐만 아니라 사람의 감정이나 대화 상황을 이해하는 공감적 대화&lt;sup&gt;empathetic conversation&lt;/sup&gt;, 데이터를 문장으로 표현하기&lt;sup&gt;data-to-text&lt;/sup&gt;, 페르소나 채팅&lt;sup&gt;persona chat&lt;/sup&gt;&lt;sup&gt;&lt;a href=&quot;#72ac:fn:17&quot; class=&quot;footnote&quot; id=&quot;72ac:fn-back:17&quot;&gt;17&lt;/a&gt;&lt;/sup&gt;처럼 원하는 조건에 따라 문장을 생성하는 자연어 생성에 관한 다양한 연구를 계속해서 진행할 계획입니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;참고-문헌&quot;&gt;참고 문헌&lt;/h1&gt;

&lt;p&gt;&lt;a id=&quot;72ac:rf:1&quot; class=&quot;referencebody&quot;&gt;&lt;a href=&quot;#72ac:rf-back:1&quot; class=&quot;backlink&quot;&gt;[1]&lt;/a&gt;  &lt;a href=&quot;https://www.aclweb.org/anthology/2020.inlg-1.25.pdf&quot;&gt;Stable Style Transformer: Delete and Generate Approach with Encoder-Decoder for Text Style Transfer&lt;/a&gt; (2020) by Joosung Lee in INLG&lt;/a&gt;&lt;br /&gt;
&lt;a id=&quot;72ac:rf:2&quot; class=&quot;referencebody&quot;&gt;&lt;a href=&quot;#72ac:rf-back:2&quot; class=&quot;backlink&quot;&gt;[2]&lt;/a&gt;  &lt;a href=&quot;https://research.fb.com/publications/multiple-attribute-text-rewriting/&quot;&gt;Multiple-Attribute Text Style Transfer&lt;/a&gt; (2019) Guillaume Lample, Sandeep Subramanian, Eric Michael Smith, Ludovic Denoyer, Marc’Aurelio Ranzato, Y-Lan Boureau in ICLR&lt;/a&gt;&lt;br /&gt;
&lt;a id=&quot;72ac:rf:3&quot; class=&quot;referencebody&quot;&gt;&lt;a href=&quot;#72ac:rf-back:3&quot; class=&quot;backlink&quot;&gt;[3]&lt;/a&gt;  &lt;a href=&quot;https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/17015/15745&quot;&gt;Style Transfer in Text: Exploration and Evaluation&lt;/a&gt; (2018) by Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan Zhao, Rui Yan in AAAI&lt;/a&gt;&lt;br /&gt;
&lt;a id=&quot;72ac:rf:4&quot; class=&quot;referencebody&quot;&gt;&lt;a href=&quot;#72ac:rf-back:4&quot; class=&quot;backlink&quot;&gt;[4]&lt;/a&gt;  &lt;a href=&quot;https://arxiv.org/abs/1811.00552&quot;&gt;Multiple-attribute text rewriting&lt;/a&gt; (2019) by Sandeep Subramanian, Guillaume Lample, Eric Michael Smith, Ludovic Denoyer, Marc’Aurelio Ranzato, Y-Lan Boureau in ICLR&lt;/a&gt;&lt;br /&gt;
&lt;a id=&quot;72ac:rf:5&quot; class=&quot;referencebody&quot;&gt;&lt;a href=&quot;#72ac:rf-back:5&quot; class=&quot;backlink&quot;&gt;[5]&lt;/a&gt;  &lt;a href=&quot;https://www.aclweb.org/anthology/N18-1169.pdf&quot;&gt;Delete, Retrieve, Generate: A Simple Approach to Sentiment and Style Transfer&lt;/a&gt; (2018) by Juncen Li, Robin Jia, He He, Percy Liang in NAACL&lt;/a&gt;&lt;br /&gt;
&lt;a id=&quot;72ac:rf:6&quot; class=&quot;referencebody&quot;&gt;&lt;a href=&quot;#72ac:rf-back:6&quot; class=&quot;backlink&quot;&gt;[6]&lt;/a&gt;  &lt;a href=&quot;https://www.ijcai.org/Proceedings/2019/0711.pdf&quot;&gt;A Dual Reinforcement Learning Framework for Unsupervised Text Style Transfer&lt;/a&gt; (2019) by Fuli Luo, Peng Li, Jie Zhou, Pengcheng Yang, Baobao Chang, Xu Sun, Zhifang Sui in IJCAI&lt;/a&gt;&lt;br /&gt;
&lt;a id=&quot;72ac:rf:7&quot; class=&quot;referencebody&quot;&gt;&lt;a href=&quot;#72ac:rf-back:7&quot; class=&quot;backlink&quot;&gt;[7]&lt;/a&gt;  &lt;a href=&quot;https://arxiv.org/pdf/1908.09368.pdf&quot;&gt;Transforming Delete, Retrieve, Generate Approach for Controlled Text Style Transfer&lt;/a&gt; (2019) by Akhilesh Sudhakar, Bhargav Upadhyay, Arjun Maheswaran in EMNLP&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;각주&quot;&gt;각주&lt;/h1&gt;

&lt;ol class=&quot;footnotelist&quot;&gt;
&lt;li id=&quot;72ac:fn:1&quot; class=&quot;footnotebody&quot; value=&quot;1&quot;&gt;&lt;p&gt;  논어 ‘선진' 편을 보면, 제자 자로와 유의 똑같은 질문에 공자는 서로 다른 답변을 준다. 이에 또 다른 제자 공서화가 이를 보고 왜 그런지 묻자, 공자는 유에게는 성정을 억누를 신중함을 심어주고, 자로에게는 결단력을 북돋아 줄 필요가 있다고 답했다.&lt;a href=&quot;#72ac:fn-back:1&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:2&quot; class=&quot;footnotebody&quot; value=&quot;2&quot;&gt;&lt;p&gt; 성별, 감정, 나이(세대), 인종 등 화자에 따라 달라지는 발화의 스타일을 의미한다.&lt;a href=&quot;#72ac:fn-back:2&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:3&quot; class=&quot;footnotebody&quot; value=&quot;3&quot;&gt;&lt;p&gt; 새로운 데이터를 생성하는 생성자&lt;sup&gt;generator&lt;/sup&gt;와 이 데이터를 평가하는 구별자&lt;sup&gt;discriminator&lt;/sup&gt;가 서로 대립하며 각각의 성능을 높이는 목적을 달성하는 경쟁 끝에 진짜와 같은 가상의 새로운 데이터를 만들어낸다. 적대적 학습은 바로 이 두 주체가 충돌해서 발전이 이뤄지는 &lt;a href=&quot;https://khshim.wordpress.com/2016/09/24/generative-adversarial-networks-1/&quot;&gt;대립쌍 프로세스&lt;/a&gt;&lt;sup&gt;adversarial process&lt;/sup&gt;라는 점에 기인했다.&lt;a href=&quot;#72ac:fn-back:3&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:4&quot; class=&quot;footnotebody&quot; value=&quot;4&quot;&gt;&lt;p&gt; 긍∙부정 레이블을 단 데이터셋에 자주 등장하는 스타일 토큰을 모아둔 데이터베이스&lt;a href=&quot;#72ac:fn-back:4&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:5&quot; class=&quot;footnotebody&quot; value=&quot;5&quot;&gt;&lt;p&gt; “이렇게 만들면 잘도 맛있겠네요&quot; 문장이라면, ‘맛있겠네요'에만 집중했을 때 이 문장을 자칫 긍정(맛있다)으로 인식할 수 있다. 하지만 전체 맥락을 살펴보면, ‘맛없다'를 반어적으로 표현한 문장임을 알 수 있다.&lt;a href=&quot;#72ac:fn-back:5&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:6&quot; class=&quot;footnotebody&quot; value=&quot;6&quot;&gt;&lt;p&gt; 특정 시퀀스를 디코딩할 때 관련된 인코딩 결과를 참조하게 만드는 기법&lt;a href=&quot;#72ac:fn-back:6&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:7&quot; class=&quot;footnotebody&quot; value=&quot;7&quot;&gt;&lt;p&gt; Special Classification Token의 약자로, 입력 문장을 구성하는 모든 토큰의 의미를 응축하고 있다.&lt;a href=&quot;#72ac:fn-back:7&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:8&quot; class=&quot;footnotebody&quot; value=&quot;8&quot;&gt;&lt;p&gt; STT 모델 훈련에 쓰인 같은 데이터로 미리 훈련해준다.&lt;a href=&quot;#72ac:fn-back:8&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:9&quot; class=&quot;footnotebody&quot; value=&quot;9&quot;&gt;&lt;p&gt; 삭제 프로세스는 1)부정 확률이 적정 수준으로 떨어지거나, 2)전체 문장에서 일정 비율의 토큰이 삭제됐을 때 종결된다.&lt;a href=&quot;#72ac:fn-back:9&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:10&quot; class=&quot;footnotebody&quot; value=&quot;10&quot;&gt;&lt;p&gt; 학습 단계에서 어떤 손실 함수를 이용하느냐에 따라 [style]은 입력 문장의 속성값 또는 타깃 스타일 속성값 둘 다 될 수 있다. 모델 훈련 과정에서 이를 상세히 설명해두었다. 반면, 테스트 단계에서는 스타일 속성을 얼마나 잘 바꾸는지를 평가해야 하므로 타깃 스타일 속성값을 나타낸다.&lt;a href=&quot;#72ac:fn-back:10&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:11&quot; class=&quot;footnotebody&quot; value=&quot;11&quot;&gt;&lt;p&gt; 두 손실 함수를 합쳐서 학습을 진행해도 성능 면에서 큰 차이가 없다. 다만 카카오엔터프라이즈는 본 연구를 진행할 때 두 손실 함수를 번갈아가며 모델을 훈련했으며, 학습률을 서로 다르게 설정해 재구성손실 함수가 모델의 가중치를 더 많이 업데이트할 수 있도록 했다.&lt;a href=&quot;#72ac:fn-back:11&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:12&quot; class=&quot;footnotebody&quot; value=&quot;12&quot;&gt;&lt;p&gt; 어떤 한 입력을 처리할 때 함께 볼 N개의 입력 단위(토큰)를 뜻한다.&lt;a href=&quot;#72ac:fn-back:12&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:13&quot; class=&quot;footnotebody&quot; value=&quot;13&quot;&gt;&lt;p&gt; n개의 요소를 곱한 후 그 값에 n 제곱근을 씌운 값&lt;a href=&quot;#72ac:fn-back:13&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:14&quot; class=&quot;footnotebody&quot; value=&quot;14&quot;&gt;&lt;p&gt; 언어 모델의 성능을 정량적으로 평가하기 위한 지표를 의미한다.&lt;a href=&quot;#72ac:fn-back:14&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:15&quot; class=&quot;footnotebody&quot; value=&quot;15&quot;&gt;&lt;p&gt; 성능 격차가 크지 않아 안 좋은 시스템이 무엇인지 고르기 애매하다. 이에 이 부분은 시스템을 가우시안 분포로 가정하고 신뢰도 95% 이내에 포함되지 않는 점수를 가지는 시스템을 불안정한 시스템으로 결정했다.&lt;a href=&quot;#72ac:fn-back:15&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:16&quot; class=&quot;footnotebody&quot; value=&quot;16&quot;&gt;&lt;p&gt; PPL을 제외한 나머지 척도에서는 숫자가 클수록 모델의 성능이 좋다고 할 수 있다.&lt;a href=&quot;#72ac:fn-back:16&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;72ac:fn:17&quot; class=&quot;footnotebody&quot; value=&quot;17&quot;&gt;&lt;p&gt; 시스템 설계자가 미리 정의한 고유 페르소나(인격)를 가진 가상의 상대와 대화를 나누는 태스크를 가리킨다. 여기서 페르소나는 4~6문장으로 표현된다. 이를테면, 대화 중에 페르소나(예: 나는 딸기를 좋아합니다)와 관련된 주제가 언급되면(“넌 무슨 케이크를 좋아해?”), 모델은 관련 내용으로 응답한다(“나는 딸기 케이크를 좋아해.”).&lt;a href=&quot;#72ac:fn-back:17&quot; class=&quot;backlink&quot;&gt; ↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;/ol&gt;</content><author><name>samantha:작성,편집</name></author><category term="deepdive" /><category term="Text Style Transfer" /><summary type="html">오늘날 많은 기업에서는 챗봇을 이용한 고객 응대 서비스도 제공하고 있습니다. 콜센터를 구축하는 비용보다 훨씬 더 저렴하고, 더 많은 고객을 동시에 응대할 수 있는 효용성을 갖춘 덕분입니다. 그 결과, 고객은 대기자가 많아 상담사 연결까지 한참을 기다리거나 수많은 상품 소개 메뉴를 찾아다닐 수고를 조금은 덜게 됐습니다.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://kakaoenterprise.github.io/assets/img/2021-05-25-210525/000.png" /><media:content medium="image" url="https://kakaoenterprise.github.io/assets/img/2021-05-25-210525/000.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Suppressing Spoof-irrelevant Factors for Domain-agnostic Face Anti-spoofing</title><link href="https://kakaoenterprise.github.io/papers/ieeeaccess2021-dasn" rel="alternate" type="text/html" title="Suppressing Spoof-irrelevant Factors for Domain-agnostic Face Anti-spoofing" /><published>2021-04-30T00:00:00-05:00</published><updated>2021-04-30T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/ieeeaccess2021-dasn</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/ieeeaccess2021-dasn">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Face anti-spoofing aims to prevent false authentications of face recognition systems by distinguishing whether an image is originated from a human face or a spoof medium. In this work, we note that images from unseen domains having different spoof-irrelevant factors (e.g., background patterns and subject) induce domain shift between source and target distributions. Also, when the same SiFs are shared by the spoof and genuine images, they show a higher level of visual similarity and this hinders accurate face anti-spoofing. Hence, we aim to minimize the discrepancies among different domains via alleviating the effects of SiFs, and achieve improvements in generalization to unseen domains. To realize our goal, we propose a novel method called a Doubly Adversarial Suppression Network (DASN) that is trained to neglect the irrelevant factors and to focus more on faithful task-relevant factors. Our DASN consists of two types of adversarial learning schemes. In the first adversarial learning scheme, multiple SiFs are suppressed by deploying multiple discrimination heads that are trained against an encoder. In the second adversarial learning scheme, each of the discrimination heads is also adversarially trained to suppress a spoof factor, and the group of the secondary spoof classifier and the encoder aims to intensify the spoof factor by overcoming the suppression. We evaluate the proposed method on four public benchmark datasets, and achieve remarkable evaluation results in generalizing to unseen domains. The results demonstrate the effectiveness of the proposed method.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-04-30-ieeeaccess-DASN/001.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ Figure 1 ] Overview of DASN&lt;/em&gt;&lt;/p&gt;</content><author><name>김태욱:카카오엔터프라이즈</name></author><category term="papers" /><category term="face anti-spoofing" /><summary type="html">Abstract</summary></entry><entry><title type="html">RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases</title><link href="https://kakaoenterprise.github.io/papers/cljournal2021-ryansql" rel="alternate" type="text/html" title="RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases" /><published>2021-03-26T00:00:00-05:00</published><updated>2021-03-26T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/cljournal2021-ryansql</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/cljournal2021-ryansql">&lt;p&gt;스파이더 챌린지&lt;sup&gt;SPIDER Text-to-SQL Challenge&lt;/sup&gt; 성과를 정리한 공동 연구 논문이 Computational Linguistics에 실렸습니다. 미국 예일대학교에서 주최한 스파이더 챌린지는 각종 데이터를 정리∙보관할 때 사용하는 데이터베이스와 자연어 형태의 사용자 질의가 주어졌을때, 이 질의문을 SQL&lt;sup&gt;Structured Query Language&lt;/sup&gt;&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;문으로 변환해주는 Text-to-SQL&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 알고리즘의 정확도를 평가합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-03-26-cljournal-ryansql/001.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ 표 1 ] 주어진 자연어 문장과 데이터베이스를 이용해 SQL 문을 생성하는 예시&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;자연어 질의문을 SQL 문으로 변환하는 데에는 스케치 기반 슬롯 채우기&lt;sup&gt;sketch-based Slot Filling&lt;/sup&gt;가 주로 활용돼 왔습니다. SELECT&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; 문에 몇 개의 열&lt;sup&gt;column&lt;/sup&gt;을 입력해야 하는지, 어떤 열을 선택해야 하는지, 집계 함수&lt;sup&gt;aggregator&lt;/sup&gt;&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;로 무엇을 써야 하는지 등 판별해야 할 정보&lt;sup&gt;slot&lt;/sup&gt;를 먼저 구분하고 나서, 각 정보의 값을 채워넣는 식입니다. 다만 이 방식으로는 쿼리 속에 또 다른 쿼리가 든 중첩 질의&lt;sup&gt;nested query&lt;/sup&gt;를 생성하는 데 한계가 있습니다. SELECT 문의 개수가 정해지지 않아서 전체 설계도 자체를 그릴 수 없기 때문입니다.&lt;/p&gt;

&lt;p&gt;공동 연구팀이 제안한 Text-to-SQL 알고리즘인 RYQNSQL&lt;sup&gt;Recursively Yielding Annotation Network for SQL&lt;/sup&gt;은 대규모 영어 비라벨링 말뭉치를 사전학습한 언어 모델인 BERT에 자체 고안한 SPC&lt;sup&gt;Statement Position Code&lt;/sup&gt; 기법을 적용했습니다. SPC는 슬롯을 채울 때 중첩된 SELECT문을 좀 더 정확하게 생성할 수 있도록 합니다. 실험 결과, 스파이더 벤치마크 데이터셋에 대해 현재 최고 성능의(SOTA)&lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; 모델보다 3.2%p 더 높은 58.2%의 정확도를 달성했습니다.&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈는 데이터의 스키마(테이블 이름, 열 이름)뿐만 아니라 실제 값도 활용하는 방식 등으로 자사 Text-to-SQL 알고리즘의 성능과 사용성을 높여 기업 데이터베이스 활용의 문턱을 낮추는 데 기여할 계획입니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;overall-architecture&quot;&gt;Overall Architecture&lt;/h1&gt;

&lt;p&gt;Figure 1 shows the overall network architecture of the input encoder. The input encoder consists of five layers: Embedding layer, Embedding Encoder layer, Question-Column Alignment layer, Table Encoder layer, and Question-Table Alignment layer. Table 1 shows the proposed sketch for a SELECT statement. The sketch-based slot-filling decoder predicts values for slots of the proposed sketch, as well as the number of slots.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-03-26-cljournal-ryansql/002.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ Figure 1 ] Network architecture of the proposed input encoder. S represents self-attention.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-03-26-cljournal-ryansql/003.png&quot; width=&quot;80%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ table 1 ] Proposed sketch for a SELECT statement. $TBL and $COL represent a table and a column, respectively. $AGG is one of {none, max, min, count, sum, avg}, $ARI is one of the arithmetic operators {none, -, +, *, / }, and $COND is one of the conditional operators {between, =, &amp;gt;, &amp;lt;, &amp;gt;=, &amp;lt;=, !=, in, like, is, exists}. $DIST and $NOT are boolean variables representing the existence of keywords DISTINCT and NOT, respectively. $ORD is a binary value for keywords ASC/DESC, and $CONJ is one of conjunctions {AND, OR}. $VAL is the value for WHERE/HAVING condition; $SEL represents the slot for another SELECT statement.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;experiments&quot;&gt;Experiments&lt;/h1&gt;

&lt;p&gt;Table 2 shows that the proposed system RYANSQL improves the previous sketch-based slot filling system RCSQL by a large margin of 15% on the dev set. Note that the RCSQL fine-tuned another well known pretrained language model ELMo. With the use of BERT, among the systems without database content, the proposed systems (RYANSQL + BERT and RYANSQL v2 + BERT) outperforms the previous state-of-the-art by 2.5% and 4.9% respectively on the hidden test dataset. The proposed system still shows competitive results compared to the systems using database content; RATSQL v3 + BERT outperforms the proposed system by better aligning user questions and database schemas using database content.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-03-26-cljournal-ryansql/005.png&quot; width=&quot;90%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ Table 2 ] Evaluation results of the proposed systems and other state-of-the-art systems.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We evaluated the proposed models on the CSpider dataset. CSpider is a chinese-translated version of the Spider benchmark. Only the question of the spider dataset is translated; database table names and column names remain as English. Evaluation on the CSpider dataset will show if the proposed model could be applied on the different languages, even when the question language and database schema language are different. To handle the case, we used multilingual BERT, which has the same network architecture with BERT-base but is trained using multilingual corpus.&lt;/p&gt;

&lt;p&gt;The results are shown in Table 3. Compared to the exact matching accuracy 51.4% of RYANSQL + BERT-base on Spider dataset, the multilingual version shows 10% lower accuracy on dev set, but still shows comparable results to other state-of-the-art systems which are designed for CSpider dataset. Our proposed system showed 34.7% test accuracy on the test set, and ranked at 2nd place on the leaderboard.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-03-26-cljournal-ryansql/005.png&quot; width=&quot;90%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ Table 3 ] Evaluation results on CSpider dataset with other state-of-the-art systems.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h3&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;관계형 데이터베이스 관리를 위해 설계된 특수목적의 프로그래밍 언어 &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;NLI2DB&lt;sup&gt;natural language interface to databases&lt;/sup&gt;라고도 부른다. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;테이블 전체 또는 일부 열과 행 값을 호출하는 명령어 &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;값 집합에 대한 산술적인 계산(레코드의 수, 값의 합, 값의 평균, 최대값, 최소값)의 결과값을 출력한다. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;논문 제출 시점(2020년 4월) 최고 성능 &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>heuristic:카카오엔터프라이즈</name></author><category term="papers" /><category term="NLI2DB" /><category term="Text-to-SQL" /><summary type="html">스파이더 챌린지SPIDER Text-to-SQL Challenge 성과를 정리한 공동 연구 논문이 Computational Linguistics에 실렸습니다. 미국 예일대학교에서 주최한 스파이더 챌린지는 각종 데이터를 정리∙보관할 때 사용하는 데이터베이스와 자연어 형태의 사용자 질의가 주어졌을때, 이 질의문을 SQLStructured Query Language1문으로 변환해주는 Text-to-SQL2 알고리즘의 정확도를 평가합니다. 관계형 데이터베이스 관리를 위해 설계된 특수목적의 프로그래밍 언어 &amp;#8617; NLI2DBnatural language interface to databases라고도 부른다. &amp;#8617;</summary></entry></feed>