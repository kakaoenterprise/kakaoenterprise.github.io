<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://kakaoenterprise.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://kakaoenterprise.github.io/" rel="alternate" type="text/html" /><updated>2022-04-24T19:51:49-05:00</updated><id>https://kakaoenterprise.github.io/feed.xml</id><title type="html">카카오엔터프라이즈 AI Research</title><subtitle>카카오엔터프라이즈 AI Lab에서 발표한 AI 논문과 연구 성과를 소개합니다.</subtitle><author><name>카카오엔터프라이즈</name></author><entry><title type="html">Revisiting Interactive Recommender System with Reinforcement Learning</title><link href="https://kakaoenterprise.github.io/papers/sigir-rl-irs" rel="alternate" type="text/html" title="Revisiting Interactive Recommender System with Reinforcement Learning" /><published>2022-07-11T00:00:00-05:00</published><updated>2022-07-11T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/SIGIR-RL-IRS</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/sigir-rl-irs">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Interactive Recommender Systems (IRS) have drawn a lot of attention, due to their ability in modeling the interactive process between the user and the recommender system. Recently, numerous works have adopted Reinforcement Learning (RL) algorithms, which directly maximize the user’s cumulative rewards, in IRS.
In IRS, researchers commonly utilize the publicly available review datasets to compare and evaluate the algorithms. However, the user feedbacks provided in the public datasets only include an instant response (e.g., rating), without any inclusion of delayed response (e.g., dwell-time, lifetime value). Thus, the question remains whether the review datasets are an appropriate choice to evaluate the long-term effects in IRS.&lt;br /&gt;
In this work, we revisit the experiments on the IRS with the review datasets and compare the RL-based models with a simple reward model that greedily recommends the item with the highest one-step reward. Through extensive experiments, we found the followings: First, a simple greedy reward model outperforms the RL-based models in maximizing the cumulative rewards. Second, applying more weights on long-term rewards degrades the recommendation performance. Third, recommended items have mere long-term effects in the benchmark datasets. From these findings, we conclude that a dataset must be carefully verified and a simple greedy baseline should be included for a proper evaluation in the RL-based IRS.&lt;/p&gt;</content><author><name>이호준:카이스트</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">CoMPM: Context Modeling with Speaker’s Pre-trained Memory Tracking for Emotion Recognition in Conversation</title><link href="https://kakaoenterprise.github.io/papers/naacl-compm" rel="alternate" type="text/html" title="CoMPM: Context Modeling with Speaker’s Pre-trained Memory Tracking for Emotion Recognition in Conversation" /><published>2022-07-10T00:00:00-05:00</published><updated>2022-07-10T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/NAACL-CoMPM</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/naacl-compm">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;As the use of interactive machines grow, the task of Emotion Recognition in Conversation (ERC) became more important. If the machine-generated sentences reflect emotion, more human-like sympathetic conversations are possible. Since emotion recognition in conversation is inaccurate if the previous utterances are not taken into account, many studies reflect the dialogue context to improve the performances. Many recent approaches show performance improvement by combining knowledge into modules learned from external structured data. However, structured data is difficult to access in non-English languages, making it difficult to extend to other languages. Therefore, we extract the pre-trained memory using the pre-trained language model as an extractor of external knowledge. We introduce CoMPM, which combines the speaker’s pre-trained memory with the context model, and find that the pre-trained memory significantly improves the performance of the context model. CoMPM achieves the first or second performance on all data and is state-of-the-art among systems that do not leverage structured data. In addition, our method shows that it can be extended to other languages because structured knowledge is not required, unlike previous methods.&lt;/p&gt;</content><author><name>rung:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Contrastive Regularization for Semi-Supervised Learning</title><link href="https://kakaoenterprise.github.io/papers/cvpr-contrastive-regularization" rel="alternate" type="text/html" title="Contrastive Regularization for Semi-Supervised Learning" /><published>2022-06-20T00:00:00-05:00</published><updated>2022-06-20T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/cvpr-contrastive-regularization</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/cvpr-contrastive-regularization">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Consistency regularization on label predictions becomes a fundamental technique in semi-supervised learning, but it still requires a large number of training iterations for high performance. In this study, we analyze that the consistency regularization restricts the propagation of labeling information due to the exclusion of samples with unconfident pseudo-labels in the model updates. Then, we propose contrastive regularization to improve both efficiency and accuracy of the consistency regularization by well-clustered features of unlabeled data. In specific, after strongly augmented samples are assigned to clusters by their pseudo-labels, our contrastive regularization updates the model so that the features with confident pseudo-labels aggregate the features in the same cluster, while pushing away features in different clusters. As a result, the information of confident pseudo-labels can be effectively propagated into more unlabeled samples during training by the well-clustered features. On benchmarks of semi-supervised learning tasks, our contrastive regularization improves the previous consistency-based methods and achieves state-of-the-art results, especially with fewer training iterations. Our method also shows robust performance on open-set semi-supervised learning where unlabeled data includes out-of-distribution samples.&lt;/p&gt;</content><author><name>이도엽:POSTECH,카카오브레인</name></author><category term="papers" /><category term="Machine_Learning" /><summary type="html">Abstract</summary></entry><entry><title type="html">Vacillating Human Correlation of SacreBLEU in Unprotected Languages</title><link href="https://kakaoenterprise.github.io/papers/humeval-meta-evaluation" rel="alternate" type="text/html" title="Vacillating Human Correlation of SacreBLEU in Unprotected Languages" /><published>2022-05-22T00:00:00-05:00</published><updated>2022-05-22T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/HumEval-meta-evaluation</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/humeval-meta-evaluation">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;SacreBLEU, by incorporating a text normalizing step in the pipeline, has become a rising automatic evaluation metric in recent MT studies. With agglutinative languages such as Korean, however, the lexical-level metric cannot provide a conceivable result without a customized pre-tokenization. In this regard, this paper endeavors to examine the influence of diversified tokenization schemes –-word, morpheme, subword, character, and consonants &amp;amp; vowels (CV)–- on the metric, after its protective layer is peeled off.&lt;br /&gt;
By performing meta-evaluation with manually-constructed into-Korean resources, our empirical study demonstrates that the human correlation of the surface-based metric and other homogeneous ones (as an extension) vacillates greatly by the token type. Moreover, the human correlation of the metric often deteriorates due to some tokenization, with CV one of its culprits. Guiding through the proper usage of tokenizers for the given metric, we discover i) the feasibility of the character tokens, and ii) the deficit of CV in the Korean MT evaluation.&lt;/p&gt;</content><author><name>ria:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Multimodal Interactions Using Pretrained Unimodal Models for SIMMC 2.0</title><link href="https://kakaoenterprise.github.io/papers/aaai-simmc" rel="alternate" type="text/html" title="Multimodal Interactions Using Pretrained Unimodal Models for SIMMC 2.0" /><published>2022-02-28T00:00:00-06:00</published><updated>2022-02-28T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/aaai-simmc</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/aaai-simmc">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;This paper presents our work on the Situated Interactive MultiModal Conversations 2.0 challenge held at Dialog State Tracking Challenge 10. SIMMC 2.0 includes 4 subtasks, and we introduce our multimodal approaches for the subtask #1, #2 and the generation of subtask #4. SIMMC 2.0 dataset is a multimodal dataset containing image and text information, which is more challenging than the problem of only text-based conversations because it must be solved by understanding the relationship between image and text. Therefore, since there is a limit to solving only text models such as BERT or GPT2, we propose a multimodal model combining image and text. We first pretrain the multimodal model to understand the relationship between image and text, then finetune our model for each task. We achieve the 3rd best performance in subtask #1, #2 and a runner-up in the generation of subtask #4. The source code is available at https://github.com/rungjoo/simmc2.0.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈 연구팀은 지난해 10월 개최된 &lt;strong&gt;Situated Interactive MultiModal Conversations 2.0&lt;/strong&gt; (이하 SIMMC 2.0) 챌린지에 참여하여 subtask #1과 #2에서는 &lt;strong&gt;3위&lt;/strong&gt;를, #4에서는 &lt;strong&gt;2위&lt;/strong&gt;를 달성하는 성과를 거두었습니다. 본 논문을 통해 챌린지 참여 과정을 소개하고자 합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-챌린지-소개&quot;&gt;1. 챌린지 소개&lt;/h1&gt;

&lt;p&gt;먼저 해당 챌린지에 대해 짧게 소개드리려고 합니다. 지난해 2회째를 맞은 SIMMC 2.0는 AI 대화 시스템 분야의 대표적인 국제 경진대회인 &lt;strong&gt;DSTC(Dialog State Tracking Challenge)10&lt;/strong&gt;을 통해 개최되었습니다.
대회 주제는 바로, 멀티모달 데이터셋을 활용해 실생활에 쓰일 수 있는 어시스턴트(assistant) 모델을 만드는 것이었는데요. 주어진 데이터셋은 쇼핑 도메인에 특화된 목적지향 대화(task-oriented dialog) 데이터로 구성되어 있었고, 이 데이터셋을 활용해 사용자가 의류 또는 가구를 쇼핑하는 상황에서 AI 어시스턴트가 얼마나 대화 맥락에 적절한 응답을 생성하는지를 평가하는 과제들이 주어졌습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-과제-소개&quot;&gt;2. 과제 소개&lt;/h1&gt;

&lt;p&gt;연구팀은 SIMMC 2.0에서 주어진 4가지 과제 중, subtask #1, #2와 #4에 참여하였습니다. 각 subtask마다 사용 가능한 데이터와 모델링에 있어 차이가 있었고, 학습과 테스트 과정에서 활용 가능한 데이터에서도 제한이 있었습니다. 특히 모든 테스트 과정에서 객체의 시각적 메타데이터, 라벨링된 사용자 정보, 대화에 언급된 모든 객체 리스트 정보는 사용할 수 없었는데요. 다만, 객체의 비시각적 메타데이터, 시스템 발화에서 언급된 객체 리스트, 대화에 해당하는 배경이미지, 모든 객체의 경계 박스(bounding box) 데이터는 모두 활용 가능했습니다. 참고로, 여기서 객체는 의류 도메인 상에서 의류 이미지에 해당됩니다.&lt;/p&gt;

&lt;p&gt;좀 더 자세히 각 과제 내용을 살펴보면, &lt;strong&gt;#1 Multimodal Disambiguation&lt;/strong&gt;은 배경 전체 이미지와 대화 맥락이 주어질 때, 이 상황에서 마지막 발화의 명확성을 판단(True/False)하는 과제입니다. 예를 들어 오른쪽 옷걸이에 파란색 옷 3가지가 걸려있다고 가정했을 때, 아래와 같은 방식으로 발화가 이루어진다면 어떤 옷을 가르키는지 명확히 알 수 없기 때문에 불명확함을 의미하는 False를 도출하게 됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;발화1 : 파란색 옷이 어디 있나요?&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;발화2 : 저기 오른쪽 위에 있습니다.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다음으로 &lt;strong&gt;#2 Multimodal Coreference Resolution&lt;/strong&gt;은 사용자의 발화에 언급된 객체를 찾는 과제로, #1 과제와 동일한 테스트 데이터 사용이 가능했습니다. 이어 &lt;strong&gt;#4 Multimodal Dialog Response Generation &amp;amp; Retrieval&lt;/strong&gt;에서는 사용자 발화에 적절한 시스템 응답을 생성하거나 검색하는 과제였습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-과제-해결과정&quot;&gt;3. 과제 해결과정&lt;/h1&gt;

&lt;p&gt;연구팀은 과제 해결을 위해, 기존 텍스트 기반의 BERT와 GPT2에서 더 나아간 멀티모달 모델을 새롭게 고안하였습니다. 멀티모달 데이터셋은 이미지와 텍스트 정보를 모두 포함하고 있어, 텍스트로만 구성된 데이터셋보다 어려운 문제로 볼 수 있는데요. 이미지와 텍스트 간의 관계를 미리 이해할 수 있도록 멀티모달 사전학습(pre-training) 과정을 거쳤습니다.
사전학습에는 그림1과 같이 총 2가지 모델이 사용되었습니다. 하나는 객체 이미지와 텍스트 설명(description)이 일치하는지 판단하는 모델(ITM)이었고, 다른 하나는 배경 이미지와 대화 맥락(context)이 일치하는지 판단하는 모델(BTM)이었습니다. 두 가지 모델을 결합한 뒤 이를 각 태스크에 맞춰 미세 조정하는 방식으로, 하나의 멀티모달 모델을 사용해 전체 과제를 해결하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/001.png&quot; width=&quot;90%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림1. 멀티모달 사전학습 과정&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;전체적인 모델 구조는 그림2와 같은데요. 앞서 그림1에서 사전학습된 모델들을 모듈화해 전체 태스크에서 사용하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/002.png&quot; width=&quot;90%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림2. 전체 모델 구조&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;각 구조를 살펴보면 &lt;strong&gt;subtask #1&lt;/strong&gt;에서는 발화의 명확성을 판단하기 위해 전체 컨텍스트가 담긴 멀티모달 사전학습이 되지 않은 RoBERTa에 사전학습된 DeIT-I을 사용하여 주어진 이미지에서 의류 형태만 크롭한 후, 객체 설명과 일치하는지를 판단하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;subtask #2&lt;/strong&gt;에서는 #1과 데이터는 동일하게 사용하였지만, 사용자의 발화에 언급된 객체를 찾기 위해 대화맥락, 객체, 배경 정보를 모두 활용하는 구조를 사용했습니다. 먼저 context feature를 추출하기 위해, 그림3과 같은 구조 하에 두 가지 멀티태스크 러닝을 추가로 수행하였습니다. 1단계(utterance classification)에서는 매칭 판단에 유의미하지 않은 발화를 제거하기 위해 발화와 객체의 일치성을 판단하고, 2단계(system matching)에서는 이 객체를 이전 시스템 발화에 해당하는 &lt;code&gt;object_ids&lt;/code&gt;에 매칭하였습니다. 여기서 모델이 학습하는 데이터에 따라 추론과정도 조금 달라지게 되는데요. 학습 데이터로 어떤 &lt;code&gt;mention_objects&lt;/code&gt;를 사용하냐에 따라 모델의 강점이 달라집니다. 이에 따라 이전 발화에 언급됐던 &lt;code&gt;related objects&lt;/code&gt;는 1 또는 matching으로, 관련이 없는 &lt;code&gt;unrelated objects&lt;/code&gt;는 0으로, 이외 나머지를 의미하는 &lt;code&gt;others&lt;/code&gt;는 0 또는 matching으로 결과값을 도출합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/003.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림3. 주어진 발화에서 객체의 포함여부를 판단하는 로직 (two multi-task learning)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;예를 들어 그림4와 같이 유저와 시스템의 발화쌍이 있다면, 시스템 1과 시스템 2의 system matching 여부를 판단하는 건데요. Case1에서는 &lt;strong&gt;“파란색 옷”&lt;/strong&gt;으로 일치하기 때문에 1이, Case2에서는 &lt;strong&gt;“검은색과 빨간색 바지”&lt;/strong&gt;, &lt;strong&gt;“파란색 옷”&lt;/strong&gt;으로 일치하지 않기 때문에 0이 도출됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/004.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림4. 그림3의 로직 판단 예시 (유저 발화:파란색, 시스템 발화:노란색)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이처럼 대화 특성상 앞서 언급된 단어가 뒤에도 동일하게 언급될 가능성이 높기 때문에, 최종적으로 system matching이 1로 판별된 시스템 발화의 objects만을 사용하여 객체의 후보군을 축소시키고자 하였습니다. 여기서 이 정보에 object feature와 background feature를 추출하는 DeIT-I와 DeIT-B 값을 매칭해 최종적으로 발화에 언급된 객체를 판단할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;마지막으로, 사용자 발화에 적절한 시스템 응답을 생성하거나 검색하는 &lt;strong&gt;subtask #4&lt;/strong&gt;에서는 응답 생성만을 진행하였습니다. 여기서는 텍스트 모델로 GPT2-Large를 활용하여 전체 발화를 입력하였고, 시스템이 말할 다음 발화에 해당하는 이미지 정보(slot values)는  DeIT-I를 사용하여 object feature를 추출해 활용하였습니다. 다른 태스크와 달리, 이번 태스크에서는 현재 순서에 대한 주석 정보(system_transcript_annnotated)를 사용할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-챌린지-성과-소개&quot;&gt;4. 챌린지 성과 소개&lt;/h1&gt;

&lt;p&gt;학습에는 hugingface library를 사용하였고, 결과값은 아래 표와 같습니다. 전반적으로 베이스모델인 GPT2 대비 우수한 성능을 보였으며, 그결과 최종적으로 subtask #1, #2에서 각각 3위, #4 생성 분야에서는 준우승을 기록했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/005.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표1. subtask #1 성능 비교&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/006.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표2. subtask #2 성능 비교&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/007.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표3. subtask #4 성능 비교&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5-마치며&quot;&gt;5. 마치며&lt;/h1&gt;

&lt;p&gt;챌린지에 참여한 상세한 소스 코드는 &lt;a href=&quot;https://github.com/rungjoo/simmc2.0&quot;&gt;깃허브&lt;/a&gt;를 통해 확인하실 수 있습니다. 앞으로 카카오엔터프라이즈 연구팀은 보다 사람같은 챗봇 서비스 구현을 위해, 이번 연구결과를 적극 활용할 계획입니다.&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈의 AI 연구에 많은 관심 부탁드리며, 스몰톡 챗봇 ‘외개인아가’와 카카오엔터프라이즈 연구팀에 대해 궁금하시다면 아래 링크를 참고해주세요!&lt;/p&gt;

&lt;p&gt;🐶 &lt;a href=&quot;https://pf.kakao.com/_lKxoMT&quot;&gt;외개인아가 만나러가기&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;👨🏻‍💻 &lt;a href=&quot;http://kko.to/ailab_career&quot;&gt;인재영입&lt;/a&gt;&lt;/p&gt;</content><author><name>rung:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Proxyless Neural Architecture Adaptation for Supervised Learning and Self-Supervised Learning</title><link href="https://kakaoenterprise.github.io/papers/aaai-pnaa" rel="alternate" type="text/html" title="Proxyless Neural Architecture Adaptation for Supervised Learning and Self-Supervised Learning" /><published>2022-02-28T00:00:00-06:00</published><updated>2022-02-28T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/aaai-pnaa</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/aaai-pnaa">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Recently, Neural Architecture Search (NAS) methods are introduced and show impressive performance on many benchmarks.
Among those NAS studies, Neural Architecture Transformer (NAT) aims to adapt the given neural architecture to improve performance while maintaining computational costs.
However, NAT lacks reproducibility and it requires an additional architecture adaptation process before network weight training.
In this paper, we propose proxyless neural architecture adaptation that is reproducible and efficient.
Our method can be applied to both supervised learning and self-supervised learning.
The proposed method shows stable performance on various architectures.
Extensive reproducibility experiments on two datasets, i.e., CIFAR-10 and Tiny Imagenet, present that the proposed method definitely outperforms NAT and be applicable to other models and datasets.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;본 글에서는 카카오엔터프라이즈와 인하대 공동 연구팀이 연산 자원을 많이 사용하는 기존 NAS의 단점을 보완하고자, 새롭게 제안한 알고리즘에 대해 소개드리려고 합니다. 해당 연구 결과는 AAAI 2022 학회에서 Workshop으로 개최된 &lt;strong&gt;Learning Network Architecture during Training&lt;/strong&gt; 을 통해 공개되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-nasneural-architecture-search의-등장&quot;&gt;1. NAS(Neural Architecture Search)의 등장&lt;/h1&gt;

&lt;p&gt;일반적으로 딥러닝에서 높은 성능을 얻기 위해서는 주어진 task와 데이터셋에 최적화된 모델 구조를 찾는 과정이 필요합니다. 이를 위해 사람이 직접 각 레이어와 필터 개수 등 여러 설정을 일일이 미세조정하고 설계하는 과정을 거치는데요. 최적화된 모델 구조는 각 task와 데이터셋에 따라 달라지기 때문에, 해당 구조의 성능은 실제 학습을 진행한 뒤 그 결과로만 판단할 수 있습니다.&lt;/p&gt;

&lt;p&gt;바로 이러한 불편함을 개선하고자 등장한 연구 분야가 &lt;strong&gt;NAS(Neural Architecture Search)&lt;/strong&gt; 입니다. NAS는 자동화를 통해 주어진 task에 최적화된 모델 구조를 편리하고 빠르게 탐색하는 방법론으로, 여러 벤치마크 데이터셋에서 눈에 띄는 우수한 연구성과들을 보이고 있습니다.&lt;/p&gt;

&lt;p&gt;여기서 더 나아가, 최근에는 NAS의 이점은 유지하면서 연산비용을 줄인 여러 연구가 주목받고 있는데요. 그 중 하나로는, 기존에 방대한 아키텍처 후보군(Search Space)을 아주 작게 줄여서 최적의 아키텍처를 찾는 &lt;strong&gt;NAT(Neural Architecture Transformer)&lt;/strong&gt; 방식이 있습니다. 하지만, NAT은 알고리즘의 재현성(reproducibility)이 떨어지고, 동일한 셀 아키텍처 구조 하에서만 탐색이 가능하다는 단점이 있는데요.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-proxyless-neural-architecture-adaption-방법론-소개&quot;&gt;2. Proxyless Neural Architecture Adaption 방법론 소개&lt;/h1&gt;

&lt;p&gt;본 연구에서는 NAT의 단점을 개선한 &lt;strong&gt;Proxyless Neural Architecture Adaption&lt;/strong&gt; 방법론을 새롭게 제안하였습니다.&lt;/p&gt;

&lt;p&gt;이 방법론은 NAT과 비교해 재현성이 높고, 효율적이라는 점이 특징인데요. NAT에서는 추가적인 아키텍처 서치 과정이 필요하기 때문에 학습시간과 GPU 자원 소모가 큰데 반해, 본 방법론은 아키텍처 서치와 모델 학습을 동시에 진행하여 자원을 크게 절감할 수 있습니다.&lt;/p&gt;

&lt;p&gt;또한, 하나의 셀(cell) 단위가 아닌 다양한 셀 아키텍처를 가진 매크로블록(macroblock) 기반 탐색으로 전체 범위를 탐색할 수도 있습니다. 이뿐만 아니라, 지도학습(Supervised Learning)과 자기지도학습(Self-Supervised Learning)에 모두 적용될 수 있어 활용도가 높은데요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-PNAA/001.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림1. Proxyless Neural Architecture Adaption 방법론을 적용한 네트워크 아키텍처 검색 구조&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-성능-비교&quot;&gt;3. 성능 비교&lt;/h1&gt;

&lt;p&gt;이 방법론의 성능과 광범위한 재현성을 검증하기 위해 &lt;strong&gt;CIFAR-10&lt;/strong&gt;과 &lt;strong&gt;Tiny Imagenet&lt;/strong&gt; 데이터셋에 여러가지 모델로 실험을 진행했습니다.&lt;/p&gt;

&lt;p&gt;먼저 지도학습 환경에서 수작업으로 설계된 Resnet20과 MobilentV2, NAS 모델인 DARTS와 Proxyless NAS 모델을 활용하여 테스트를 진행하였습니다. 기존 방식과 NAT, 본 방법론으로 실험을 진행한 결과, [표1]과 같이 다양한 아키텍처에서 기존 방법론 대비 뛰어난 성능을 확인했습니다. 더불어 전체적인 연산비용 측면에서도 NAT과 비교해 더 적은 비용을 사용할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-PNAA/002.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표1. 지도학습에서의 평균 정확도, 표준편차, 연산시간 비교 (CIFAR-10 기준)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;표2에서는 마찬가지로 CIFAR-10 데이터셋 상에서 5번의 무작위 시도를 거쳐 재현성을 테스트 진행하였고, 안정적인 성능을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-PNAA/003.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표2. 지도학습에서의 재현성 비교 (CIFAR-10 기준)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-PNAA/004.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표3. 지도학습에서의 평균 정확도, 표준편차, 연산시간 비교 (Tiny Imagenet 기준)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;또한, 자기지도학습 환경에서도 성능을 확인하기 위해 NAS모델인 DARTS와 Proxyless NAS에 추가적인 테스트를 진행하였고, 여기에서도 기존 방식 대비 우수한 성능을 확인하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-PNAA/005.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표4. 자기지도학습에서의 정확도 비교 (CIFAR-10 기준)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-향후-연구-계획&quot;&gt;4. 향후 연구 계획&lt;/h1&gt;

&lt;p&gt;카카오엔터프라이즈 연구팀은 해당 방법론을 활용하여 정확도를 넘어, 결과가 도출되는 시간, 속도(latency)까지 고려한 모델을 만들고자 합니다. 특히 컴퓨터비전 분야 연구에 적용해 최적의 모델 구조를 빠르고, 저비용으로 탐색하는 데에 중점을 둘 계획입니다.&lt;/p&gt;

&lt;p&gt;앞으로도 카카오엔터프라이즈의 AI 연구에 많은 관심 부탁드리며, &lt;strong&gt;카카오엔터프라이즈 AI Lab &amp;amp; Service&lt;/strong&gt;에 대해 궁금하시다면 아래 링크를 참고해주세요!&lt;/p&gt;

&lt;p&gt;👨🏻‍💻 &lt;a href=&quot;http://kko.to/ailab_career&quot;&gt;인재영입&lt;/a&gt;&lt;/p&gt;</content><author><name>김도국:인하대학교</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">APEACH: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets</title><link href="https://kakaoenterprise.github.io/papers/arxiv-apeach" rel="alternate" type="text/html" title="APEACH: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets" /><published>2022-02-25T00:00:00-06:00</published><updated>2022-02-25T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/arxiv-apeach</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/arxiv-apeach">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Detecting toxic or pejorative expressions in online communities has become one of the main concerns for preventing the users’ men- tal harm. This led to the development of large- scale hate speech detection datasets of var- ious domains, which are mainly built upon web-crawled texts with labels by crowdwork- ers. However, for languages other than English, researchers might have to rely on only a small- sized corpus due to the lack of data-driven re- search of hate speech detection. This some- times misleads the evaluation of prevalently used pretrained language models (PLMs) such as BERT, given that PLMs often share the do- main of pretraining corpus with the evaluation set, resulting in over-representation of the de- tection performance. Also, the scope of pejo- rative expressions might be restricted if the dataset is built on a single domain text.&lt;/p&gt;

&lt;p&gt;To alleviate the above problems in Korean hate speech detection, we propose APEACH, a method that allows the collection of hate speech generated by unspecified users. By con- trolling the crowd-generation of hate speech and adding only a minimum post-labeling, we create a corpus that enables the general- izable and fair evaluation of hate speech de- tection regarding text domain and topic. We compare our outcome with prior work on an annotation-based toxic news comment dataset using publicly available PLMs. We check that our dataset is less sensitive to the lexical over- lap between the evaluation set and pretraining corpus of PLMs, showing that it helps mitigate the unexpected under/over-representation of model performance. We distribute our dataset publicly online to further facilitate the general- domain hate speech detection in Korean.&lt;/p&gt;</content><author><name>양기창:카카오, 카카오엔터프라이즈, 숭실대</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness</title><link href="https://kakaoenterprise.github.io/papers/neurips-smoothmix" rel="alternate" type="text/html" title="SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness" /><published>2021-12-06T00:00:00-06:00</published><updated>2021-12-06T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/neurips-smoothmix</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/neurips-smoothmix">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Randomized smoothing is currently a state-of-the-art method to construct a certifiably robust classifier from neural networks against \(l_{2}\)-adversarial perturbations. Under the paradigm, the robustness of a classifier is aligned with the prediction confidence, i.e., the higher confidence from a smoothed classifier implies the better robustness. This motivates us to rethink the fundamental trade-off between accuracy and robustness in terms of calibrating confidences of smoothed classifier. In this paper, we propose a simple training scheme, coined SmoothMix, to control the robustness of smoothed classifiers via self-mixup: it trains convex combinations of samples along the direction of adversarial perturbation for each input. The proposed procedure effectively identifies over-confident, near off-class samples as a cause of limited robustness in case of smoothed classifiers, and offers an intuitive way to adaptively set a new decision boundary between these samples for better robustness. Our experimental results demonstrate that the proposed method can significantly improve the certified \(l_{2}\)-robustness of smoothed classifiers compared to existing state-of-the-art robust training methods.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;본 글에서는 카카오엔터프라이즈와 카이스트, Vector Institute 공동 연구팀이 강건한 분류기 구축을 위해, 새롭게 제안하는 적대적 학습(adversarial training) 기법을 소개드리려고 합니다. 해당 연구 결과는 NeurIPS 2021 학회를 통해 공개되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-적대적-학습-기법의-필요성&quot;&gt;1. 적대적 학습 기법의 필요성&lt;/h1&gt;

&lt;p&gt;일반적으로 딥러닝 모델은 훈련 과정에서 예측값에 대해 과잉 확신(over-confidence)을 가지는 경향이 있습니다. 이로 인해 틀린 답을 정답으로 간주하는 큰 문제를 야기할 수 있는데요. 이같은 문제 해결을 위해 적대적 학습 기법이 등장하였습니다.&lt;/p&gt;

&lt;p&gt;적대적 학습 기법은 원본 데이터에 최적의 노이즈를 추가한 적대적 샘플을 통해, 딥러닝 모델의 오예측을 유도하는 훈련 방법론입니다. 실제 사람이 보기에는 크게 문제가 없는 수준의 노이즈더라도, 노이즈로 인해 왜곡된 이미지는 모델 예측에 악영향을 끼칠 수 있습니다. 이처럼 예측이 어려운 적대적 샘플을 통해 학습을 진행하고, 이를 방어하기 위한 목적함수를 조정하는 적대적 학습 기법을 활용해 정확도를 한층 높인 강건한 분류기를 구축할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/001.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림1. 맨 왼쪽 그림은 57.7%의 confidence로 판다라고 인식하지만, 중간에 노이즈를 추가한 오른쪽 그림은 유관상으로는 같은 그림 같아 보이지만 모델은 99.3%의 confidence로 긴팔원숭이로 분류하는 걸 확인할 수 있습니다. [Goodfellow et al., 2014]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-기존-적대적-학습-기법-연구의-한계&quot;&gt;2. 기존 적대적 학습 기법 연구의 한계&lt;/h1&gt;

&lt;p&gt;기존 연구들은 학습 과정에서 적대적 입력으로 데이터를 증강하는 학습 기법 [Madry et al., 2018]을 널리 사용해 왔습니다. 이에 비해 가우시안(Gaussian) 랜덤변수를 표방한 무작위 평활화(randomized smoothing) 기법은 충분히 연구되지 못했습니다.&lt;/p&gt;

&lt;p&gt;무작위 평활화 기법은 현재 가장 강력한 perturbation으로 알려진 \(l_{2}\) adversarial perturbations에도 강건한 분류 성능을 보이는 SOTA(State-of-the-art) 방법론입니다. 최근 등장한 SmoothAdv 방법론 [Salman et al., 2019]은 무작위 평활화 기반 분류기에 직접적으로 적대적 학습을 적용해, 모델 성능이 향상될 수 있음을 보였습니다. 하지만, 이는 이미 지역적으로 강인성을 확보하고 있는 평활 분류기에 여전히 기존 방법론의 지역적 검색을 사용하는 등 일반 분류기와의 차이를 고려하지 못했다는 한계가 있었는데요. 이에 본 연구팀은 평활화 기반 분류기의 특성을 고려한 적대적 학습 기법을 새롭게 제안하고자 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/002.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림2. 기존 적대적 학습 기법(a, b)과 제안 방법론(c)에 대한 시각화&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-smoothmix-방법론-소개&quot;&gt;3. SmoothMix 방법론 소개&lt;/h1&gt;

&lt;p&gt;SmoothMix의 가장 큰 특징은 적대적 입력 탐색에서 지역적 검색을 사용하지 않고, 해당 입력값과 원본 입력값 간의 mixup 학습 구조를 가진다는 점입니다.&lt;/p&gt;

&lt;p&gt;이를 자세히 살펴보면, SmootMix는 기존 적대적 학습 기법에서 사용되었던 제한된 ε-ball 내부에서의 검색을 사용하지 않는 대신, 주어진 입력 x 주변의 over-confident한 입력을 찾습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/003.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이때 over-confident 입력값을 학습에 적용하기 위해, confidence 값을 uniform prediction으로 penalize하는데요. 해당 값과 원본 입력값 간의 차이를 측정하여 mixup [Zhang et al., 2017] 목적함수를 최소화하는 정규화 기법을 사용합니다. 이를 통해 두 입력값 간의 confidence를 조정하여 기존 적대적 학습 기법 대비 분류기의 강건함을 향상시켰습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/004.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/005.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또한, SmoothMix는 SmoothAdv 기법을 통해 효과를 입증한 mixup 목적함수에 ‘single-step adversarial example’ 기법을 추가 제안하여 더욱 강건한 분류기 구조를 구성하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-성능-평가&quot;&gt;4. 성능 평가&lt;/h1&gt;

&lt;p&gt;해당 방법론은 &lt;strong&gt;MNIST, CIFAR-10, ImagNet&lt;/strong&gt; 등의 이미지 분류 데이터셋에서 기존 방법론 대비 높은 성능을 보였습니다. 특히 모델의 정확도와 강인성의 최적 정도를 보여주는 ACR(Average Certified Radius) 수치를 평가하였고, 아래 표2, 표3과 같이 현재 SOTA(State-of-the-art)와 비교해 우수한 성능을 확인하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/006.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표1. 기존 방법론과의 성능 비교 (MNIST 데이터셋 기준)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/007.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표2. 기존 방법론과의 성능 비교 (CIFAR-10 데이터셋 기준)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/008.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표3. 기존 방법론과의 성능 비교 (ImageNet 데이터셋 기준)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5-향후-연구-계획&quot;&gt;5. 향후 연구 계획&lt;/h1&gt;

&lt;p&gt;적대적 학습 기법은 노이즈에 강력한 모델을 구축하는데 큰 역할을 할 수 있습니다. 이로 인해 모델이 처음 보는 실서비스 데이터에서도 우수한 성능을 보일 수 있는데요. 이 기법은 다양한 AI 분야에 활용이 가능하지만, 특히 자율주행차, 의료 시스템 등 높은 정확도를 요구하는 영역에서 오판단을 줄여 그 성능을 크게 발휘할 수 있습니다.&lt;/p&gt;

&lt;p&gt;향후 카카오엔터프라이즈 연구팀은 해당 방법론을 기반으로 여러가지 컴퓨터 비전 문제를 해결하고, 서비스를 고도화해 나갈 계획입니다. 앞으로도 카카오엔터프라이즈 연구에 많은 관심과 응원 부탁드립니다. 감사합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;참고문헌&quot;&gt;참고문헌&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;[Goodfellow et al., 2014] Explaining and harnessing adversarial examples. arXiv 2014.&lt;/li&gt;
  &lt;li&gt;[Madry et al., 2018] Towards Deep Learning Models Resistant to Adversarial Attacks, ICLR 2018.&lt;/li&gt;
  &lt;li&gt;[Salman et al., 2019] Provably robust deep learning via adversarially trained smoothed classifiers, NeurIPS 2019.&lt;/li&gt;
  &lt;li&gt;[Zhang et al., 2017] mixup: Beyond Empirical Risk Minimization, ICLR 2018.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;현재 카카오엔터프라이즈 AI Lab에서는 다양한 AI 연구와 서비스화를 함께 고민해나갈 여러분의 지원을 기다리고 있습니다. AI를 통해 더욱 가치있는 세상을 만들고, 꿈을 현실로 만들어가는 여정에 함께하세요!&lt;/p&gt;

&lt;p&gt;👨🏻‍💻 &lt;a href=&quot;http://kko.to/ailab_career&quot;&gt;인재영입&lt;/a&gt;&lt;/p&gt;</content><author><name>정종현:카이스트</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Learning Debiased Representation via Disentangled Feature Augmentation</title><link href="https://kakaoenterprise.github.io/papers/neurips-learning-debiased-representation" rel="alternate" type="text/html" title="Learning Debiased Representation via Disentangled Feature Augmentation" /><published>2021-12-06T00:00:00-06:00</published><updated>2021-12-06T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/neurips-learning-debiased-representation</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/neurips-learning-debiased-representation">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Image classification models tend to make decisions based on peripheral attributes of data items that have strong correlation with a target variable (i.e., dataset bias). These biased models suffer from the poor generalization capability when evaluated on unbiased datasets. Existing approaches for debiasing often identify and emphasize those samples with no such correlation (i.e., bias-conflicting) without defining the bias type in advance. However, such bias-conflicting samples are significantly scarce in biased datasets, limiting the debiasing capability of these approaches. This paper first presents an empirical analysis revealing that training with “diverse” bias-conflicting samples beyond a given training set is crucial for debiasing as well as the generalization capability. Based on this observation, we propose a novel feature-level data augmentation technique in order to synthesize diverse bias-conflicting samples. To this end, our method learns the disentangled representation of (1) the intrinsic attributes (i.e., those inherently defining a certain class) and (2) bias attributes (i.e., peripheral attributes causing the bias), from a large number of bias-aligned samples, the bias attributes of which have strong correlation with the target variable. Using the disentangled representation, we synthesize bias-conflicting samples that contain the diverse intrinsic attributes of bias-aligned samples by swapping their latent features. By utilizing these diversified bias-conflicting features during the training, our approach achieves superior classification accuracy and debiasing results against the existing baselines on both synthetic as well as real-world datasets.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;본 글에서는 카카오엔터프라이즈와 카이스트 공동 연구팀이 데이터셋의 편향(bias) 문제를 개선하기 위해 새롭게 제안한 데이터 증강(data augmentation) 기법을 소개드리고자 합니다. 해당 연구 결과는 NeurIPS 2021 학회에서 oral presentation을 통해 공개되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-기존-편향성-개선-연구의-한계&quot;&gt;1. 기존 편향성 개선 연구의 한계&lt;/h1&gt;

&lt;p&gt;데이터셋의 편향 문제는 이미지 분류 모델의 학습 과정에서 흔하게 발생됩니다. 데이터를 수집, 가공하는 과정에서 자연스럽게 존재하게 되는 bias로 인해, 모델의 성능이 크게 좌우될 수 있습니다. 이로 인해 훈련 과정에서는 높은 정확도를 보였던 모델이 실제 편향되지 않은 데이터셋에 적용될 때, 낮은 성능을 보일 수 있는데요. 예를 들어 ‘새’ 이미지를 학습하는 과정에서 학습한 모든 이미지에 ‘하늘’이 있었다면, 하늘과 함께 있는 물체만 새로 인식하여 ‘땅’ 또는 ‘풀’ 위에 있는 새는 분류에 실패할 수 있습니다. 학습자의 의도와 관계 없이, 데이터셋 자체에 존재하는 편향성에 의해 모델의 성능이 저하될 수 있는건데요.&lt;/p&gt;

&lt;p&gt;기존 연구들은 이러한 편향성을 제거하기 위해, 편향성을 제거한 샘플(bias-conflicting sample)을 추가하거나, 가중치를 조정하는 방식을 활용했습니다. 사실상 bias-conflicting 샘플을 수집하는 데에는 물리적, 시간적 어려움이 있기 때문에 이러한 방식에는 한계가 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-다양한-bias-conflicting-샘플의-중요성&quot;&gt;2. 다양한 bias-conflicting 샘플의 중요성&lt;/h1&gt;

&lt;p&gt;딥러닝 학습에 있어 알고리즘 이상으로 중요한 것은 바로 데이터의 양입니다. 많은 데이터를 잘 활용하는 것이 모델의 성능을 좌우하는데요. 이에 공동 연구팀은 편향성 개선을 위해서는 ‘다양한 bias-conficting 샘플을 많이 활용하는 것이 모델 학습에 효과적’이라는 가설을 가지고, 이를 검증하기 위한 토이셋(toy-set) 실험을 진행하였습니다.&lt;/p&gt;

&lt;p&gt;먼저 훈련 과정에는 그림1과 같이 두 가지 데이터셋(Colored MNIST, Corrupted CIFAR-10)을 활용하였습니다. 하나는 기존 MNIST 데이터셋에서 숫자에 특정 색상이 자주 나오도록 색상 bias를 설정한 Colored MNIST이고, 다른 하나는 기존 CIFAR-10 데이터셋에서 사물에 특정 텍스쳐(Corruption)가 반복되도록 텍스쳐 bias를 변형한 Corrupted CIFAR-10입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-Learning Debiased Representation/001.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림1. 데이터셋 형태
(점선 위는 기존 bias-aligned 샘플이며, 점선 아래는 bias-conflicting 샘플임)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;아래 표1은 해당 데이터셋으로 학습한 모델에 편향성이 없는 테스트셋(unbiased test sets)을 적용했을 때의 분류 정확도를 나타냅니다. 다양한 bias-conflicting 샘플을 학습에 많이 활용한 경우가 가장 높은 정확도를 보였습니다. 여기서 주목할 점은 바로 샘플링 비율보다 다양성 비율이 높았을 때, 상대적으로 높은 정확도를 보였다는 점입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-Learning Debiased Representation/002.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표1. 편향성이 없는 테스트셋(unbiased test sets)에서의 분류 정확도&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이를 통해 본 연구팀은 다양한 bias-conflicting 샘플의 활용이 편향 제거에 효과가 있다는 가설을 검증하였고,  bias-conflicting 샘플 데이터의 증강을 통해 편향성을 개선한 방법론을 제안하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-debiasing-via-disentangled-feature-augmentation-방법론-소개&quot;&gt;3. Debiasing via disentangled feature augmentation 방법론 소개&lt;/h1&gt;

&lt;p&gt;해당 방법론의 가장 큰 특징은 각 이미지가 가진 고유속성과 편향속성을 교차합성하여 데이터를 증강시켰다는 점입니다.&lt;/p&gt;

&lt;p&gt;전체 구조를 살펴보면 각각 고유속성(\(E_{i}\)), 편향속성(\(E_{b}\))으로 구분되는 2개의 인코더가 있습니다. 하나의 이미지가 입력되면 해당 인코더를 거쳐 각각 고유속성과 편향속성의 disentangled feature로 \(Z_{i}\), \(Z_{b}\)가 출력됩니다.&lt;/p&gt;

&lt;p&gt;여기서 고유속성과 편향속성의 disentanglement를 학습하기 위해, 다음과 같은 학습과정을 진행합니다. 먼저 고유속성을 학습하는데 사용되는 \(E_{b}\)와 \(C_{b}\)를 기존 논문(Nam et al., “Learning from Failure: Training Debiased Classifier from Biased Classifier”)에서 제시한 Generalized Cross-Entropy Loss를 통해 “쉬운” 정보만을 학습하도록 강제합니다. 이를 통해 해당 인코더는 주어진 이미지로부터 편향속성을 주로 추출하게 되고, 이렇게 편향 학습된 인코더로부터 상대적으로 큰 Loss를 갖게 되는 이미지를 Bias-conflicting 샘플로 판단할 수 있게 됩니다. 이러한 이미지들에 대한 가중학습을 통해, \(E_{i}\)와 \(C_{i}\)는 편향속성이 아닌 고유속성을 주로 추출하는데 사용됩니다.&lt;/p&gt;

&lt;p&gt;이때, 이 한 쌍의 피쳐들을 미니배치 내 다른 랜덤 이미지의 피쳐값과 교차 합성(swapping)을 함으로써 기존 고유속성과 편향속성 간의 강한 상관관계(correlation)가 끊어진 샘플을 생성할 수 있는데요. 이는 곧 편향성을 가지지 않는 새로운 bias-conflicting 샘플을 의미합니다. 이 과정을 통해 실제 편향성 개선에 효과적인 유의미한 합성 결과물을 구현할 수 있었습니다. 또한, 데이터 증강으로 훈련 데이터셋의 다양성을 증가시키고, 데이터의 품질 또한 높여 분류 정확도를 향상시킬 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-Learning Debiased Representation/003.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림2. 전체 모델의 구조&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-성능-평가&quot;&gt;4. 성능 평가&lt;/h1&gt;

&lt;p&gt;보다 정량적인 성능 평가를 위해, 앞서 언급한 2가지 합성 데이터셋(Colored MNIST, Corrupted CIFAR-10)과 함께 BFFHQ 데이터셋을 활용하여 실험을 진행하였습니다. 여기서 BFFHQ는 기존 FFHQ 데이터셋이 가진 나이와 성별 편향성(대다수 데이터가 젊은 여자와 나이 든 남자로 구성됨)에 변형을 둔 데이터셋입니다.&lt;/p&gt;

&lt;p&gt;이 세가지 데이터셋으로 학습한 모델을 각각 편향성이 없는 테스트셋으로 평가했을 때, 아래 표2와 같이 SOTA(State-of-the-art)를 뛰어넘는 우수한 성능을 보임을 확인하였습니다. 해당 방법론은 합성 데이터셋 뿐만 아니라 실서비스 상의 데이터셋에도 효과적이라는 사실을 알 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-Learning Debiased Representation/004.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표2. 편향성이 없는 테스트셋(unbiased test sets)으로 평가한 분류 정확도&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5-향후-연구-계획&quot;&gt;5. 향후 연구 계획&lt;/h1&gt;

&lt;p&gt;Dataset Bias 문제 해결은 이미지 인식, 얼굴 인식 등 여러 컴퓨터 비전 과제를 해결하는데 큰 역할을 할 수 있습니다. 예를 들어 앞서 언급한 이미지 분류 문제에서 오식률을 개선하고, 모델의 성능을 높이는 데에도 활용될 수 있는데요. 보다 구체적으로는 딥러닝 모델이 성별, 인종, 나이 등과 같이 편향과 관련된 여러 민감한 문제에 대해 보다 신뢰성 높은 정답을 도출할 수 있도록 기여할 수 있을 것으로 기대됩니다.&lt;/p&gt;

&lt;p&gt;향후 카카오엔터프라이즈 AI Lab 비전팀은 해당 방법론을 기반으로 여러가지 컴퓨터 비전 문제를 해결하고, 서비스를 고도화할 계획입니다. 앞으로도 카카오엔터프라이즈 연구에 많은 관심과 응원 부탁드립니다. 감사합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;현재 카카오엔터프라이즈 AI Lab에서는 다양한 AI 연구와 서비스화를 함께 고민해나갈 여러분의 지원을 기다리고 있습니다. AI를 통해 더욱 가치있는 세상을 만들고, 꿈을 현실로 만들어가는 여정에 함께하세요!&lt;/p&gt;

&lt;p&gt;👨🏻‍💻 &lt;a href=&quot;http://kko.to/ailab_career&quot;&gt;인재영입&lt;/a&gt;&lt;/p&gt;</content><author><name>이정수:카이스트, 카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Kakao Enterprise’s WMT21 Machine Translation using Terminologies Task Submission</title><link href="https://kakaoenterprise.github.io/papers/wmt21-terminology-translation" rel="alternate" type="text/html" title="Kakao Enterprise’s WMT21 Machine Translation using Terminologies Task Submission" /><published>2021-11-19T00:00:00-06:00</published><updated>2021-11-19T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/wmt21-terminology-translation</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/wmt21-terminology-translation">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;This paper describes Kakao Enterprise’s submission to the WMT21 shared Machine Translation using Terminologies task. We integrate terminology constraints by pre-training with target lemma annotations and fine-tuning with exact target annotations utilizing the given terminology dataset. This approach yields a model that achieves outstanding results in terms of both translation quality and term consistency, ranking first based on COMET in the En→Fr language direction. Furthermore, we explore various methods such as back-translation, explicitly training terminologies as additional parallel data, and in-domain data selection.&lt;/p&gt;</content><author><name>juliette:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry></feed>