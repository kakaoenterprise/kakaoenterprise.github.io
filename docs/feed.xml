<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://kakaoenterprise.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://kakaoenterprise.github.io/" rel="alternate" type="text/html" /><updated>2022-04-24T19:51:49-05:00</updated><id>https://kakaoenterprise.github.io/feed.xml</id><title type="html">ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ AI Research</title><subtitle>ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ AI Labì—ì„œ ë°œí‘œí•œ AI ë…¼ë¬¸ê³¼ ì—°êµ¬ ì„±ê³¼ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.</subtitle><author><name>ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ</name></author><entry><title type="html">Revisiting Interactive Recommender System with Reinforcement Learning</title><link href="https://kakaoenterprise.github.io/papers/sigir-rl-irs" rel="alternate" type="text/html" title="Revisiting Interactive Recommender System with Reinforcement Learning" /><published>2022-07-11T00:00:00-05:00</published><updated>2022-07-11T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/SIGIR-RL-IRS</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/sigir-rl-irs">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Interactive Recommender Systems (IRS) have drawn a lot of attention, due to their ability in modeling the interactive process between the user and the recommender system. Recently, numerous works have adopted Reinforcement Learning (RL) algorithms, which directly maximize the userâ€™s cumulative rewards, in IRS.
In IRS, researchers commonly utilize the publicly available review datasets to compare and evaluate the algorithms. However, the user feedbacks provided in the public datasets only include an instant response (e.g., rating), without any inclusion of delayed response (e.g., dwell-time, lifetime value). Thus, the question remains whether the review datasets are an appropriate choice to evaluate the long-term effects in IRS.&lt;br /&gt;
In this work, we revisit the experiments on the IRS with the review datasets and compare the RL-based models with a simple reward model that greedily recommends the item with the highest one-step reward. Through extensive experiments, we found the followings: First, a simple greedy reward model outperforms the RL-based models in maximizing the cumulative rewards. Second, applying more weights on long-term rewards degrades the recommendation performance. Third, recommended items have mere long-term effects in the benchmark datasets. From these findings, we conclude that a dataset must be carefully verified and a simple greedy baseline should be included for a proper evaluation in the RL-based IRS.&lt;/p&gt;</content><author><name>ì´í˜¸ì¤€:ì¹´ì´ìŠ¤íŠ¸</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">CoMPM: Context Modeling with Speakerâ€™s Pre-trained Memory Tracking for Emotion Recognition in Conversation</title><link href="https://kakaoenterprise.github.io/papers/naacl-compm" rel="alternate" type="text/html" title="CoMPM: Context Modeling with Speakerâ€™s Pre-trained Memory Tracking for Emotion Recognition in Conversation" /><published>2022-07-10T00:00:00-05:00</published><updated>2022-07-10T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/NAACL-CoMPM</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/naacl-compm">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;As the use of interactive machines grow, the task of Emotion Recognition in Conversation (ERC) became more important. If the machine-generated sentences reflect emotion, more human-like sympathetic conversations are possible. Since emotion recognition in conversation is inaccurate if the previous utterances are not taken into account, many studies reflect the dialogue context to improve the performances. Many recent approaches show performance improvement by combining knowledge into modules learned from external structured data. However, structured data is difficult to access in non-English languages, making it difficult to extend to other languages. Therefore, we extract the pre-trained memory using the pre-trained language model as an extractor of external knowledge. We introduce CoMPM, which combines the speakerâ€™s pre-trained memory with the context model, and find that the pre-trained memory significantly improves the performance of the context model. CoMPM achieves the first or second performance on all data and is state-of-the-art among systems that do not leverage structured data. In addition, our method shows that it can be extended to other languages because structured knowledge is not required, unlike previous methods.&lt;/p&gt;</content><author><name>rung:ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Contrastive Regularization for Semi-Supervised Learning</title><link href="https://kakaoenterprise.github.io/papers/cvpr-contrastive-regularization" rel="alternate" type="text/html" title="Contrastive Regularization for Semi-Supervised Learning" /><published>2022-06-20T00:00:00-05:00</published><updated>2022-06-20T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/cvpr-contrastive-regularization</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/cvpr-contrastive-regularization">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Consistency regularization on label predictions becomes a fundamental technique in semi-supervised learning, but it still requires a large number of training iterations for high performance. In this study, we analyze that the consistency regularization restricts the propagation of labeling information due to the exclusion of samples with unconfident pseudo-labels in the model updates. Then, we propose contrastive regularization to improve both efficiency and accuracy of the consistency regularization by well-clustered features of unlabeled data. In specific, after strongly augmented samples are assigned to clusters by their pseudo-labels, our contrastive regularization updates the model so that the features with confident pseudo-labels aggregate the features in the same cluster, while pushing away features in different clusters. As a result, the information of confident pseudo-labels can be effectively propagated into more unlabeled samples during training by the well-clustered features. On benchmarks of semi-supervised learning tasks, our contrastive regularization improves the previous consistency-based methods and achieves state-of-the-art results, especially with fewer training iterations. Our method also shows robust performance on open-set semi-supervised learning where unlabeled data includes out-of-distribution samples.&lt;/p&gt;</content><author><name>ì´ë„ì—½:POSTECH,ì¹´ì¹´ì˜¤ë¸Œë ˆì¸</name></author><category term="papers" /><category term="Machine_Learning" /><summary type="html">Abstract</summary></entry><entry><title type="html">Vacillating Human Correlation of SacreBLEU in Unprotected Languages</title><link href="https://kakaoenterprise.github.io/papers/humeval-meta-evaluation" rel="alternate" type="text/html" title="Vacillating Human Correlation of SacreBLEU in Unprotected Languages" /><published>2022-05-22T00:00:00-05:00</published><updated>2022-05-22T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/HumEval-meta-evaluation</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/humeval-meta-evaluation">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;SacreBLEU, by incorporating a text normalizing step in the pipeline, has become a rising automatic evaluation metric in recent MT studies. With agglutinative languages such as Korean, however, the lexical-level metric cannot provide a conceivable result without a customized pre-tokenization. In this regard, this paper endeavors to examine the influence of diversified tokenization schemes â€“-word, morpheme, subword, character, and consonants &amp;amp; vowels (CV)â€“- on the metric, after its protective layer is peeled off.&lt;br /&gt;
By performing meta-evaluation with manually-constructed into-Korean resources, our empirical study demonstrates that the human correlation of the surface-based metric and other homogeneous ones (as an extension) vacillates greatly by the token type. Moreover, the human correlation of the metric often deteriorates due to some tokenization, with CV one of its culprits. Guiding through the proper usage of tokenizers for the given metric, we discover i) the feasibility of the character tokens, and ii) the deficit of CV in the Korean MT evaluation.&lt;/p&gt;</content><author><name>ria:ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Multimodal Interactions Using Pretrained Unimodal Models for SIMMC 2.0</title><link href="https://kakaoenterprise.github.io/papers/aaai-simmc" rel="alternate" type="text/html" title="Multimodal Interactions Using Pretrained Unimodal Models for SIMMC 2.0" /><published>2022-02-28T00:00:00-06:00</published><updated>2022-02-28T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/aaai-simmc</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/aaai-simmc">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;This paper presents our work on the Situated Interactive MultiModal Conversations 2.0 challenge held at Dialog State Tracking Challenge 10. SIMMC 2.0 includes 4 subtasks, and we introduce our multimodal approaches for the subtask #1, #2 and the generation of subtask #4. SIMMC 2.0 dataset is a multimodal dataset containing image and text information, which is more challenging than the problem of only text-based conversations because it must be solved by understanding the relationship between image and text. Therefore, since there is a limit to solving only text models such as BERT or GPT2, we propose a multimodal model combining image and text. We first pretrain the multimodal model to understand the relationship between image and text, then finetune our model for each task. We achieve the 3rd best performance in subtask #1, #2 and a runner-up in the generation of subtask #4. The source code is available at https://github.com/rungjoo/simmc2.0.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ ì—°êµ¬íŒ€ì€ ì§€ë‚œí•´ 10ì›” ê°œìµœëœ &lt;strong&gt;Situated Interactive MultiModal Conversations 2.0&lt;/strong&gt; (ì´í•˜ SIMMC 2.0) ì±Œë¦°ì§€ì— ì°¸ì—¬í•˜ì—¬ subtask #1ê³¼ #2ì—ì„œëŠ” &lt;strong&gt;3ìœ„&lt;/strong&gt;ë¥¼, #4ì—ì„œëŠ” &lt;strong&gt;2ìœ„&lt;/strong&gt;ë¥¼ ë‹¬ì„±í•˜ëŠ” ì„±ê³¼ë¥¼ ê±°ë‘ì—ˆìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì„ í†µí•´ ì±Œë¦°ì§€ ì°¸ì—¬ ê³¼ì •ì„ ì†Œê°œí•˜ê³ ì í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-ì±Œë¦°ì§€-ì†Œê°œ&quot;&gt;1. ì±Œë¦°ì§€ ì†Œê°œ&lt;/h1&gt;

&lt;p&gt;ë¨¼ì € í•´ë‹¹ ì±Œë¦°ì§€ì— ëŒ€í•´ ì§§ê²Œ ì†Œê°œë“œë¦¬ë ¤ê³  í•©ë‹ˆë‹¤. ì§€ë‚œí•´ 2íšŒì§¸ë¥¼ ë§ì€ SIMMC 2.0ëŠ” AI ëŒ€í™” ì‹œìŠ¤í…œ ë¶„ì•¼ì˜ ëŒ€í‘œì ì¸ êµ­ì œ ê²½ì§„ëŒ€íšŒì¸ &lt;strong&gt;DSTC(Dialog State Tracking Challenge)10&lt;/strong&gt;ì„ í†µí•´ ê°œìµœë˜ì—ˆìŠµë‹ˆë‹¤.
ëŒ€íšŒ ì£¼ì œëŠ” ë°”ë¡œ, ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ì„ í™œìš©í•´ ì‹¤ìƒí™œì— ì“°ì¼ ìˆ˜ ìˆëŠ” ì–´ì‹œìŠ¤í„´íŠ¸(assistant) ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒì´ì—ˆëŠ”ë°ìš”. ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì€ ì‡¼í•‘ ë„ë©”ì¸ì— íŠ¹í™”ëœ ëª©ì ì§€í–¥ ëŒ€í™”(task-oriented dialog) ë°ì´í„°ë¡œ êµ¬ì„±ë˜ì–´ ìˆì—ˆê³ , ì´ ë°ì´í„°ì…‹ì„ í™œìš©í•´ ì‚¬ìš©ìê°€ ì˜ë¥˜ ë˜ëŠ” ê°€êµ¬ë¥¼ ì‡¼í•‘í•˜ëŠ” ìƒí™©ì—ì„œ AI ì–´ì‹œìŠ¤í„´íŠ¸ê°€ ì–¼ë§ˆë‚˜ ëŒ€í™” ë§¥ë½ì— ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•˜ëŠ” ê³¼ì œë“¤ì´ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-ê³¼ì œ-ì†Œê°œ&quot;&gt;2. ê³¼ì œ ì†Œê°œ&lt;/h1&gt;

&lt;p&gt;ì—°êµ¬íŒ€ì€ SIMMC 2.0ì—ì„œ ì£¼ì–´ì§„ 4ê°€ì§€ ê³¼ì œ ì¤‘, subtask #1, #2ì™€ #4ì— ì°¸ì—¬í•˜ì˜€ìŠµë‹ˆë‹¤. ê° subtaskë§ˆë‹¤ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì™€ ëª¨ë¸ë§ì— ìˆì–´ ì°¨ì´ê°€ ìˆì—ˆê³ , í•™ìŠµê³¼ í…ŒìŠ¤íŠ¸ ê³¼ì •ì—ì„œ í™œìš© ê°€ëŠ¥í•œ ë°ì´í„°ì—ì„œë„ ì œí•œì´ ìˆì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ ëª¨ë“  í…ŒìŠ¤íŠ¸ ê³¼ì •ì—ì„œ ê°ì²´ì˜ ì‹œê°ì  ë©”íƒ€ë°ì´í„°, ë¼ë²¨ë§ëœ ì‚¬ìš©ì ì •ë³´, ëŒ€í™”ì— ì–¸ê¸‰ëœ ëª¨ë“  ê°ì²´ ë¦¬ìŠ¤íŠ¸ ì •ë³´ëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ì—ˆëŠ”ë°ìš”. ë‹¤ë§Œ, ê°ì²´ì˜ ë¹„ì‹œê°ì  ë©”íƒ€ë°ì´í„°, ì‹œìŠ¤í…œ ë°œí™”ì—ì„œ ì–¸ê¸‰ëœ ê°ì²´ ë¦¬ìŠ¤íŠ¸, ëŒ€í™”ì— í•´ë‹¹í•˜ëŠ” ë°°ê²½ì´ë¯¸ì§€, ëª¨ë“  ê°ì²´ì˜ ê²½ê³„ ë°•ìŠ¤(bounding box) ë°ì´í„°ëŠ” ëª¨ë‘ í™œìš© ê°€ëŠ¥í–ˆìŠµë‹ˆë‹¤. ì°¸ê³ ë¡œ, ì—¬ê¸°ì„œ ê°ì²´ëŠ” ì˜ë¥˜ ë„ë©”ì¸ ìƒì—ì„œ ì˜ë¥˜ ì´ë¯¸ì§€ì— í•´ë‹¹ë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì¢€ ë” ìì„¸íˆ ê° ê³¼ì œ ë‚´ìš©ì„ ì‚´í´ë³´ë©´, &lt;strong&gt;#1 Multimodal Disambiguation&lt;/strong&gt;ì€ ë°°ê²½ ì „ì²´ ì´ë¯¸ì§€ì™€ ëŒ€í™” ë§¥ë½ì´ ì£¼ì–´ì§ˆ ë•Œ, ì´ ìƒí™©ì—ì„œ ë§ˆì§€ë§‰ ë°œí™”ì˜ ëª…í™•ì„±ì„ íŒë‹¨(True/False)í•˜ëŠ” ê³¼ì œì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì˜¤ë¥¸ìª½ ì˜·ê±¸ì´ì— íŒŒë€ìƒ‰ ì˜· 3ê°€ì§€ê°€ ê±¸ë ¤ìˆë‹¤ê³  ê°€ì •í–ˆì„ ë•Œ, ì•„ë˜ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë°œí™”ê°€ ì´ë£¨ì–´ì§„ë‹¤ë©´ ì–´ë–¤ ì˜·ì„ ê°€ë¥´í‚¤ëŠ”ì§€ ëª…í™•íˆ ì•Œ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ë¶ˆëª…í™•í•¨ì„ ì˜ë¯¸í•˜ëŠ” Falseë¥¼ ë„ì¶œí•˜ê²Œ ë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;ë°œí™”1 : íŒŒë€ìƒ‰ ì˜·ì´ ì–´ë”” ìˆë‚˜ìš”?&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;ë°œí™”2 : ì €ê¸° ì˜¤ë¥¸ìª½ ìœ„ì— ìˆìŠµë‹ˆë‹¤.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ë‹¤ìŒìœ¼ë¡œ &lt;strong&gt;#2 Multimodal Coreference Resolution&lt;/strong&gt;ì€ ì‚¬ìš©ìì˜ ë°œí™”ì— ì–¸ê¸‰ëœ ê°ì²´ë¥¼ ì°¾ëŠ” ê³¼ì œë¡œ, #1 ê³¼ì œì™€ ë™ì¼í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©ì´ ê°€ëŠ¥í–ˆìŠµë‹ˆë‹¤. ì´ì–´ &lt;strong&gt;#4 Multimodal Dialog Response Generation &amp;amp; Retrieval&lt;/strong&gt;ì—ì„œëŠ” ì‚¬ìš©ì ë°œí™”ì— ì ì ˆí•œ ì‹œìŠ¤í…œ ì‘ë‹µì„ ìƒì„±í•˜ê±°ë‚˜ ê²€ìƒ‰í•˜ëŠ” ê³¼ì œì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-ê³¼ì œ-í•´ê²°ê³¼ì •&quot;&gt;3. ê³¼ì œ í•´ê²°ê³¼ì •&lt;/h1&gt;

&lt;p&gt;ì—°êµ¬íŒ€ì€ ê³¼ì œ í•´ê²°ì„ ìœ„í•´, ê¸°ì¡´ í…ìŠ¤íŠ¸ ê¸°ë°˜ì˜ BERTì™€ GPT2ì—ì„œ ë” ë‚˜ì•„ê°„ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ ìƒˆë¡­ê²Œ ê³ ì•ˆí•˜ì˜€ìŠµë‹ˆë‹¤. ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ì€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ëª¨ë‘ í¬í•¨í•˜ê³  ìˆì–´, í…ìŠ¤íŠ¸ë¡œë§Œ êµ¬ì„±ëœ ë°ì´í„°ì…‹ë³´ë‹¤ ì–´ë ¤ìš´ ë¬¸ì œë¡œ ë³¼ ìˆ˜ ìˆëŠ”ë°ìš”. ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ ê´€ê³„ë¥¼ ë¯¸ë¦¬ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë©€í‹°ëª¨ë‹¬ ì‚¬ì „í•™ìŠµ(pre-training) ê³¼ì •ì„ ê±°ì³¤ìŠµë‹ˆë‹¤.
ì‚¬ì „í•™ìŠµì—ëŠ” ê·¸ë¦¼1ê³¼ ê°™ì´ ì´ 2ê°€ì§€ ëª¨ë¸ì´ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. í•˜ë‚˜ëŠ” ê°ì²´ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì„¤ëª…(description)ì´ ì¼ì¹˜í•˜ëŠ”ì§€ íŒë‹¨í•˜ëŠ” ëª¨ë¸(ITM)ì´ì—ˆê³ , ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ë°°ê²½ ì´ë¯¸ì§€ì™€ ëŒ€í™” ë§¥ë½(context)ì´ ì¼ì¹˜í•˜ëŠ”ì§€ íŒë‹¨í•˜ëŠ” ëª¨ë¸(BTM)ì´ì—ˆìŠµë‹ˆë‹¤. ë‘ ê°€ì§€ ëª¨ë¸ì„ ê²°í•©í•œ ë’¤ ì´ë¥¼ ê° íƒœìŠ¤í¬ì— ë§ì¶° ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, í•˜ë‚˜ì˜ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ ì‚¬ìš©í•´ ì „ì²´ ê³¼ì œë¥¼ í•´ê²°í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/001.png&quot; width=&quot;90%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;ê·¸ë¦¼1. ë©€í‹°ëª¨ë‹¬ ì‚¬ì „í•™ìŠµ ê³¼ì •&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;ì „ì²´ì ì¸ ëª¨ë¸ êµ¬ì¡°ëŠ” ê·¸ë¦¼2ì™€ ê°™ì€ë°ìš”. ì•ì„œ ê·¸ë¦¼1ì—ì„œ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ë“¤ì„ ëª¨ë“ˆí™”í•´ ì „ì²´ íƒœìŠ¤í¬ì—ì„œ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/002.png&quot; width=&quot;90%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;ê·¸ë¦¼2. ì „ì²´ ëª¨ë¸ êµ¬ì¡°&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;ê° êµ¬ì¡°ë¥¼ ì‚´í´ë³´ë©´ &lt;strong&gt;subtask #1&lt;/strong&gt;ì—ì„œëŠ” ë°œí™”ì˜ ëª…í™•ì„±ì„ íŒë‹¨í•˜ê¸° ìœ„í•´ ì „ì²´ ì»¨í…ìŠ¤íŠ¸ê°€ ë‹´ê¸´ ë©€í‹°ëª¨ë‹¬ ì‚¬ì „í•™ìŠµì´ ë˜ì§€ ì•Šì€ RoBERTaì— ì‚¬ì „í•™ìŠµëœ DeIT-Iì„ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ ì´ë¯¸ì§€ì—ì„œ ì˜ë¥˜ í˜•íƒœë§Œ í¬ë¡­í•œ í›„, ê°ì²´ ì„¤ëª…ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ë¥¼ íŒë‹¨í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;subtask #2&lt;/strong&gt;ì—ì„œëŠ” #1ê³¼ ë°ì´í„°ëŠ” ë™ì¼í•˜ê²Œ ì‚¬ìš©í•˜ì˜€ì§€ë§Œ, ì‚¬ìš©ìì˜ ë°œí™”ì— ì–¸ê¸‰ëœ ê°ì²´ë¥¼ ì°¾ê¸° ìœ„í•´ ëŒ€í™”ë§¥ë½, ê°ì²´, ë°°ê²½ ì •ë³´ë¥¼ ëª¨ë‘ í™œìš©í•˜ëŠ” êµ¬ì¡°ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ë¨¼ì € context featureë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•´, ê·¸ë¦¼3ê³¼ ê°™ì€ êµ¬ì¡° í•˜ì— ë‘ ê°€ì§€ ë©€í‹°íƒœìŠ¤í¬ ëŸ¬ë‹ì„ ì¶”ê°€ë¡œ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. 1ë‹¨ê³„(utterance classification)ì—ì„œëŠ” ë§¤ì¹­ íŒë‹¨ì— ìœ ì˜ë¯¸í•˜ì§€ ì•Šì€ ë°œí™”ë¥¼ ì œê±°í•˜ê¸° ìœ„í•´ ë°œí™”ì™€ ê°ì²´ì˜ ì¼ì¹˜ì„±ì„ íŒë‹¨í•˜ê³ , 2ë‹¨ê³„(system matching)ì—ì„œëŠ” ì´ ê°ì²´ë¥¼ ì´ì „ ì‹œìŠ¤í…œ ë°œí™”ì— í•´ë‹¹í•˜ëŠ” &lt;code&gt;object_ids&lt;/code&gt;ì— ë§¤ì¹­í•˜ì˜€ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ëª¨ë¸ì´ í•™ìŠµí•˜ëŠ” ë°ì´í„°ì— ë”°ë¼ ì¶”ë¡ ê³¼ì •ë„ ì¡°ê¸ˆ ë‹¬ë¼ì§€ê²Œ ë˜ëŠ”ë°ìš”. í•™ìŠµ ë°ì´í„°ë¡œ ì–´ë–¤ &lt;code&gt;mention_objects&lt;/code&gt;ë¥¼ ì‚¬ìš©í•˜ëƒì— ë”°ë¼ ëª¨ë¸ì˜ ê°•ì ì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤. ì´ì— ë”°ë¼ ì´ì „ ë°œí™”ì— ì–¸ê¸‰ëë˜ &lt;code&gt;related objects&lt;/code&gt;ëŠ” 1 ë˜ëŠ” matchingìœ¼ë¡œ, ê´€ë ¨ì´ ì—†ëŠ” &lt;code&gt;unrelated objects&lt;/code&gt;ëŠ” 0ìœ¼ë¡œ, ì´ì™¸ ë‚˜ë¨¸ì§€ë¥¼ ì˜ë¯¸í•˜ëŠ” &lt;code&gt;others&lt;/code&gt;ëŠ” 0 ë˜ëŠ” matchingìœ¼ë¡œ ê²°ê³¼ê°’ì„ ë„ì¶œí•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/003.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;ê·¸ë¦¼3. ì£¼ì–´ì§„ ë°œí™”ì—ì„œ ê°ì²´ì˜ í¬í•¨ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” ë¡œì§ (two multi-task learning)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;ì˜ˆë¥¼ ë“¤ì–´ ê·¸ë¦¼4ì™€ ê°™ì´ ìœ ì €ì™€ ì‹œìŠ¤í…œì˜ ë°œí™”ìŒì´ ìˆë‹¤ë©´, ì‹œìŠ¤í…œ 1ê³¼ ì‹œìŠ¤í…œ 2ì˜ system matching ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” ê±´ë°ìš”. Case1ì—ì„œëŠ” &lt;strong&gt;â€œíŒŒë€ìƒ‰ ì˜·â€&lt;/strong&gt;ìœ¼ë¡œ ì¼ì¹˜í•˜ê¸° ë•Œë¬¸ì— 1ì´, Case2ì—ì„œëŠ” &lt;strong&gt;â€œê²€ì€ìƒ‰ê³¼ ë¹¨ê°„ìƒ‰ ë°”ì§€â€&lt;/strong&gt;, &lt;strong&gt;â€œíŒŒë€ìƒ‰ ì˜·â€&lt;/strong&gt;ìœ¼ë¡œ ì¼ì¹˜í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— 0ì´ ë„ì¶œë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/004.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;ê·¸ë¦¼4. ê·¸ë¦¼3ì˜ ë¡œì§ íŒë‹¨ ì˜ˆì‹œ (ìœ ì € ë°œí™”:íŒŒë€ìƒ‰, ì‹œìŠ¤í…œ ë°œí™”:ë…¸ë€ìƒ‰)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;ì´ì²˜ëŸ¼ ëŒ€í™” íŠ¹ì„±ìƒ ì•ì„œ ì–¸ê¸‰ëœ ë‹¨ì–´ê°€ ë’¤ì—ë„ ë™ì¼í•˜ê²Œ ì–¸ê¸‰ë  ê°€ëŠ¥ì„±ì´ ë†’ê¸° ë•Œë¬¸ì—, ìµœì¢…ì ìœ¼ë¡œ system matchingì´ 1ë¡œ íŒë³„ëœ ì‹œìŠ¤í…œ ë°œí™”ì˜ objectsë§Œì„ ì‚¬ìš©í•˜ì—¬ ê°ì²´ì˜ í›„ë³´êµ°ì„ ì¶•ì†Œì‹œí‚¤ê³ ì í•˜ì˜€ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ì´ ì •ë³´ì— object featureì™€ background featureë¥¼ ì¶”ì¶œí•˜ëŠ” DeIT-Iì™€ DeIT-B ê°’ì„ ë§¤ì¹­í•´ ìµœì¢…ì ìœ¼ë¡œ ë°œí™”ì— ì–¸ê¸‰ëœ ê°ì²´ë¥¼ íŒë‹¨í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë§ˆì§€ë§‰ìœ¼ë¡œ, ì‚¬ìš©ì ë°œí™”ì— ì ì ˆí•œ ì‹œìŠ¤í…œ ì‘ë‹µì„ ìƒì„±í•˜ê±°ë‚˜ ê²€ìƒ‰í•˜ëŠ” &lt;strong&gt;subtask #4&lt;/strong&gt;ì—ì„œëŠ” ì‘ë‹µ ìƒì„±ë§Œì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” í…ìŠ¤íŠ¸ ëª¨ë¸ë¡œ GPT2-Largeë¥¼ í™œìš©í•˜ì—¬ ì „ì²´ ë°œí™”ë¥¼ ì…ë ¥í•˜ì˜€ê³ , ì‹œìŠ¤í…œì´ ë§í•  ë‹¤ìŒ ë°œí™”ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ì •ë³´(slot values)ëŠ”  DeIT-Ië¥¼ ì‚¬ìš©í•˜ì—¬ object featureë¥¼ ì¶”ì¶œí•´ í™œìš©í•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íƒœìŠ¤í¬ì™€ ë‹¬ë¦¬, ì´ë²ˆ íƒœìŠ¤í¬ì—ì„œëŠ” í˜„ì¬ ìˆœì„œì— ëŒ€í•œ ì£¼ì„ ì •ë³´(system_transcript_annnotated)ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-ì±Œë¦°ì§€-ì„±ê³¼-ì†Œê°œ&quot;&gt;4. ì±Œë¦°ì§€ ì„±ê³¼ ì†Œê°œ&lt;/h1&gt;

&lt;p&gt;í•™ìŠµì—ëŠ” hugingface libraryë¥¼ ì‚¬ìš©í•˜ì˜€ê³ , ê²°ê³¼ê°’ì€ ì•„ë˜ í‘œì™€ ê°™ìŠµë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ ë² ì´ìŠ¤ëª¨ë¸ì¸ GPT2 ëŒ€ë¹„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ê·¸ê²°ê³¼ ìµœì¢…ì ìœ¼ë¡œ subtask #1, #2ì—ì„œ ê°ê° 3ìœ„, #4 ìƒì„± ë¶„ì•¼ì—ì„œëŠ” ì¤€ìš°ìŠ¹ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/005.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;í‘œ1. subtask #1 ì„±ëŠ¥ ë¹„êµ&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/006.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;í‘œ2. subtask #2 ì„±ëŠ¥ ë¹„êµ&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/007.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;í‘œ3. subtask #4 ì„±ëŠ¥ ë¹„êµ&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5-ë§ˆì¹˜ë©°&quot;&gt;5. ë§ˆì¹˜ë©°&lt;/h1&gt;

&lt;p&gt;ì±Œë¦°ì§€ì— ì°¸ì—¬í•œ ìƒì„¸í•œ ì†ŒìŠ¤ ì½”ë“œëŠ” &lt;a href=&quot;https://github.com/rungjoo/simmc2.0&quot;&gt;ê¹ƒí—ˆë¸Œ&lt;/a&gt;ë¥¼ í†µí•´ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•ìœ¼ë¡œ ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ ì—°êµ¬íŒ€ì€ ë³´ë‹¤ ì‚¬ëŒê°™ì€ ì±—ë´‡ ì„œë¹„ìŠ¤ êµ¬í˜„ì„ ìœ„í•´, ì´ë²ˆ ì—°êµ¬ê²°ê³¼ë¥¼ ì ê·¹ í™œìš©í•  ê³„íšì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆì˜ AI ì—°êµ¬ì— ë§ì€ ê´€ì‹¬ ë¶€íƒë“œë¦¬ë©°, ìŠ¤ëª°í†¡ ì±—ë´‡ â€˜ì™¸ê°œì¸ì•„ê°€â€™ì™€ ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ ì—°êµ¬íŒ€ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹œë‹¤ë©´ ì•„ë˜ ë§í¬ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”!&lt;/p&gt;

&lt;p&gt;ğŸ¶ &lt;a href=&quot;https://pf.kakao.com/_lKxoMT&quot;&gt;ì™¸ê°œì¸ì•„ê°€ ë§Œë‚˜ëŸ¬ê°€ê¸°&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ğŸ‘¨ğŸ»â€ğŸ’» &lt;a href=&quot;http://kko.to/ailab_career&quot;&gt;ì¸ì¬ì˜ì…&lt;/a&gt;&lt;/p&gt;</content><author><name>rung:ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Proxyless Neural Architecture Adaptation for Supervised Learning and Self-Supervised Learning</title><link href="https://kakaoenterprise.github.io/papers/aaai-pnaa" rel="alternate" type="text/html" title="Proxyless Neural Architecture Adaptation for Supervised Learning and Self-Supervised Learning" /><published>2022-02-28T00:00:00-06:00</published><updated>2022-02-28T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/aaai-pnaa</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/aaai-pnaa">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Recently, Neural Architecture Search (NAS) methods are introduced and show impressive performance on many benchmarks.
Among those NAS studies, Neural Architecture Transformer (NAT) aims to adapt the given neural architecture to improve performance while maintaining computational costs.
However, NAT lacks reproducibility and it requires an additional architecture adaptation process before network weight training.
In this paper, we propose proxyless neural architecture adaptation that is reproducible and efficient.
Our method can be applied to both supervised learning and self-supervised learning.
The proposed method shows stable performance on various architectures.
Extensive reproducibility experiments on two datasets, i.e., CIFAR-10 and Tiny Imagenet, present that the proposed method definitely outperforms NAT and be applicable to other models and datasets.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;ë³¸ ê¸€ì—ì„œëŠ” ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆì™€ ì¸í•˜ëŒ€ ê³µë™ ì—°êµ¬íŒ€ì´ ì—°ì‚° ìì›ì„ ë§ì´ ì‚¬ìš©í•˜ëŠ” ê¸°ì¡´ NASì˜ ë‹¨ì ì„ ë³´ì™„í•˜ê³ ì, ìƒˆë¡­ê²Œ ì œì•ˆí•œ ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•´ ì†Œê°œë“œë¦¬ë ¤ê³  í•©ë‹ˆë‹¤. í•´ë‹¹ ì—°êµ¬ ê²°ê³¼ëŠ” AAAI 2022 í•™íšŒì—ì„œ Workshopìœ¼ë¡œ ê°œìµœëœ &lt;strong&gt;Learning Network Architecture during Training&lt;/strong&gt; ì„ í†µí•´ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-nasneural-architecture-searchì˜-ë“±ì¥&quot;&gt;1. NAS(Neural Architecture Search)ì˜ ë“±ì¥&lt;/h1&gt;

&lt;p&gt;ì¼ë°˜ì ìœ¼ë¡œ ë”¥ëŸ¬ë‹ì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ì–»ê¸° ìœ„í•´ì„œëŠ” ì£¼ì–´ì§„ taskì™€ ë°ì´í„°ì…‹ì— ìµœì í™”ëœ ëª¨ë¸ êµ¬ì¡°ë¥¼ ì°¾ëŠ” ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ì‚¬ëŒì´ ì§ì ‘ ê° ë ˆì´ì–´ì™€ í•„í„° ê°œìˆ˜ ë“± ì—¬ëŸ¬ ì„¤ì •ì„ ì¼ì¼ì´ ë¯¸ì„¸ì¡°ì •í•˜ê³  ì„¤ê³„í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹˜ëŠ”ë°ìš”. ìµœì í™”ëœ ëª¨ë¸ êµ¬ì¡°ëŠ” ê° taskì™€ ë°ì´í„°ì…‹ì— ë”°ë¼ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì—, í•´ë‹¹ êµ¬ì¡°ì˜ ì„±ëŠ¥ì€ ì‹¤ì œ í•™ìŠµì„ ì§„í–‰í•œ ë’¤ ê·¸ ê²°ê³¼ë¡œë§Œ íŒë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë°”ë¡œ ì´ëŸ¬í•œ ë¶ˆí¸í•¨ì„ ê°œì„ í•˜ê³ ì ë“±ì¥í•œ ì—°êµ¬ ë¶„ì•¼ê°€ &lt;strong&gt;NAS(Neural Architecture Search)&lt;/strong&gt; ì…ë‹ˆë‹¤. NASëŠ” ìë™í™”ë¥¼ í†µí•´ ì£¼ì–´ì§„ taskì— ìµœì í™”ëœ ëª¨ë¸ êµ¬ì¡°ë¥¼ í¸ë¦¬í•˜ê³  ë¹ ë¥´ê²Œ íƒìƒ‰í•˜ëŠ” ë°©ë²•ë¡ ìœ¼ë¡œ, ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ ëˆˆì— ë„ëŠ” ìš°ìˆ˜í•œ ì—°êµ¬ì„±ê³¼ë“¤ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì—¬ê¸°ì„œ ë” ë‚˜ì•„ê°€, ìµœê·¼ì—ëŠ” NASì˜ ì´ì ì€ ìœ ì§€í•˜ë©´ì„œ ì—°ì‚°ë¹„ìš©ì„ ì¤„ì¸ ì—¬ëŸ¬ ì—°êµ¬ê°€ ì£¼ëª©ë°›ê³  ìˆëŠ”ë°ìš”. ê·¸ ì¤‘ í•˜ë‚˜ë¡œëŠ”, ê¸°ì¡´ì— ë°©ëŒ€í•œ ì•„í‚¤í…ì²˜ í›„ë³´êµ°(Search Space)ì„ ì•„ì£¼ ì‘ê²Œ ì¤„ì—¬ì„œ ìµœì ì˜ ì•„í‚¤í…ì²˜ë¥¼ ì°¾ëŠ” &lt;strong&gt;NAT(Neural Architecture Transformer)&lt;/strong&gt; ë°©ì‹ì´ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, NATì€ ì•Œê³ ë¦¬ì¦˜ì˜ ì¬í˜„ì„±(reproducibility)ì´ ë–¨ì–´ì§€ê³ , ë™ì¼í•œ ì…€ ì•„í‚¤í…ì²˜ êµ¬ì¡° í•˜ì—ì„œë§Œ íƒìƒ‰ì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ë‹¨ì ì´ ìˆëŠ”ë°ìš”.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-proxyless-neural-architecture-adaption-ë°©ë²•ë¡ -ì†Œê°œ&quot;&gt;2. Proxyless Neural Architecture Adaption ë°©ë²•ë¡  ì†Œê°œ&lt;/h1&gt;

&lt;p&gt;ë³¸ ì—°êµ¬ì—ì„œëŠ” NATì˜ ë‹¨ì ì„ ê°œì„ í•œ &lt;strong&gt;Proxyless Neural Architecture Adaption&lt;/strong&gt; ë°©ë²•ë¡ ì„ ìƒˆë¡­ê²Œ ì œì•ˆí•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ ë°©ë²•ë¡ ì€ NATê³¼ ë¹„êµí•´ ì¬í˜„ì„±ì´ ë†’ê³ , íš¨ìœ¨ì ì´ë¼ëŠ” ì ì´ íŠ¹ì§•ì¸ë°ìš”. NATì—ì„œëŠ” ì¶”ê°€ì ì¸ ì•„í‚¤í…ì²˜ ì„œì¹˜ ê³¼ì •ì´ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— í•™ìŠµì‹œê°„ê³¼ GPU ìì› ì†Œëª¨ê°€ í°ë° ë°˜í•´, ë³¸ ë°©ë²•ë¡ ì€ ì•„í‚¤í…ì²˜ ì„œì¹˜ì™€ ëª¨ë¸ í•™ìŠµì„ ë™ì‹œì— ì§„í–‰í•˜ì—¬ ìì›ì„ í¬ê²Œ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë˜í•œ, í•˜ë‚˜ì˜ ì…€(cell) ë‹¨ìœ„ê°€ ì•„ë‹Œ ë‹¤ì–‘í•œ ì…€ ì•„í‚¤í…ì²˜ë¥¼ ê°€ì§„ ë§¤í¬ë¡œë¸”ë¡(macroblock) ê¸°ë°˜ íƒìƒ‰ìœ¼ë¡œ ì „ì²´ ë²”ìœ„ë¥¼ íƒìƒ‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ë¿ë§Œ ì•„ë‹ˆë¼, ì§€ë„í•™ìŠµ(Supervised Learning)ê³¼ ìê¸°ì§€ë„í•™ìŠµ(Self-Supervised Learning)ì— ëª¨ë‘ ì ìš©ë  ìˆ˜ ìˆì–´ í™œìš©ë„ê°€ ë†’ì€ë°ìš”.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-PNAA/001.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;ê·¸ë¦¼1. Proxyless Neural Architecture Adaption ë°©ë²•ë¡ ì„ ì ìš©í•œ ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ ê²€ìƒ‰ êµ¬ì¡°&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-ì„±ëŠ¥-ë¹„êµ&quot;&gt;3. ì„±ëŠ¥ ë¹„êµ&lt;/h1&gt;

&lt;p&gt;ì´ ë°©ë²•ë¡ ì˜ ì„±ëŠ¥ê³¼ ê´‘ë²”ìœ„í•œ ì¬í˜„ì„±ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ &lt;strong&gt;CIFAR-10&lt;/strong&gt;ê³¼ &lt;strong&gt;Tiny Imagenet&lt;/strong&gt; ë°ì´í„°ì…‹ì— ì—¬ëŸ¬ê°€ì§€ ëª¨ë¸ë¡œ ì‹¤í—˜ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë¨¼ì € ì§€ë„í•™ìŠµ í™˜ê²½ì—ì„œ ìˆ˜ì‘ì—…ìœ¼ë¡œ ì„¤ê³„ëœ Resnet20ê³¼ MobilentV2, NAS ëª¨ë¸ì¸ DARTSì™€ Proxyless NAS ëª¨ë¸ì„ í™œìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. ê¸°ì¡´ ë°©ì‹ê³¼ NAT, ë³¸ ë°©ë²•ë¡ ìœ¼ë¡œ ì‹¤í—˜ì„ ì§„í–‰í•œ ê²°ê³¼, [í‘œ1]ê³¼ ê°™ì´ ë‹¤ì–‘í•œ ì•„í‚¤í…ì²˜ì—ì„œ ê¸°ì¡´ ë°©ë²•ë¡  ëŒ€ë¹„ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë”ë¶ˆì–´ ì „ì²´ì ì¸ ì—°ì‚°ë¹„ìš© ì¸¡ë©´ì—ì„œë„ NATê³¼ ë¹„êµí•´ ë” ì ì€ ë¹„ìš©ì„ ì‚¬ìš©í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-PNAA/002.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;í‘œ1. ì§€ë„í•™ìŠµì—ì„œì˜ í‰ê·  ì •í™•ë„, í‘œì¤€í¸ì°¨, ì—°ì‚°ì‹œê°„ ë¹„êµ (CIFAR-10 ê¸°ì¤€)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;í‘œ2ì—ì„œëŠ” ë§ˆì°¬ê°€ì§€ë¡œ CIFAR-10 ë°ì´í„°ì…‹ ìƒì—ì„œ 5ë²ˆì˜ ë¬´ì‘ìœ„ ì‹œë„ë¥¼ ê±°ì³ ì¬í˜„ì„±ì„ í…ŒìŠ¤íŠ¸ ì§„í–‰í•˜ì˜€ê³ , ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-PNAA/003.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;í‘œ2. ì§€ë„í•™ìŠµì—ì„œì˜ ì¬í˜„ì„± ë¹„êµ (CIFAR-10 ê¸°ì¤€)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-PNAA/004.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;í‘œ3. ì§€ë„í•™ìŠµì—ì„œì˜ í‰ê·  ì •í™•ë„, í‘œì¤€í¸ì°¨, ì—°ì‚°ì‹œê°„ ë¹„êµ (Tiny Imagenet ê¸°ì¤€)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;ë˜í•œ, ìê¸°ì§€ë„í•™ìŠµ í™˜ê²½ì—ì„œë„ ì„±ëŠ¥ì„ í™•ì¸í•˜ê¸° ìœ„í•´ NASëª¨ë¸ì¸ DARTSì™€ Proxyless NASì— ì¶”ê°€ì ì¸ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ì˜€ê³ , ì—¬ê¸°ì—ì„œë„ ê¸°ì¡´ ë°©ì‹ ëŒ€ë¹„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-PNAA/005.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;í‘œ4. ìê¸°ì§€ë„í•™ìŠµì—ì„œì˜ ì •í™•ë„ ë¹„êµ (CIFAR-10 ê¸°ì¤€)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-í–¥í›„-ì—°êµ¬-ê³„íš&quot;&gt;4. í–¥í›„ ì—°êµ¬ ê³„íš&lt;/h1&gt;

&lt;p&gt;ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ ì—°êµ¬íŒ€ì€ í•´ë‹¹ ë°©ë²•ë¡ ì„ í™œìš©í•˜ì—¬ ì •í™•ë„ë¥¼ ë„˜ì–´, ê²°ê³¼ê°€ ë„ì¶œë˜ëŠ” ì‹œê°„, ì†ë„(latency)ê¹Œì§€ ê³ ë ¤í•œ ëª¨ë¸ì„ ë§Œë“¤ê³ ì í•©ë‹ˆë‹¤. íŠ¹íˆ ì»´í“¨í„°ë¹„ì „ ë¶„ì•¼ ì—°êµ¬ì— ì ìš©í•´ ìµœì ì˜ ëª¨ë¸ êµ¬ì¡°ë¥¼ ë¹ ë¥´ê³ , ì €ë¹„ìš©ìœ¼ë¡œ íƒìƒ‰í•˜ëŠ” ë°ì— ì¤‘ì ì„ ë‘˜ ê³„íšì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì•ìœ¼ë¡œë„ ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆì˜ AI ì—°êµ¬ì— ë§ì€ ê´€ì‹¬ ë¶€íƒë“œë¦¬ë©°, &lt;strong&gt;ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ AI Lab &amp;amp; Service&lt;/strong&gt;ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹œë‹¤ë©´ ì•„ë˜ ë§í¬ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”!&lt;/p&gt;

&lt;p&gt;ğŸ‘¨ğŸ»â€ğŸ’» &lt;a href=&quot;http://kko.to/ailab_career&quot;&gt;ì¸ì¬ì˜ì…&lt;/a&gt;&lt;/p&gt;</content><author><name>ê¹€ë„êµ­:ì¸í•˜ëŒ€í•™êµ</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">APEACH: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets</title><link href="https://kakaoenterprise.github.io/papers/arxiv-apeach" rel="alternate" type="text/html" title="APEACH: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets" /><published>2022-02-25T00:00:00-06:00</published><updated>2022-02-25T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/arxiv-apeach</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/arxiv-apeach">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Detecting toxic or pejorative expressions in online communities has become one of the main concerns for preventing the usersâ€™ men- tal harm. This led to the development of large- scale hate speech detection datasets of var- ious domains, which are mainly built upon web-crawled texts with labels by crowdwork- ers. However, for languages other than English, researchers might have to rely on only a small- sized corpus due to the lack of data-driven re- search of hate speech detection. This some- times misleads the evaluation of prevalently used pretrained language models (PLMs) such as BERT, given that PLMs often share the do- main of pretraining corpus with the evaluation set, resulting in over-representation of the de- tection performance. Also, the scope of pejo- rative expressions might be restricted if the dataset is built on a single domain text.&lt;/p&gt;

&lt;p&gt;To alleviate the above problems in Korean hate speech detection, we propose APEACH, a method that allows the collection of hate speech generated by unspecified users. By con- trolling the crowd-generation of hate speech and adding only a minimum post-labeling, we create a corpus that enables the general- izable and fair evaluation of hate speech de- tection regarding text domain and topic. We compare our outcome with prior work on an annotation-based toxic news comment dataset using publicly available PLMs. We check that our dataset is less sensitive to the lexical over- lap between the evaluation set and pretraining corpus of PLMs, showing that it helps mitigate the unexpected under/over-representation of model performance. We distribute our dataset publicly online to further facilitate the general- domain hate speech detection in Korean.&lt;/p&gt;</content><author><name>ì–‘ê¸°ì°½:ì¹´ì¹´ì˜¤, ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ, ìˆ­ì‹¤ëŒ€</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness</title><link href="https://kakaoenterprise.github.io/papers/neurips-smoothmix" rel="alternate" type="text/html" title="SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness" /><published>2021-12-06T00:00:00-06:00</published><updated>2021-12-06T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/neurips-smoothmix</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/neurips-smoothmix">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Randomized smoothing is currently a state-of-the-art method to construct a certifiably robust classifier from neural networks against \(l_{2}\)-adversarial perturbations. Under the paradigm, the robustness of a classifier is aligned with the prediction confidence, i.e., the higher confidence from a smoothed classifier implies the better robustness. This motivates us to rethink the fundamental trade-off between accuracy and robustness in terms of calibrating confidences of smoothed classifier. In this paper, we propose a simple training scheme, coined SmoothMix, to control the robustness of smoothed classifiers via self-mixup: it trains convex combinations of samples along the direction of adversarial perturbation for each input. The proposed procedure effectively identifies over-confident, near off-class samples as a cause of limited robustness in case of smoothed classifiers, and offers an intuitive way to adaptively set a new decision boundary between these samples for better robustness. Our experimental results demonstrate that the proposed method can significantly improve the certified \(l_{2}\)-robustness of smoothed classifiers compared to existing state-of-the-art robust training methods.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;ë³¸ ê¸€ì—ì„œëŠ” ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆì™€ ì¹´ì´ìŠ¤íŠ¸, Vector Institute ê³µë™ ì—°êµ¬íŒ€ì´ ê°•ê±´í•œ ë¶„ë¥˜ê¸° êµ¬ì¶•ì„ ìœ„í•´, ìƒˆë¡­ê²Œ ì œì•ˆí•˜ëŠ” ì ëŒ€ì  í•™ìŠµ(adversarial training) ê¸°ë²•ì„ ì†Œê°œë“œë¦¬ë ¤ê³  í•©ë‹ˆë‹¤. í•´ë‹¹ ì—°êµ¬ ê²°ê³¼ëŠ” NeurIPS 2021 í•™íšŒë¥¼ í†µí•´ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-ì ëŒ€ì -í•™ìŠµ-ê¸°ë²•ì˜-í•„ìš”ì„±&quot;&gt;1. ì ëŒ€ì  í•™ìŠµ ê¸°ë²•ì˜ í•„ìš”ì„±&lt;/h1&gt;

&lt;p&gt;ì¼ë°˜ì ìœ¼ë¡œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ í›ˆë ¨ ê³¼ì •ì—ì„œ ì˜ˆì¸¡ê°’ì— ëŒ€í•´ ê³¼ì‰ í™•ì‹ (over-confidence)ì„ ê°€ì§€ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ í‹€ë¦° ë‹µì„ ì •ë‹µìœ¼ë¡œ ê°„ì£¼í•˜ëŠ” í° ë¬¸ì œë¥¼ ì•¼ê¸°í•  ìˆ˜ ìˆëŠ”ë°ìš”. ì´ê°™ì€ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì ëŒ€ì  í•™ìŠµ ê¸°ë²•ì´ ë“±ì¥í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì ëŒ€ì  í•™ìŠµ ê¸°ë²•ì€ ì›ë³¸ ë°ì´í„°ì— ìµœì ì˜ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•œ ì ëŒ€ì  ìƒ˜í”Œì„ í†µí•´, ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ì˜¤ì˜ˆì¸¡ì„ ìœ ë„í•˜ëŠ” í›ˆë ¨ ë°©ë²•ë¡ ì…ë‹ˆë‹¤. ì‹¤ì œ ì‚¬ëŒì´ ë³´ê¸°ì—ëŠ” í¬ê²Œ ë¬¸ì œê°€ ì—†ëŠ” ìˆ˜ì¤€ì˜ ë…¸ì´ì¦ˆë”ë¼ë„, ë…¸ì´ì¦ˆë¡œ ì¸í•´ ì™œê³¡ëœ ì´ë¯¸ì§€ëŠ” ëª¨ë¸ ì˜ˆì¸¡ì— ì•…ì˜í–¥ì„ ë¼ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ì²˜ëŸ¼ ì˜ˆì¸¡ì´ ì–´ë ¤ìš´ ì ëŒ€ì  ìƒ˜í”Œì„ í†µí•´ í•™ìŠµì„ ì§„í–‰í•˜ê³ , ì´ë¥¼ ë°©ì–´í•˜ê¸° ìœ„í•œ ëª©ì í•¨ìˆ˜ë¥¼ ì¡°ì •í•˜ëŠ” ì ëŒ€ì  í•™ìŠµ ê¸°ë²•ì„ í™œìš©í•´ ì •í™•ë„ë¥¼ í•œì¸µ ë†’ì¸ ê°•ê±´í•œ ë¶„ë¥˜ê¸°ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/001.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;ê·¸ë¦¼1. ë§¨ ì™¼ìª½ ê·¸ë¦¼ì€ 57.7%ì˜ confidenceë¡œ íŒë‹¤ë¼ê³  ì¸ì‹í•˜ì§€ë§Œ, ì¤‘ê°„ì— ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•œ ì˜¤ë¥¸ìª½ ê·¸ë¦¼ì€ ìœ ê´€ìƒìœ¼ë¡œëŠ” ê°™ì€ ê·¸ë¦¼ ê°™ì•„ ë³´ì´ì§€ë§Œ ëª¨ë¸ì€ 99.3%ì˜ confidenceë¡œ ê¸´íŒ”ì›ìˆ­ì´ë¡œ ë¶„ë¥˜í•˜ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [Goodfellow et al., 2014]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-ê¸°ì¡´-ì ëŒ€ì -í•™ìŠµ-ê¸°ë²•-ì—°êµ¬ì˜-í•œê³„&quot;&gt;2. ê¸°ì¡´ ì ëŒ€ì  í•™ìŠµ ê¸°ë²• ì—°êµ¬ì˜ í•œê³„&lt;/h1&gt;

&lt;p&gt;ê¸°ì¡´ ì—°êµ¬ë“¤ì€ í•™ìŠµ ê³¼ì •ì—ì„œ ì ëŒ€ì  ì…ë ¥ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì¦ê°•í•˜ëŠ” í•™ìŠµ ê¸°ë²• [Madry et al., 2018]ì„ ë„ë¦¬ ì‚¬ìš©í•´ ì™”ìŠµë‹ˆë‹¤. ì´ì— ë¹„í•´ ê°€ìš°ì‹œì•ˆ(Gaussian) ëœë¤ë³€ìˆ˜ë¥¼ í‘œë°©í•œ ë¬´ì‘ìœ„ í‰í™œí™”(randomized smoothing) ê¸°ë²•ì€ ì¶©ë¶„íˆ ì—°êµ¬ë˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë¬´ì‘ìœ„ í‰í™œí™” ê¸°ë²•ì€ í˜„ì¬ ê°€ì¥ ê°•ë ¥í•œ perturbationìœ¼ë¡œ ì•Œë ¤ì§„ \(l_{2}\) adversarial perturbationsì—ë„ ê°•ê±´í•œ ë¶„ë¥˜ ì„±ëŠ¥ì„ ë³´ì´ëŠ” SOTA(State-of-the-art) ë°©ë²•ë¡ ì…ë‹ˆë‹¤. ìµœê·¼ ë“±ì¥í•œ SmoothAdv ë°©ë²•ë¡  [Salman et al., 2019]ì€ ë¬´ì‘ìœ„ í‰í™œí™” ê¸°ë°˜ ë¶„ë¥˜ê¸°ì— ì§ì ‘ì ìœ¼ë¡œ ì ëŒ€ì  í•™ìŠµì„ ì ìš©í•´, ëª¨ë¸ ì„±ëŠ¥ì´ í–¥ìƒë  ìˆ˜ ìˆìŒì„ ë³´ì˜€ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, ì´ëŠ” ì´ë¯¸ ì§€ì—­ì ìœ¼ë¡œ ê°•ì¸ì„±ì„ í™•ë³´í•˜ê³  ìˆëŠ” í‰í™œ ë¶„ë¥˜ê¸°ì— ì—¬ì „íˆ ê¸°ì¡´ ë°©ë²•ë¡ ì˜ ì§€ì—­ì  ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ëŠ” ë“± ì¼ë°˜ ë¶„ë¥˜ê¸°ì™€ì˜ ì°¨ì´ë¥¼ ê³ ë ¤í•˜ì§€ ëª»í–ˆë‹¤ëŠ” í•œê³„ê°€ ìˆì—ˆëŠ”ë°ìš”. ì´ì— ë³¸ ì—°êµ¬íŒ€ì€ í‰í™œí™” ê¸°ë°˜ ë¶„ë¥˜ê¸°ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ ì ëŒ€ì  í•™ìŠµ ê¸°ë²•ì„ ìƒˆë¡­ê²Œ ì œì•ˆí•˜ê³ ì í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/002.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;ê·¸ë¦¼2. ê¸°ì¡´ ì ëŒ€ì  í•™ìŠµ ê¸°ë²•(a, b)ê³¼ ì œì•ˆ ë°©ë²•ë¡ (c)ì— ëŒ€í•œ ì‹œê°í™”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-smoothmix-ë°©ë²•ë¡ -ì†Œê°œ&quot;&gt;3. SmoothMix ë°©ë²•ë¡  ì†Œê°œ&lt;/h1&gt;

&lt;p&gt;SmoothMixì˜ ê°€ì¥ í° íŠ¹ì§•ì€ ì ëŒ€ì  ì…ë ¥ íƒìƒ‰ì—ì„œ ì§€ì—­ì  ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³ , í•´ë‹¹ ì…ë ¥ê°’ê³¼ ì›ë³¸ ì…ë ¥ê°’ ê°„ì˜ mixup í•™ìŠµ êµ¬ì¡°ë¥¼ ê°€ì§„ë‹¤ëŠ” ì ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ë¥¼ ìì„¸íˆ ì‚´í´ë³´ë©´, SmootMixëŠ” ê¸°ì¡´ ì ëŒ€ì  í•™ìŠµ ê¸°ë²•ì—ì„œ ì‚¬ìš©ë˜ì—ˆë˜ ì œí•œëœ Îµ-ball ë‚´ë¶€ì—ì„œì˜ ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ëŒ€ì‹ , ì£¼ì–´ì§„ ì…ë ¥ x ì£¼ë³€ì˜ over-confidentí•œ ì…ë ¥ì„ ì°¾ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/003.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì´ë•Œ over-confident ì…ë ¥ê°’ì„ í•™ìŠµì— ì ìš©í•˜ê¸° ìœ„í•´, confidence ê°’ì„ uniform predictionìœ¼ë¡œ penalizeí•˜ëŠ”ë°ìš”. í•´ë‹¹ ê°’ê³¼ ì›ë³¸ ì…ë ¥ê°’ ê°„ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•˜ì—¬ mixup [Zhang et al., 2017] ëª©ì í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” ì •ê·œí™” ê¸°ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‘ ì…ë ¥ê°’ ê°„ì˜ confidenceë¥¼ ì¡°ì •í•˜ì—¬ ê¸°ì¡´ ì ëŒ€ì  í•™ìŠµ ê¸°ë²• ëŒ€ë¹„ ë¶„ë¥˜ê¸°ì˜ ê°•ê±´í•¨ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/004.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/005.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ë˜í•œ, SmoothMixëŠ” SmoothAdv ê¸°ë²•ì„ í†µí•´ íš¨ê³¼ë¥¼ ì…ì¦í•œ mixup ëª©ì í•¨ìˆ˜ì— â€˜single-step adversarial exampleâ€™ ê¸°ë²•ì„ ì¶”ê°€ ì œì•ˆí•˜ì—¬ ë”ìš± ê°•ê±´í•œ ë¶„ë¥˜ê¸° êµ¬ì¡°ë¥¼ êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-ì„±ëŠ¥-í‰ê°€&quot;&gt;4. ì„±ëŠ¥ í‰ê°€&lt;/h1&gt;

&lt;p&gt;í•´ë‹¹ ë°©ë²•ë¡ ì€ &lt;strong&gt;MNIST, CIFAR-10, ImagNet&lt;/strong&gt; ë“±ì˜ ì´ë¯¸ì§€ ë¶„ë¥˜ ë°ì´í„°ì…‹ì—ì„œ ê¸°ì¡´ ë°©ë²•ë¡  ëŒ€ë¹„ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. íŠ¹íˆ ëª¨ë¸ì˜ ì •í™•ë„ì™€ ê°•ì¸ì„±ì˜ ìµœì  ì •ë„ë¥¼ ë³´ì—¬ì£¼ëŠ” ACR(Average Certified Radius) ìˆ˜ì¹˜ë¥¼ í‰ê°€í•˜ì˜€ê³ , ì•„ë˜ í‘œ2, í‘œ3ê³¼ ê°™ì´ í˜„ì¬ SOTA(State-of-the-art)ì™€ ë¹„êµí•´ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/006.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;í‘œ1. ê¸°ì¡´ ë°©ë²•ë¡ ê³¼ì˜ ì„±ëŠ¥ ë¹„êµ (MNIST ë°ì´í„°ì…‹ ê¸°ì¤€)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/007.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;í‘œ2. ê¸°ì¡´ ë°©ë²•ë¡ ê³¼ì˜ ì„±ëŠ¥ ë¹„êµ (CIFAR-10 ë°ì´í„°ì…‹ ê¸°ì¤€)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-smoothmix/008.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;í‘œ3. ê¸°ì¡´ ë°©ë²•ë¡ ê³¼ì˜ ì„±ëŠ¥ ë¹„êµ (ImageNet ë°ì´í„°ì…‹ ê¸°ì¤€)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5-í–¥í›„-ì—°êµ¬-ê³„íš&quot;&gt;5. í–¥í›„ ì—°êµ¬ ê³„íš&lt;/h1&gt;

&lt;p&gt;ì ëŒ€ì  í•™ìŠµ ê¸°ë²•ì€ ë…¸ì´ì¦ˆì— ê°•ë ¥í•œ ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ”ë° í° ì—­í• ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ëª¨ë¸ì´ ì²˜ìŒ ë³´ëŠ” ì‹¤ì„œë¹„ìŠ¤ ë°ì´í„°ì—ì„œë„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì¼ ìˆ˜ ìˆëŠ”ë°ìš”. ì´ ê¸°ë²•ì€ ë‹¤ì–‘í•œ AI ë¶„ì•¼ì— í™œìš©ì´ ê°€ëŠ¥í•˜ì§€ë§Œ, íŠ¹íˆ ììœ¨ì£¼í–‰ì°¨, ì˜ë£Œ ì‹œìŠ¤í…œ ë“± ë†’ì€ ì •í™•ë„ë¥¼ ìš”êµ¬í•˜ëŠ” ì˜ì—­ì—ì„œ ì˜¤íŒë‹¨ì„ ì¤„ì—¬ ê·¸ ì„±ëŠ¥ì„ í¬ê²Œ ë°œíœ˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;í–¥í›„ ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ ì—°êµ¬íŒ€ì€ í•´ë‹¹ ë°©ë²•ë¡ ì„ ê¸°ë°˜ìœ¼ë¡œ ì—¬ëŸ¬ê°€ì§€ ì»´í“¨í„° ë¹„ì „ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , ì„œë¹„ìŠ¤ë¥¼ ê³ ë„í™”í•´ ë‚˜ê°ˆ ê³„íšì…ë‹ˆë‹¤. ì•ìœ¼ë¡œë„ ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ ì—°êµ¬ì— ë§ì€ ê´€ì‹¬ê³¼ ì‘ì› ë¶€íƒë“œë¦½ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;ì°¸ê³ ë¬¸í—Œ&quot;&gt;ì°¸ê³ ë¬¸í—Œ&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;[Goodfellow et al., 2014] Explaining and harnessing adversarial examples. arXiv 2014.&lt;/li&gt;
  &lt;li&gt;[Madry et al., 2018] Towards Deep Learning Models Resistant to Adversarial Attacks, ICLR 2018.&lt;/li&gt;
  &lt;li&gt;[Salman et al., 2019] Provably robust deep learning via adversarially trained smoothed classifiers, NeurIPS 2019.&lt;/li&gt;
  &lt;li&gt;[Zhang et al., 2017] mixup: Beyond Empirical Risk Minimization, ICLR 2018.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;í˜„ì¬ ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ AI Labì—ì„œëŠ” ë‹¤ì–‘í•œ AI ì—°êµ¬ì™€ ì„œë¹„ìŠ¤í™”ë¥¼ í•¨ê»˜ ê³ ë¯¼í•´ë‚˜ê°ˆ ì—¬ëŸ¬ë¶„ì˜ ì§€ì›ì„ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤. AIë¥¼ í†µí•´ ë”ìš± ê°€ì¹˜ìˆëŠ” ì„¸ìƒì„ ë§Œë“¤ê³ , ê¿ˆì„ í˜„ì‹¤ë¡œ ë§Œë“¤ì–´ê°€ëŠ” ì—¬ì •ì— í•¨ê»˜í•˜ì„¸ìš”!&lt;/p&gt;

&lt;p&gt;ğŸ‘¨ğŸ»â€ğŸ’» &lt;a href=&quot;http://kko.to/ailab_career&quot;&gt;ì¸ì¬ì˜ì…&lt;/a&gt;&lt;/p&gt;</content><author><name>ì •ì¢…í˜„:ì¹´ì´ìŠ¤íŠ¸</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Learning Debiased Representation via Disentangled Feature Augmentation</title><link href="https://kakaoenterprise.github.io/papers/neurips-learning-debiased-representation" rel="alternate" type="text/html" title="Learning Debiased Representation via Disentangled Feature Augmentation" /><published>2021-12-06T00:00:00-06:00</published><updated>2021-12-06T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/neurips-learning-debiased-representation</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/neurips-learning-debiased-representation">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Image classification models tend to make decisions based on peripheral attributes of data items that have strong correlation with a target variable (i.e., dataset bias). These biased models suffer from the poor generalization capability when evaluated on unbiased datasets. Existing approaches for debiasing often identify and emphasize those samples with no such correlation (i.e., bias-conflicting) without defining the bias type in advance. However, such bias-conflicting samples are significantly scarce in biased datasets, limiting the debiasing capability of these approaches. This paper first presents an empirical analysis revealing that training with â€œdiverseâ€ bias-conflicting samples beyond a given training set is crucial for debiasing as well as the generalization capability. Based on this observation, we propose a novel feature-level data augmentation technique in order to synthesize diverse bias-conflicting samples. To this end, our method learns the disentangled representation of (1) the intrinsic attributes (i.e., those inherently defining a certain class) and (2) bias attributes (i.e., peripheral attributes causing the bias), from a large number of bias-aligned samples, the bias attributes of which have strong correlation with the target variable. Using the disentangled representation, we synthesize bias-conflicting samples that contain the diverse intrinsic attributes of bias-aligned samples by swapping their latent features. By utilizing these diversified bias-conflicting features during the training, our approach achieves superior classification accuracy and debiasing results against the existing baselines on both synthetic as well as real-world datasets.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;ë³¸ ê¸€ì—ì„œëŠ” ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆì™€ ì¹´ì´ìŠ¤íŠ¸ ê³µë™ ì—°êµ¬íŒ€ì´ ë°ì´í„°ì…‹ì˜ í¸í–¥(bias) ë¬¸ì œë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ìƒˆë¡­ê²Œ ì œì•ˆí•œ ë°ì´í„° ì¦ê°•(data augmentation) ê¸°ë²•ì„ ì†Œê°œë“œë¦¬ê³ ì í•©ë‹ˆë‹¤. í•´ë‹¹ ì—°êµ¬ ê²°ê³¼ëŠ” NeurIPS 2021 í•™íšŒì—ì„œ oral presentationì„ í†µí•´ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-ê¸°ì¡´-í¸í–¥ì„±-ê°œì„ -ì—°êµ¬ì˜-í•œê³„&quot;&gt;1. ê¸°ì¡´ í¸í–¥ì„± ê°œì„  ì—°êµ¬ì˜ í•œê³„&lt;/h1&gt;

&lt;p&gt;ë°ì´í„°ì…‹ì˜ í¸í–¥ ë¬¸ì œëŠ” ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì˜ í•™ìŠµ ê³¼ì •ì—ì„œ í”í•˜ê²Œ ë°œìƒë©ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ìˆ˜ì§‘, ê°€ê³µí•˜ëŠ” ê³¼ì •ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì¡´ì¬í•˜ê²Œ ë˜ëŠ” biasë¡œ ì¸í•´, ëª¨ë¸ì˜ ì„±ëŠ¥ì´ í¬ê²Œ ì¢Œìš°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ í›ˆë ¨ ê³¼ì •ì—ì„œëŠ” ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì˜€ë˜ ëª¨ë¸ì´ ì‹¤ì œ í¸í–¥ë˜ì§€ ì•Šì€ ë°ì´í„°ì…‹ì— ì ìš©ë  ë•Œ, ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì¼ ìˆ˜ ìˆëŠ”ë°ìš”. ì˜ˆë¥¼ ë“¤ì–´ â€˜ìƒˆâ€™ ì´ë¯¸ì§€ë¥¼ í•™ìŠµí•˜ëŠ” ê³¼ì •ì—ì„œ í•™ìŠµí•œ ëª¨ë“  ì´ë¯¸ì§€ì— â€˜í•˜ëŠ˜â€™ì´ ìˆì—ˆë‹¤ë©´, í•˜ëŠ˜ê³¼ í•¨ê»˜ ìˆëŠ” ë¬¼ì²´ë§Œ ìƒˆë¡œ ì¸ì‹í•˜ì—¬ â€˜ë•…â€™ ë˜ëŠ” â€˜í’€â€™ ìœ„ì— ìˆëŠ” ìƒˆëŠ” ë¶„ë¥˜ì— ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•™ìŠµìì˜ ì˜ë„ì™€ ê´€ê³„ ì—†ì´, ë°ì´í„°ì…‹ ìì²´ì— ì¡´ì¬í•˜ëŠ” í¸í–¥ì„±ì— ì˜í•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆëŠ”ê±´ë°ìš”.&lt;/p&gt;

&lt;p&gt;ê¸°ì¡´ ì—°êµ¬ë“¤ì€ ì´ëŸ¬í•œ í¸í–¥ì„±ì„ ì œê±°í•˜ê¸° ìœ„í•´, í¸í–¥ì„±ì„ ì œê±°í•œ ìƒ˜í”Œ(bias-conflicting sample)ì„ ì¶”ê°€í•˜ê±°ë‚˜, ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ëŠ” ë°©ì‹ì„ í™œìš©í–ˆìŠµë‹ˆë‹¤. ì‚¬ì‹¤ìƒ bias-conflicting ìƒ˜í”Œì„ ìˆ˜ì§‘í•˜ëŠ” ë°ì—ëŠ” ë¬¼ë¦¬ì , ì‹œê°„ì  ì–´ë ¤ì›€ì´ ìˆê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ ë°©ì‹ì—ëŠ” í•œê³„ê°€ ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-ë‹¤ì–‘í•œ-bias-conflicting-ìƒ˜í”Œì˜-ì¤‘ìš”ì„±&quot;&gt;2. ë‹¤ì–‘í•œ bias-conflicting ìƒ˜í”Œì˜ ì¤‘ìš”ì„±&lt;/h1&gt;

&lt;p&gt;ë”¥ëŸ¬ë‹ í•™ìŠµì— ìˆì–´ ì•Œê³ ë¦¬ì¦˜ ì´ìƒìœ¼ë¡œ ì¤‘ìš”í•œ ê²ƒì€ ë°”ë¡œ ë°ì´í„°ì˜ ì–‘ì…ë‹ˆë‹¤. ë§ì€ ë°ì´í„°ë¥¼ ì˜ í™œìš©í•˜ëŠ” ê²ƒì´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¢Œìš°í•˜ëŠ”ë°ìš”. ì´ì— ê³µë™ ì—°êµ¬íŒ€ì€ í¸í–¥ì„± ê°œì„ ì„ ìœ„í•´ì„œëŠ” â€˜ë‹¤ì–‘í•œ bias-conficting ìƒ˜í”Œì„ ë§ì´ í™œìš©í•˜ëŠ” ê²ƒì´ ëª¨ë¸ í•™ìŠµì— íš¨ê³¼ì â€™ì´ë¼ëŠ” ê°€ì„¤ì„ ê°€ì§€ê³ , ì´ë¥¼ ê²€ì¦í•˜ê¸° ìœ„í•œ í† ì´ì…‹(toy-set) ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë¨¼ì € í›ˆë ¨ ê³¼ì •ì—ëŠ” ê·¸ë¦¼1ê³¼ ê°™ì´ ë‘ ê°€ì§€ ë°ì´í„°ì…‹(Colored MNIST, Corrupted CIFAR-10)ì„ í™œìš©í•˜ì˜€ìŠµë‹ˆë‹¤. í•˜ë‚˜ëŠ” ê¸°ì¡´ MNIST ë°ì´í„°ì…‹ì—ì„œ ìˆ«ìì— íŠ¹ì • ìƒ‰ìƒì´ ìì£¼ ë‚˜ì˜¤ë„ë¡ ìƒ‰ìƒ biasë¥¼ ì„¤ì •í•œ Colored MNISTì´ê³ , ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ê¸°ì¡´ CIFAR-10 ë°ì´í„°ì…‹ì—ì„œ ì‚¬ë¬¼ì— íŠ¹ì • í…ìŠ¤ì³(Corruption)ê°€ ë°˜ë³µë˜ë„ë¡ í…ìŠ¤ì³ biasë¥¼ ë³€í˜•í•œ Corrupted CIFAR-10ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-Learning Debiased Representation/001.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;ê·¸ë¦¼1. ë°ì´í„°ì…‹ í˜•íƒœ
(ì ì„  ìœ„ëŠ” ê¸°ì¡´ bias-aligned ìƒ˜í”Œì´ë©°, ì ì„  ì•„ë˜ëŠ” bias-conflicting ìƒ˜í”Œì„)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;ì•„ë˜ í‘œ1ì€ í•´ë‹¹ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•œ ëª¨ë¸ì— í¸í–¥ì„±ì´ ì—†ëŠ” í…ŒìŠ¤íŠ¸ì…‹(unbiased test sets)ì„ ì ìš©í–ˆì„ ë•Œì˜ ë¶„ë¥˜ ì •í™•ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë‹¤ì–‘í•œ bias-conflicting ìƒ˜í”Œì„ í•™ìŠµì— ë§ì´ í™œìš©í•œ ê²½ìš°ê°€ ê°€ì¥ ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ì£¼ëª©í•  ì ì€ ë°”ë¡œ ìƒ˜í”Œë§ ë¹„ìœ¨ë³´ë‹¤ ë‹¤ì–‘ì„± ë¹„ìœ¨ì´ ë†’ì•˜ì„ ë•Œ, ìƒëŒ€ì ìœ¼ë¡œ ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì˜€ë‹¤ëŠ” ì ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-Learning Debiased Representation/002.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;í‘œ1. í¸í–¥ì„±ì´ ì—†ëŠ” í…ŒìŠ¤íŠ¸ì…‹(unbiased test sets)ì—ì„œì˜ ë¶„ë¥˜ ì •í™•ë„&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;ì´ë¥¼ í†µí•´ ë³¸ ì—°êµ¬íŒ€ì€ ë‹¤ì–‘í•œ bias-conflicting ìƒ˜í”Œì˜ í™œìš©ì´ í¸í–¥ ì œê±°ì— íš¨ê³¼ê°€ ìˆë‹¤ëŠ” ê°€ì„¤ì„ ê²€ì¦í•˜ì˜€ê³ ,  bias-conflicting ìƒ˜í”Œ ë°ì´í„°ì˜ ì¦ê°•ì„ í†µí•´ í¸í–¥ì„±ì„ ê°œì„ í•œ ë°©ë²•ë¡ ì„ ì œì•ˆí•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-debiasing-via-disentangled-feature-augmentation-ë°©ë²•ë¡ -ì†Œê°œ&quot;&gt;3. Debiasing via disentangled feature augmentation ë°©ë²•ë¡  ì†Œê°œ&lt;/h1&gt;

&lt;p&gt;í•´ë‹¹ ë°©ë²•ë¡ ì˜ ê°€ì¥ í° íŠ¹ì§•ì€ ê° ì´ë¯¸ì§€ê°€ ê°€ì§„ ê³ ìœ ì†ì„±ê³¼ í¸í–¥ì†ì„±ì„ êµì°¨í•©ì„±í•˜ì—¬ ë°ì´í„°ë¥¼ ì¦ê°•ì‹œì¼°ë‹¤ëŠ” ì ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì „ì²´ êµ¬ì¡°ë¥¼ ì‚´í´ë³´ë©´ ê°ê° ê³ ìœ ì†ì„±(\(E_{i}\)), í¸í–¥ì†ì„±(\(E_{b}\))ìœ¼ë¡œ êµ¬ë¶„ë˜ëŠ” 2ê°œì˜ ì¸ì½”ë”ê°€ ìˆìŠµë‹ˆë‹¤. í•˜ë‚˜ì˜ ì´ë¯¸ì§€ê°€ ì…ë ¥ë˜ë©´ í•´ë‹¹ ì¸ì½”ë”ë¥¼ ê±°ì³ ê°ê° ê³ ìœ ì†ì„±ê³¼ í¸í–¥ì†ì„±ì˜ disentangled featureë¡œ \(Z_{i}\), \(Z_{b}\)ê°€ ì¶œë ¥ë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì—¬ê¸°ì„œ ê³ ìœ ì†ì„±ê³¼ í¸í–¥ì†ì„±ì˜ disentanglementë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´, ë‹¤ìŒê³¼ ê°™ì€ í•™ìŠµê³¼ì •ì„ ì§„í–‰í•©ë‹ˆë‹¤. ë¨¼ì € ê³ ìœ ì†ì„±ì„ í•™ìŠµí•˜ëŠ”ë° ì‚¬ìš©ë˜ëŠ” \(E_{b}\)ì™€ \(C_{b}\)ë¥¼ ê¸°ì¡´ ë…¼ë¬¸(Nam et al., â€œLearning from Failure: Training Debiased Classifier from Biased Classifierâ€)ì—ì„œ ì œì‹œí•œ Generalized Cross-Entropy Lossë¥¼ í†µí•´ â€œì‰¬ìš´â€ ì •ë³´ë§Œì„ í•™ìŠµí•˜ë„ë¡ ê°•ì œí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í•´ë‹¹ ì¸ì½”ë”ëŠ” ì£¼ì–´ì§„ ì´ë¯¸ì§€ë¡œë¶€í„° í¸í–¥ì†ì„±ì„ ì£¼ë¡œ ì¶”ì¶œí•˜ê²Œ ë˜ê³ , ì´ë ‡ê²Œ í¸í–¥ í•™ìŠµëœ ì¸ì½”ë”ë¡œë¶€í„° ìƒëŒ€ì ìœ¼ë¡œ í° Lossë¥¼ ê°–ê²Œ ë˜ëŠ” ì´ë¯¸ì§€ë¥¼ Bias-conflicting ìƒ˜í”Œë¡œ íŒë‹¨í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•œ ê°€ì¤‘í•™ìŠµì„ í†µí•´, \(E_{i}\)ì™€ \(C_{i}\)ëŠ” í¸í–¥ì†ì„±ì´ ì•„ë‹Œ ê³ ìœ ì†ì„±ì„ ì£¼ë¡œ ì¶”ì¶œí•˜ëŠ”ë° ì‚¬ìš©ë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ë•Œ, ì´ í•œ ìŒì˜ í”¼ì³ë“¤ì„ ë¯¸ë‹ˆë°°ì¹˜ ë‚´ ë‹¤ë¥¸ ëœë¤ ì´ë¯¸ì§€ì˜ í”¼ì³ê°’ê³¼ êµì°¨ í•©ì„±(swapping)ì„ í•¨ìœ¼ë¡œì¨ ê¸°ì¡´ ê³ ìœ ì†ì„±ê³¼ í¸í–¥ì†ì„± ê°„ì˜ ê°•í•œ ìƒê´€ê´€ê³„(correlation)ê°€ ëŠì–´ì§„ ìƒ˜í”Œì„ ìƒì„±í•  ìˆ˜ ìˆëŠ”ë°ìš”. ì´ëŠ” ê³§ í¸í–¥ì„±ì„ ê°€ì§€ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ bias-conflicting ìƒ˜í”Œì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì„ í†µí•´ ì‹¤ì œ í¸í–¥ì„± ê°œì„ ì— íš¨ê³¼ì ì¸ ìœ ì˜ë¯¸í•œ í•©ì„± ê²°ê³¼ë¬¼ì„ êµ¬í˜„í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë°ì´í„° ì¦ê°•ìœ¼ë¡œ í›ˆë ¨ ë°ì´í„°ì…‹ì˜ ë‹¤ì–‘ì„±ì„ ì¦ê°€ì‹œí‚¤ê³ , ë°ì´í„°ì˜ í’ˆì§ˆ ë˜í•œ ë†’ì—¬ ë¶„ë¥˜ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-Learning Debiased Representation/003.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;ê·¸ë¦¼2. ì „ì²´ ëª¨ë¸ì˜ êµ¬ì¡°&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-ì„±ëŠ¥-í‰ê°€&quot;&gt;4. ì„±ëŠ¥ í‰ê°€&lt;/h1&gt;

&lt;p&gt;ë³´ë‹¤ ì •ëŸ‰ì ì¸ ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•´, ì•ì„œ ì–¸ê¸‰í•œ 2ê°€ì§€ í•©ì„± ë°ì´í„°ì…‹(Colored MNIST, Corrupted CIFAR-10)ê³¼ í•¨ê»˜ BFFHQ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ BFFHQëŠ” ê¸°ì¡´ FFHQ ë°ì´í„°ì…‹ì´ ê°€ì§„ ë‚˜ì´ì™€ ì„±ë³„ í¸í–¥ì„±(ëŒ€ë‹¤ìˆ˜ ë°ì´í„°ê°€ ì Šì€ ì—¬ìì™€ ë‚˜ì´ ë“  ë‚¨ìë¡œ êµ¬ì„±ë¨)ì— ë³€í˜•ì„ ë‘” ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ ì„¸ê°€ì§€ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•œ ëª¨ë¸ì„ ê°ê° í¸í–¥ì„±ì´ ì—†ëŠ” í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ í‰ê°€í–ˆì„ ë•Œ, ì•„ë˜ í‘œ2ì™€ ê°™ì´ SOTA(State-of-the-art)ë¥¼ ë›°ì–´ë„˜ëŠ” ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„ì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤. í•´ë‹¹ ë°©ë²•ë¡ ì€ í•©ì„± ë°ì´í„°ì…‹ ë¿ë§Œ ì•„ë‹ˆë¼ ì‹¤ì„œë¹„ìŠ¤ ìƒì˜ ë°ì´í„°ì…‹ì—ë„ íš¨ê³¼ì ì´ë¼ëŠ” ì‚¬ì‹¤ì„ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-12-06-NeurIPS-Learning Debiased Representation/004.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;í‘œ2. í¸í–¥ì„±ì´ ì—†ëŠ” í…ŒìŠ¤íŠ¸ì…‹(unbiased test sets)ìœ¼ë¡œ í‰ê°€í•œ ë¶„ë¥˜ ì •í™•ë„&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5-í–¥í›„-ì—°êµ¬-ê³„íš&quot;&gt;5. í–¥í›„ ì—°êµ¬ ê³„íš&lt;/h1&gt;

&lt;p&gt;Dataset Bias ë¬¸ì œ í•´ê²°ì€ ì´ë¯¸ì§€ ì¸ì‹, ì–¼êµ´ ì¸ì‹ ë“± ì—¬ëŸ¬ ì»´í“¨í„° ë¹„ì „ ê³¼ì œë¥¼ í•´ê²°í•˜ëŠ”ë° í° ì—­í• ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì•ì„œ ì–¸ê¸‰í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì˜¤ì‹ë¥ ì„ ê°œì„ í•˜ê³ , ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë°ì—ë„ í™œìš©ë  ìˆ˜ ìˆëŠ”ë°ìš”. ë³´ë‹¤ êµ¬ì²´ì ìœ¼ë¡œëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ì„±ë³„, ì¸ì¢…, ë‚˜ì´ ë“±ê³¼ ê°™ì´ í¸í–¥ê³¼ ê´€ë ¨ëœ ì—¬ëŸ¬ ë¯¼ê°í•œ ë¬¸ì œì— ëŒ€í•´ ë³´ë‹¤ ì‹ ë¢°ì„± ë†’ì€ ì •ë‹µì„ ë„ì¶œí•  ìˆ˜ ìˆë„ë¡ ê¸°ì—¬í•  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;í–¥í›„ ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ AI Lab ë¹„ì „íŒ€ì€ í•´ë‹¹ ë°©ë²•ë¡ ì„ ê¸°ë°˜ìœ¼ë¡œ ì—¬ëŸ¬ê°€ì§€ ì»´í“¨í„° ë¹„ì „ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , ì„œë¹„ìŠ¤ë¥¼ ê³ ë„í™”í•  ê³„íšì…ë‹ˆë‹¤. ì•ìœ¼ë¡œë„ ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ ì—°êµ¬ì— ë§ì€ ê´€ì‹¬ê³¼ ì‘ì› ë¶€íƒë“œë¦½ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;í˜„ì¬ ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ AI Labì—ì„œëŠ” ë‹¤ì–‘í•œ AI ì—°êµ¬ì™€ ì„œë¹„ìŠ¤í™”ë¥¼ í•¨ê»˜ ê³ ë¯¼í•´ë‚˜ê°ˆ ì—¬ëŸ¬ë¶„ì˜ ì§€ì›ì„ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤. AIë¥¼ í†µí•´ ë”ìš± ê°€ì¹˜ìˆëŠ” ì„¸ìƒì„ ë§Œë“¤ê³ , ê¿ˆì„ í˜„ì‹¤ë¡œ ë§Œë“¤ì–´ê°€ëŠ” ì—¬ì •ì— í•¨ê»˜í•˜ì„¸ìš”!&lt;/p&gt;

&lt;p&gt;ğŸ‘¨ğŸ»â€ğŸ’» &lt;a href=&quot;http://kko.to/ailab_career&quot;&gt;ì¸ì¬ì˜ì…&lt;/a&gt;&lt;/p&gt;</content><author><name>ì´ì •ìˆ˜:ì¹´ì´ìŠ¤íŠ¸, ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Kakao Enterpriseâ€™s WMT21 Machine Translation using Terminologies Task Submission</title><link href="https://kakaoenterprise.github.io/papers/wmt21-terminology-translation" rel="alternate" type="text/html" title="Kakao Enterpriseâ€™s WMT21 Machine Translation using Terminologies Task Submission" /><published>2021-11-19T00:00:00-06:00</published><updated>2021-11-19T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/wmt21-terminology-translation</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/wmt21-terminology-translation">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;This paper describes Kakao Enterpriseâ€™s submission to the WMT21 shared Machine Translation using Terminologies task. We integrate terminology constraints by pre-training with target lemma annotations and fine-tuning with exact target annotations utilizing the given terminology dataset. This approach yields a model that achieves outstanding results in terms of both translation quality and term consistency, ranking first based on COMET in the Enâ†’Fr language direction. Furthermore, we explore various methods such as back-translation, explicitly training terminologies as additional parallel data, and in-domain data selection.&lt;/p&gt;</content><author><name>juliette:ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ</name></author><category term="papers" /><summary type="html">Abstract</summary></entry></feed>