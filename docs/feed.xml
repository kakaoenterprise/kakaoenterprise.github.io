<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://kakaoenterprise.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://kakaoenterprise.github.io/" rel="alternate" type="text/html" /><updated>2022-06-13T00:42:58-05:00</updated><id>https://kakaoenterprise.github.io/feed.xml</id><title type="html">카카오엔터프라이즈 AI Research</title><subtitle>카카오엔터프라이즈 AI Lab에서 발표한 AI 논문과 연구 성과를 소개합니다.</subtitle><author><name>카카오엔터프라이즈</name></author><entry><title type="html">Classification-based Multi-task Learning for Efficient Pose Estimation Network</title><link href="https://kakaoenterprise.github.io/papers/icpr-pose-estimation" rel="alternate" type="text/html" title="Classification-based Multi-task Learning for Efficient Pose Estimation Network" /><published>2022-08-21T00:00:00-05:00</published><updated>2022-08-21T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/ICPR-pose-estimation</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/icpr-pose-estimation">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Human pose estimation is an interesting and underlying topic in various fields such as action recognition and human-computer interaction. Although many methods have been developed recently, they are still far from perfect in accuracy and speed at a time. In this paper, we propose a Classification-based Pose Estimation Network with Multi-task Learning (CPENML) based on the low-resolution feature map to improve accuracy and inference time simultaneously. The proposed CPENML consists of two ideas. Firstly, novel proposed keypoint and offset estimation
tasks based on classification achieve better performance than regression. Secondly, the proposed Multi-Scale Network
(MSN) makes robust feature maps and balances the keypoint and offset tasks to maximize performance. To prove the effectiveness of the proposed method, we conduct ablation studies on the COCO dataset for proposed ideas. Compared to benchmarks, we demonstrate the superiority of our proposed method on COCO dataset in terms of inference time and accuracy.&lt;/p&gt;</content><author><name>benjamin:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">ComDensE : Combined Dense Embedding of Relation-aware and Common Features for Knowledge Graph Completion</title><link href="https://kakaoenterprise.github.io/papers/icpr-comdense" rel="alternate" type="text/html" title="ComDensE : Combined Dense Embedding of Relation-aware and Common Features for Knowledge Graph Completion" /><published>2022-08-21T00:00:00-05:00</published><updated>2022-08-21T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/ICPR-ComDensE</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/icpr-comdense">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Real-world knowledge graphs (KG) are mostly incomplete. The problem of recovering missing relations, called KG completion, has recently become an active research area. Knowledge graph (KG) embedding, a low-dimensional representation of entities and relations, is the crucial technique for KG completion. Convolutional neural networks in models such as ConvE, SACN, InteractE, and RGCN achieve recent successes. This paper takes a different architectural view and proposes ComDensE which combines relation-aware and common features using dense neural networks. In the relation-aware feature extraction, we attempt to create relational inductive bias by applying an encoding function specific to each relation. In the common feature extraction, we apply the common encoding function to all input embeddings. These encoding functions are implemented using dense layers in ComDensE. ComDensE achieves the state-of-the-art performance in the link prediction in terms of MRR, HIT@1 on FB15k-237 and HIT@1 on WN18RR compared to the previous baseline approaches. We conduct an extensive ablation study to examine the effects of the relation-aware layer and the common layer of the ComDensE. Experimental results illustrate that the combined dense architecture as implemented in ComDensE achieves the best performance.&lt;/p&gt;</content><author><name>lucas:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Connecting a Low Loss Subspace for Personalized Federated Learning</title><link href="https://kakaoenterprise.github.io/papers/kdd-federated-learning" rel="alternate" type="text/html" title="Connecting a Low Loss Subspace for Personalized Federated Learning" /><published>2022-08-14T00:00:00-05:00</published><updated>2022-08-14T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/KDD-federated-learning</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/kdd-federated-learning">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Due to the curse of statistical heterogeneity across clients, adopting a personalized federated learning method has become an essential choice for the successful deployment of federated learning-based services. Among diverse branches of personalization techniques, a model mixture-based personalization method is preferred as each client has their own personalized model as a result of federated learning. It usually requires a local model and a federated model, but this approach is either limited to partial parameter exchange or requires additional local updates, each of which is helpless to novel clients and burdensome to the client’s computational capacity. As the existence of a connected subspace containing diverse low-loss solutions between two or more independent deep networks has been discovered, we combined this interesting property with the model mixture-based personalized federated learning method for improved performance of personalization. We proposed SuPerFed, a personalized federated learning method that induces an explicit connection between the optima of the local and the federated model in weight space for boosting each other. Through extensive experiments on several benchmark datasets, we demonstrated that our method achieves consistent gains in both personalization performance and robustness to problematic scenarios possible in realistic services.&lt;/p&gt;</content><author><name>한석주:UNIST, 카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Paraphrasing via Ranking Many Candidates</title><link href="https://kakaoenterprise.github.io/papers/inlg-paraphrasing" rel="alternate" type="text/html" title="Paraphrasing via Ranking Many Candidates" /><published>2022-07-18T00:00:00-05:00</published><updated>2022-07-18T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/inlg-paraphrasing</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/inlg-paraphrasing">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;We present a simple and effective way to generate a variety of paraphrases and find a good quality paraphrase among them. As in previous studies, it is difficult to ensure that one generation method always generates the best paraphrase in various domains. Therefore, we focus on finding the best candidate from multiple candidates, rather than assuming that there is only one combination of generative models and decoding options. Our approach shows that it is easy to apply in various domains and has sufficiently good performance compared to previous methods. In addition, our approach can be used for data augmentation that extends the downstream corpus, showing that it can help improve performance in English and Korean datasets.&lt;/p&gt;</content><author><name>rung:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">A Statistical Manifold Framework for Point Cloud Data</title><link href="https://kakaoenterprise.github.io/papers/icml-point-cloud-data" rel="alternate" type="text/html" title="A Statistical Manifold Framework for Point Cloud Data" /><published>2022-07-17T00:00:00-05:00</published><updated>2022-07-17T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/ICML-point-cloud-data</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/icml-point-cloud-data">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Many problems in machine learning involve data sets in which each data point is a point cloud in R^D. A growing number of applications require a means of measuring not only distances between point clouds, but also angles, volumes, derivatives, and other more advanced concepts. To formulate and quantify these concepts in a coordinate-invariant way, we develop a Riemannian geometric framework for point cloud data. By interpreting each point in a point cloud as a sample drawn from some given underlying probability density, the space of point cloud data can be given the structure of a statistical manifold – each point on this manifold represents a point cloud – with the Fisher information metric acting as a natural Riemannian metric. Two autoencoder applications of our framework are presented: (i) smoothly deforming one 3D object into another via interpolation between the two corresponding point clouds; (ii) learning an optimal set of latent space coordinates for point cloud data that best preserves angles and distances, and thus produces a more discriminative representation space. Experiments with large-scale standard benchmark point cloud data show greatly improved classification accuracy vis-´a-vis existing methods.&lt;/p&gt;</content><author><name>이용현:서울대</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Revisiting Interactive Recommender System with Reinforcement Learning</title><link href="https://kakaoenterprise.github.io/papers/sigir-rl-irs" rel="alternate" type="text/html" title="Revisiting Interactive Recommender System with Reinforcement Learning" /><published>2022-07-11T00:00:00-05:00</published><updated>2022-07-11T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/SIGIR-RL-IRS</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/sigir-rl-irs">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Interactive Recommender Systems (IRS) have drawn a lot of attention, due to their ability in modeling the interactive process between the user and the recommender system. Recently, numerous works have adopted Reinforcement Learning (RL) algorithms, which directly maximize the user’s cumulative rewards, in IRS.
In IRS, researchers commonly utilize the publicly available review datasets to compare and evaluate the algorithms. However, the user feedbacks provided in the public datasets only include an instant response (e.g., rating), without any inclusion of delayed response (e.g., dwell-time, lifetime value). Thus, the question remains whether the review datasets are an appropriate choice to evaluate the long-term effects in IRS.&lt;br /&gt;
In this work, we revisit the experiments on the IRS with the review datasets and compare the RL-based models with a simple reward model that greedily recommends the item with the highest one-step reward. Through extensive experiments, we found the followings: First, a simple greedy reward model outperforms the RL-based models in maximizing the cumulative rewards. Second, applying more weights on long-term rewards degrades the recommendation performance. Third, recommended items have mere long-term effects in the benchmark datasets. From these findings, we conclude that a dataset must be carefully verified and a simple greedy baseline should be included for a proper evaluation in the RL-based IRS.&lt;/p&gt;</content><author><name>이호준:카이스트</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">CoMPM: Context Modeling with Speaker’s Pre-trained Memory Tracking for Emotion Recognition in Conversation</title><link href="https://kakaoenterprise.github.io/papers/naacl-compm" rel="alternate" type="text/html" title="CoMPM: Context Modeling with Speaker’s Pre-trained Memory Tracking for Emotion Recognition in Conversation" /><published>2022-07-10T00:00:00-05:00</published><updated>2022-07-10T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/NAACL-CoMPM</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/naacl-compm">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;As the use of interactive machines grow, the task of Emotion Recognition in Conversation (ERC) became more important. If the machine-generated sentences reflect emotion, more human-like sympathetic conversations are possible. Since emotion recognition in conversation is inaccurate if the previous utterances are not taken into account, many studies reflect the dialogue context to improve the performances. Many recent approaches show performance improvement by combining knowledge into modules learned from external structured data. However, structured data is difficult to access in non-English languages, making it difficult to extend to other languages. Therefore, we extract the pre-trained memory using the pre-trained language model as an extractor of external knowledge. We introduce CoMPM, which combines the speaker’s pre-trained memory with the context model, and find that the pre-trained memory significantly improves the performance of the context model. CoMPM achieves the first or second performance on all data and is state-of-the-art among systems that do not leverage structured data. In addition, our method shows that it can be extended to other languages because structured knowledge is not required, unlike previous methods.&lt;/p&gt;</content><author><name>rung:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Contrastive Regularization for Semi-Supervised Learning</title><link href="https://kakaoenterprise.github.io/papers/cvpr-contrastive-regularization" rel="alternate" type="text/html" title="Contrastive Regularization for Semi-Supervised Learning" /><published>2022-06-20T00:00:00-05:00</published><updated>2022-06-20T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/cvpr-contrastive-regularization</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/cvpr-contrastive-regularization">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Consistency regularization on label predictions becomes a fundamental technique in semi-supervised learning, but it still requires a large number of training iterations for high performance. In this study, we analyze that the consistency regularization restricts the propagation of labeling information due to the exclusion of samples with unconfident pseudo-labels in the model updates. Then, we propose contrastive regularization to improve both efficiency and accuracy of the consistency regularization by well-clustered features of unlabeled data. In specific, after strongly augmented samples are assigned to clusters by their pseudo-labels, our contrastive regularization updates the model so that the features with confident pseudo-labels aggregate the features in the same cluster, while pushing away features in different clusters. As a result, the information of confident pseudo-labels can be effectively propagated into more unlabeled samples during training by the well-clustered features. On benchmarks of semi-supervised learning tasks, our contrastive regularization improves the previous consistency-based methods and achieves state-of-the-art results, especially with fewer training iterations. Our method also shows robust performance on open-set semi-supervised learning where unlabeled data includes out-of-distribution samples.&lt;/p&gt;</content><author><name>이도엽:POSTECH,카카오브레인</name></author><category term="papers" /><category term="Machine_Learning" /><summary type="html">Abstract</summary></entry><entry><title type="html">Vacillating Human Correlation of SacreBLEU in Unprotected Languages</title><link href="https://kakaoenterprise.github.io/papers/humeval-meta-evaluation" rel="alternate" type="text/html" title="Vacillating Human Correlation of SacreBLEU in Unprotected Languages" /><published>2022-05-27T00:00:00-05:00</published><updated>2022-05-27T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/HumEval-meta-evaluation</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/humeval-meta-evaluation">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;SacreBLEU, by incorporating a text normalizing step in the pipeline, has become a rising automatic evaluation metric in recent MT studies. With agglutinative languages such as Korean, however, the lexical-level metric cannot provide a conceivable result without a customized pre-tokenization. In this regard, this paper endeavors to examine the influence of diversified tokenization schemes –-word, morpheme, subword, character, and consonants &amp;amp; vowels (CV)–- on the metric, after its protective layer is peeled off.&lt;br /&gt;
By performing meta-evaluation with manually-constructed into-Korean resources, our empirical study demonstrates that the human correlation of the surface-based metric and other homogeneous ones (as an extension) vacillates greatly by the token type. Moreover, the human correlation of the metric often deteriorates due to some tokenization, with CV one of its culprits. Guiding through the proper usage of tokenizers for the given metric, we discover i) the feasibility of the character tokens, and ii) the deficit of CV in the Korean MT evaluation.&lt;/p&gt;</content><author><name>ria:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Multimodal Interactions Using Pretrained Unimodal Models for SIMMC 2.0</title><link href="https://kakaoenterprise.github.io/papers/aaai-simmc" rel="alternate" type="text/html" title="Multimodal Interactions Using Pretrained Unimodal Models for SIMMC 2.0" /><published>2022-02-28T00:00:00-06:00</published><updated>2022-02-28T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/aaai-simmc</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/aaai-simmc">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;This paper presents our work on the Situated Interactive MultiModal Conversations 2.0 challenge held at Dialog State Tracking Challenge 10. SIMMC 2.0 includes 4 subtasks, and we introduce our multimodal approaches for the subtask #1, #2 and the generation of subtask #4. SIMMC 2.0 dataset is a multimodal dataset containing image and text information, which is more challenging than the problem of only text-based conversations because it must be solved by understanding the relationship between image and text. Therefore, since there is a limit to solving only text models such as BERT or GPT2, we propose a multimodal model combining image and text. We first pretrain the multimodal model to understand the relationship between image and text, then finetune our model for each task. We achieve the 3rd best performance in subtask #1, #2 and a runner-up in the generation of subtask #4. The source code is available at https://github.com/rungjoo/simmc2.0.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈 연구팀은 지난해 10월 개최된 &lt;strong&gt;Situated Interactive MultiModal Conversations 2.0&lt;/strong&gt; (이하 SIMMC 2.0) 챌린지에 참여하여 subtask #1과 #2에서는 &lt;strong&gt;3위&lt;/strong&gt;를, #4에서는 &lt;strong&gt;2위&lt;/strong&gt;를 달성하는 성과를 거두었습니다. 본 논문을 통해 챌린지 참여 과정을 소개하고자 합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-챌린지-소개&quot;&gt;1. 챌린지 소개&lt;/h1&gt;

&lt;p&gt;먼저 해당 챌린지에 대해 짧게 소개드리려고 합니다. 지난해 2회째를 맞은 SIMMC 2.0는 AI 대화 시스템 분야의 대표적인 국제 경진대회인 &lt;strong&gt;DSTC(Dialog State Tracking Challenge)10&lt;/strong&gt;을 통해 개최되었습니다.
대회 주제는 바로, 멀티모달 데이터셋을 활용해 실생활에 쓰일 수 있는 어시스턴트(assistant) 모델을 만드는 것이었는데요. 주어진 데이터셋은 쇼핑 도메인에 특화된 목적지향 대화(task-oriented dialog) 데이터로 구성되어 있었고, 이 데이터셋을 활용해 사용자가 의류 또는 가구를 쇼핑하는 상황에서 AI 어시스턴트가 얼마나 대화 맥락에 적절한 응답을 생성하는지를 평가하는 과제들이 주어졌습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-과제-소개&quot;&gt;2. 과제 소개&lt;/h1&gt;

&lt;p&gt;연구팀은 SIMMC 2.0에서 주어진 4가지 과제 중, subtask #1, #2와 #4에 참여하였습니다. 각 subtask마다 사용 가능한 데이터와 모델링에 있어 차이가 있었고, 학습과 테스트 과정에서 활용 가능한 데이터에서도 제한이 있었습니다. 특히 모든 테스트 과정에서 객체의 시각적 메타데이터, 라벨링된 사용자 정보, 대화에 언급된 모든 객체 리스트 정보는 사용할 수 없었는데요. 다만, 객체의 비시각적 메타데이터, 시스템 발화에서 언급된 객체 리스트, 대화에 해당하는 배경이미지, 모든 객체의 경계 박스(bounding box) 데이터는 모두 활용 가능했습니다. 참고로, 여기서 객체는 의류 도메인 상에서 의류 이미지에 해당됩니다.&lt;/p&gt;

&lt;p&gt;좀 더 자세히 각 과제 내용을 살펴보면, &lt;strong&gt;#1 Multimodal Disambiguation&lt;/strong&gt;은 배경 전체 이미지와 대화 맥락이 주어질 때, 이 상황에서 마지막 발화의 명확성을 판단(True/False)하는 과제입니다. 예를 들어 오른쪽 옷걸이에 파란색 옷 3가지가 걸려있다고 가정했을 때, 아래와 같은 방식으로 발화가 이루어진다면 어떤 옷을 가르키는지 명확히 알 수 없기 때문에 불명확함을 의미하는 False를 도출하게 됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;발화1 : 파란색 옷이 어디 있나요?&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;발화2 : 저기 오른쪽 위에 있습니다.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다음으로 &lt;strong&gt;#2 Multimodal Coreference Resolution&lt;/strong&gt;은 사용자의 발화에 언급된 객체를 찾는 과제로, #1 과제와 동일한 테스트 데이터 사용이 가능했습니다. 이어 &lt;strong&gt;#4 Multimodal Dialog Response Generation &amp;amp; Retrieval&lt;/strong&gt;에서는 사용자 발화에 적절한 시스템 응답을 생성하거나 검색하는 과제였습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-과제-해결과정&quot;&gt;3. 과제 해결과정&lt;/h1&gt;

&lt;p&gt;연구팀은 과제 해결을 위해, 기존 텍스트 기반의 BERT와 GPT2에서 더 나아간 멀티모달 모델을 새롭게 고안하였습니다. 멀티모달 데이터셋은 이미지와 텍스트 정보를 모두 포함하고 있어, 텍스트로만 구성된 데이터셋보다 어려운 문제로 볼 수 있는데요. 이미지와 텍스트 간의 관계를 미리 이해할 수 있도록 멀티모달 사전학습(pre-training) 과정을 거쳤습니다.
사전학습에는 그림1과 같이 총 2가지 모델이 사용되었습니다. 하나는 객체 이미지와 텍스트 설명(description)이 일치하는지 판단하는 모델(ITM)이었고, 다른 하나는 배경 이미지와 대화 맥락(context)이 일치하는지 판단하는 모델(BTM)이었습니다. 두 가지 모델을 결합한 뒤 이를 각 태스크에 맞춰 미세 조정하는 방식으로, 하나의 멀티모달 모델을 사용해 전체 과제를 해결하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/001.png&quot; width=&quot;90%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림1. 멀티모달 사전학습 과정&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;전체적인 모델 구조는 그림2와 같은데요. 앞서 그림1에서 사전학습된 모델들을 모듈화해 전체 태스크에서 사용하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/002.png&quot; width=&quot;90%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림2. 전체 모델 구조&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;각 구조를 살펴보면 &lt;strong&gt;subtask #1&lt;/strong&gt;에서는 발화의 명확성을 판단하기 위해 전체 컨텍스트가 담긴 멀티모달 사전학습이 되지 않은 RoBERTa에 사전학습된 DeIT-I을 사용하여 주어진 이미지에서 의류 형태만 크롭한 후, 객체 설명과 일치하는지를 판단하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;subtask #2&lt;/strong&gt;에서는 #1과 데이터는 동일하게 사용하였지만, 사용자의 발화에 언급된 객체를 찾기 위해 대화맥락, 객체, 배경 정보를 모두 활용하는 구조를 사용했습니다. 먼저 context feature를 추출하기 위해, 그림3과 같은 구조 하에 두 가지 멀티태스크 러닝을 추가로 수행하였습니다. 1단계(utterance classification)에서는 매칭 판단에 유의미하지 않은 발화를 제거하기 위해 발화와 객체의 일치성을 판단하고, 2단계(system matching)에서는 이 객체를 이전 시스템 발화에 해당하는 &lt;code&gt;object_ids&lt;/code&gt;에 매칭하였습니다. 여기서 모델이 학습하는 데이터에 따라 추론과정도 조금 달라지게 되는데요. 학습 데이터로 어떤 &lt;code&gt;mention_objects&lt;/code&gt;를 사용하냐에 따라 모델의 강점이 달라집니다. 이에 따라 이전 발화에 언급됐던 &lt;code&gt;related objects&lt;/code&gt;는 1 또는 matching으로, 관련이 없는 &lt;code&gt;unrelated objects&lt;/code&gt;는 0으로, 이외 나머지를 의미하는 &lt;code&gt;others&lt;/code&gt;는 0 또는 matching으로 결과값을 도출합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/003.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림3. 주어진 발화에서 객체의 포함여부를 판단하는 로직 (two multi-task learning)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;예를 들어 그림4와 같이 유저와 시스템의 발화쌍이 있다면, 시스템 1과 시스템 2의 system matching 여부를 판단하는 건데요. Case1에서는 &lt;strong&gt;“파란색 옷”&lt;/strong&gt;으로 일치하기 때문에 1이, Case2에서는 &lt;strong&gt;“검은색과 빨간색 바지”&lt;/strong&gt;, &lt;strong&gt;“파란색 옷”&lt;/strong&gt;으로 일치하지 않기 때문에 0이 도출됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/004.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림4. 그림3의 로직 판단 예시 (유저 발화:파란색, 시스템 발화:노란색)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이처럼 대화 특성상 앞서 언급된 단어가 뒤에도 동일하게 언급될 가능성이 높기 때문에, 최종적으로 system matching이 1로 판별된 시스템 발화의 objects만을 사용하여 객체의 후보군을 축소시키고자 하였습니다. 여기서 이 정보에 object feature와 background feature를 추출하는 DeIT-I와 DeIT-B 값을 매칭해 최종적으로 발화에 언급된 객체를 판단할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;마지막으로, 사용자 발화에 적절한 시스템 응답을 생성하거나 검색하는 &lt;strong&gt;subtask #4&lt;/strong&gt;에서는 응답 생성만을 진행하였습니다. 여기서는 텍스트 모델로 GPT2-Large를 활용하여 전체 발화를 입력하였고, 시스템이 말할 다음 발화에 해당하는 이미지 정보(slot values)는  DeIT-I를 사용하여 object feature를 추출해 활용하였습니다. 다른 태스크와 달리, 이번 태스크에서는 현재 순서에 대한 주석 정보(system_transcript_annnotated)를 사용할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-챌린지-성과-소개&quot;&gt;4. 챌린지 성과 소개&lt;/h1&gt;

&lt;p&gt;학습에는 hugingface library를 사용하였고, 결과값은 아래 표와 같습니다. 전반적으로 베이스모델인 GPT2 대비 우수한 성능을 보였으며, 그결과 최종적으로 subtask #1, #2에서 각각 3위, #4 생성 분야에서는 준우승을 기록했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/005.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표1. subtask #1 성능 비교&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/006.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표2. subtask #2 성능 비교&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-28-AAAI-SIMMC/007.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표3. subtask #4 성능 비교&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5-마치며&quot;&gt;5. 마치며&lt;/h1&gt;

&lt;p&gt;챌린지에 참여한 상세한 소스 코드는 &lt;a href=&quot;https://github.com/rungjoo/simmc2.0&quot;&gt;깃허브&lt;/a&gt;를 통해 확인하실 수 있습니다. 앞으로 카카오엔터프라이즈 연구팀은 보다 사람같은 챗봇 서비스 구현을 위해, 이번 연구결과를 적극 활용할 계획입니다.&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈의 AI 연구에 많은 관심 부탁드리며, 스몰톡 챗봇 ‘외개인아가’와 카카오엔터프라이즈 연구팀에 대해 궁금하시다면 아래 링크를 참고해주세요!&lt;/p&gt;

&lt;p&gt;🐶 &lt;a href=&quot;https://pf.kakao.com/_lKxoMT&quot;&gt;외개인아가 만나러가기&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;👨🏻‍💻 &lt;a href=&quot;http://kko.to/ailab_career&quot;&gt;인재영입&lt;/a&gt;&lt;/p&gt;</content><author><name>rung:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry></feed>