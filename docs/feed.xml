<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://kakaoenterprise.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://kakaoenterprise.github.io/" rel="alternate" type="text/html" /><updated>2021-12-07T03:16:30-06:00</updated><id>https://kakaoenterprise.github.io/feed.xml</id><title type="html">카카오엔터프라이즈 AI Research</title><subtitle>카카오엔터프라이즈 AI Lab에서 발표한 AI 논문과 연구 성과를 소개합니다.</subtitle><author><name>카카오엔터프라이즈</name></author><entry><title type="html">SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness</title><link href="https://kakaoenterprise.github.io/papers/neurips-smoothmix" rel="alternate" type="text/html" title="SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness" /><published>2021-12-06T00:00:00-06:00</published><updated>2021-12-06T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/neurips-smoothmix</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/neurips-smoothmix">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Randomized smoothing is currently a state-of-the-art method to construct a certifiably robust classifier from neural networks against l2-adversarial perturbations. Under the paradigm, the robustness of a classifier is aligned with the prediction confidence, i.e., the higher confidence from a smoothed classifier implies the better robustness. This motivates us to rethink the fundamental trade-off between accuracy and robustness in terms of calibrating confidences of smoothed classifier. In this paper, we propose a simple training scheme, coined SmoothMix, to control the robustness of smoothed classifiers via self-mixup: it trains convex combinations of samples along the direction of adversarial perturbation for each input. The proposed procedure effectively identifies over-confident, near off-class samples as a cause of limited robustness in case of smoothed classifiers, and offers an intuitive way to adaptively set a new decision boundary between these samples for better robustness. Our experimental results demonstrate that the proposed method can significantly improve the certified l2-robustness of smoothed classifiers compared to existing state-of-the-art robust training methods.&lt;/p&gt;</content><author><name>정종현:카이스트</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Learning Debiased Representation via Disentangled Feature Augmentation</title><link href="https://kakaoenterprise.github.io/papers/neurips-learning-debiased-representation" rel="alternate" type="text/html" title="Learning Debiased Representation via Disentangled Feature Augmentation" /><published>2021-12-06T00:00:00-06:00</published><updated>2021-12-06T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/neurips-learning-debiased-representation</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/neurips-learning-debiased-representation">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Image classification models tend to make decisions based on peripheral attributes of data items that have strong correlation with a target variable (i.e., dataset bias). These biased models suffer from the poor generalization capability when evaluated on unbiased datasets. Existing approaches for debiasing often identify and emphasize those samples with no such correlation (i.e., bias-conflicting) without defining the bias type in advance. However, such bias-conflicting samples are significantly scarce in biased datasets, limiting the debiasing capability of these approaches. This paper first presents an empirical analysis revealing that training with “diverse” bias-conflicting samples beyond a given training set is crucial for debiasing as well as the generalization capability. Based on this observation, we propose a novel feature-level data augmentation technique in order to synthesize diverse bias-conflicting samples. To this end, our method learns the disentangled representation of (1) the intrinsic attributes (i.e., those inherently defining a certain class) and (2) bias attributes (i.e., peripheral attributes causing the bias), from a large number of bias-aligned samples, the bias attributes of which have strong correlation with the target variable. Using the disentangled representation, we synthesize bias-conflicting samples that contain the diverse intrinsic attributes of bias-aligned samples by swapping their latent features. By utilizing these diversified bias-conflicting features during the training, our approach achieves superior classification accuracy and debiasing results against the existing baselines on both synthetic as well as real-world datasets.&lt;/p&gt;</content><author><name>이정수:카이스트</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Kakao Enterprise’s WMT21 Machine Translation using Terminologies Task Submission</title><link href="https://kakaoenterprise.github.io/papers/wmt21-terminology-translation" rel="alternate" type="text/html" title="Kakao Enterprise’s WMT21 Machine Translation using Terminologies Task Submission" /><published>2021-11-19T00:00:00-06:00</published><updated>2021-11-19T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/wmt21-terminology-translation</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/wmt21-terminology-translation">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;This paper describes Kakao Enterprise’s submission to the WMT21 shared Machine Translation using Terminologies task. We integrate terminology constraints by pre-training with target lemma annotations and fine-tuning with exact target annotations utilizing the given terminology dataset. This approach yields a model that achieves outstanding results in terms of both translation quality and term consistency, ranking first based on COMET in the En→Fr language direction. Furthermore, we explore various methods such as back-translation, explicitly training terminologies as additional parallel data, and in-domain data selection.&lt;/p&gt;</content><author><name>juliette:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Capturing Speaker Incorrectness: Speaker-Focused Post-Correction for Abstractive Dialogue Summarization</title><link href="https://kakaoenterprise.github.io/papers/newsum-csi" rel="alternate" type="text/html" title="Capturing Speaker Incorrectness: Speaker-Focused Post-Correction for Abstractive Dialogue Summarization" /><published>2021-11-10T00:00:00-06:00</published><updated>2021-11-10T00:00:00-06:00</updated><id>https://kakaoenterprise.github.io/papers/NewSum-CSI</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/newsum-csi">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;In this paper, we focus on improving the quality of the summary generated by neural abstractive dialogue summarization systems.&lt;/p&gt;

&lt;p&gt;Even though pre-trained language models generate well-constructed and promising results, it is still challenging to summarize the conversation of multiple participants since the summary should include a description of the overall situation and the actions of each speaker.&lt;/p&gt;

&lt;p&gt;This paper proposes self-supervised strategies for speaker-focused post-correction in abstractive dialogue summarization. Specifically, our model first discriminates which type of speaker correction is required in a draft summary and then generates a revised summary according to the required type.&lt;/p&gt;

&lt;p&gt;Experimental results show that our proposed method adequately corrects the draft summaries, and the revised summaries are significantly improved in both quantitative and qualitative evaluations.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈에서는 마치 사람처럼 대화 맥락(context)을 이해하고, 그 내용을 자연스럽게 요약할 수 있는 자연어 처리 기술을 연구하고 있습니다. 본 글에서는 카카오, 카카오엔터프라이즈와 고려대, 와이즈넛, 마이크로소프트 공동 연구팀이 발표한 새로운 대화 생성 요약 방법론에 대해 소개드리고자 합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-기존-대화-요약-기술의-한계&quot;&gt;1. 기존 대화 요약 기술의 한계&lt;/h1&gt;

&lt;p&gt;기존 트랜스포머 기반 사전훈련 언어모델(PLM; BERT, BART, T5)이 많은 발전을 거듭하여 뛰어난 성능을 보임에도 불구하고, 여전히 여러 화자의 대화를 요약하는 상황에서 한계점이 있었습니다.&lt;/p&gt;

&lt;p&gt;최근 많이 활용되는 생성 요약(abstractive summarization) 방식은 대화 내용에서 중요한 핵심 문장 또는 단어구 몇가지를 그대로 뽑아 요약하는 추출 요약(extractive summarization)과 달리, 대화 문맥을 고려해 새로운 문장을 만들어냅니다. 긴 시간 다수의 화자가 대화한 내용으로부터 핵심 키워드를 선별하여 가독성 좋은 요약문을 만드는게 핵심인데요. 이때 문장 구조나 언급된 표현의 수정으로, 보다 자연스럽고 깔끔한 형태의 요약문을 만들 수 있습니다. 다만 모델이 재해석한 내용을 바탕으로 만들어지기 때문에 내용이 잘못 요약될 수 있는 문제(Factual Consistency)를 안고 있는데요.&lt;/p&gt;

&lt;p&gt;실제 100개의 테스트셋을 직접 사람이 분석한 결과 53%가 내용에 오류가 있었고, 이 중 절반 이상이 화자와 관련된 오류였습니다. 예를 들어 &lt;그림1&gt;과 같이 화자 정보가 바뀌는 경우인데요. 주로 화자와 관련된 엔티티(entity)나 릴레이션(relation) 서술에 오류가 있는 경우가 많았습니다. 본 연구에서는 이같은 문제를 해결하고자, 화자 중심의 대화문 사후 편집(post-correction)을 통한 생성 요약 방법론을 새롭게 제안하였습니다.&lt;/그림1&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-10-NewSum-CSI/001.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표1. 화자와 관련된 대화 요약 오류 예시&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2--capturing-speaker-incorrectness-방법론-소개&quot;&gt;2.  Capturing Speaker Incorrectness 방법론 소개&lt;/h1&gt;

&lt;p&gt;해당 방법론의 가장 큰 특징은 대화 요약 태스크에서 화자 중심의 사후 편집 전략을 적용했다는 점입니다. 해당 모델은 초안 요약(draft summary) 단계에서 잘못 언급된 화자 오류 유형을 먼저 찾고, 어떤 유형으로 이를 수정해야 될지 판단합니다. 이후 빠져있는 화자명을 추가하거나, 잘못 언급된 화자를 삭제, 혹은 교체하는 방식으로 요약 내용을 수정합니다. 최종적으로 수정된 결과 예시는 &lt;표2&gt;와 같습니다.&lt;/표2&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-10-NewSum-CSI/002.png&quot; width=&quot;80%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표2. 대화 교정 후 결과 예시 (빨간색 오류 부분을 파란색으로 수정)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;일반적으로 생성 요약 학습에서는 레이블링된 요약문 데이터셋이 필요한데요. 해당 방법론에서는 자기지도학습(Self-supervised Learning) 전략을 사용하여 추가적인 어노테이션(annotation) 없이 학습 데이터를 구성하였습니다. 또한, 강건한 모델을 만들기 위해 학습 시에 대화 맥락과 초안 요약이 주어지면 화자 리스트를 구성하는 화자 생성기(speaker generator)를 보조 태스크로 진행하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-성능-평가&quot;&gt;3. 성능 평가&lt;/h1&gt;

&lt;p&gt;실제 모델의 성능을 정량적, 정성적인 평가 기준으로 측정하였을 때, 초안 요약 결과와 수정된 요약 결과 모두에서 높은 성능을 보임을 확인하였습니다. 먼저 동일한 단어가 얼마나 많이 매칭되는지를 판단하는 기계 평가 메트릭 ROUGE 스코어를 활용했을 때, &lt;표3&gt;와 같은 성능 결과를 얻었습니다. 여기서 Correction Rate는 해당 모델에 의해 수정된 비율을 의미합니다.&lt;/표3&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-10-NewSum-CSI/003.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표3. 정량적인 성능 평가 결과 (ROUGE score)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;ROUGE 스코어는 단어의 시멘틱 요소는 고려되지 않기 때문에, 정성적인 측면의 평가를 위해 Amazon Mechanical Turk(AMT)를 활용하여 &lt;표3&gt;과 같이 실제 사람의 평가를 진행하였습니다. 여기서도 우수한 성능을 보임을 확인할 수 있었습니다.&lt;/표3&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-10-NewSum-CSI/004.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표4. 정성적인 성능 평가 결과 (Human Evaluation)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-향후-연구-계획&quot;&gt;4. 향후 연구 계획&lt;/h1&gt;

&lt;p&gt;장시간의 대화를 요약하는 시스템은 회의록 작성 등 현재 다양한 분야에 활용되고 있습니다. 본 연구 결과는 카카오엔터프라이즈의 대화 요약 서비스의 적용되어 factual consistency 문제를 개선하는 데에 활용될 예정입니다. 앞으로도 카카오엔터프라이즈의 AI 연구와 서비스에 많은 관심 부탁드립니다. 감사합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;현재 카카오엔터프라이즈 AI Lab에서는 다양한 AI 연구와 서비스화를 함께 고민해나갈 여러분의 지원을 기다리고 있습니다. AI를 통해 더욱 가치있는 세상을 만들고, 꿈을 현실로 만들어가는 여정에 함께하세요!&lt;/p&gt;

&lt;p&gt;👨🏻‍💻 &lt;a href=&quot;http://kko.to/ailab_career&quot;&gt;인재영입&lt;/a&gt;&lt;/p&gt;</content><author><name>이동엽:카카오</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">An Evaluation Dataset and Strategy for Building Robust Multi-turn Response Selection Model</title><link href="https://kakaoenterprise.github.io/papers/emnlp-evaluation-dataset-and-strategy" rel="alternate" type="text/html" title="An Evaluation Dataset and Strategy for Building Robust Multi-turn Response Selection Model" /><published>2021-11-07T00:00:00-05:00</published><updated>2021-11-07T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/emnlp-evaluation-dataset-and-strategy</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/emnlp-evaluation-dataset-and-strategy">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Multi-turn response selection models have recently shown comparable performance to humans in several benchmark datasets. However, in the real environment, these models often have weaknesses, such as making incorrect predictions based heavily on superficial patterns without a comprehensive understanding of the context. For example, these models often give a high score to the wrong response candidate containing several keywords related to the context but using the inconsistent tense. In this study, we analyze the weaknesses of the open-domain Korean Multi-turn response selection models and publish an adversarial dataset to evaluate these weaknesses. We also suggest a strategy to build a robust model in this adversarial environment.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈에서는 실제 사람처럼 자연스러운 대화가 가능한 오픈 도메인 챗봇 (open domain Chatbot)을 연구하고 있습니다. 현재 해당 기술은 AI 스피커 ‘카카오미니’, 종합 업무 플랫폼 ‘카카오워크’, 카카오톡채널 ‘&lt;a href=&quot;https://pf.kakao.com/_lKxoMT&quot;&gt;외개인아가&lt;/a&gt;’ 등에 적용되어 있는데요.&lt;/p&gt;

&lt;p&gt;챗봇이 실제 사람처럼 자연스럽게 대화를 하기 위해서는 대화 맥락(context)에 맞는 답변을 하는 것이 중요합니다. 이를 위해서는 주어진 응답 후보에서 가장 적절한 답변을 선택하는 응답 선택(Response Selection) 태스크를 잘 수행해야 합니다. 본 연구에서는 보다 자연스러운 한국어 챗봇 시스템 구현을 위한 응답 선택 모델 구성 전략과 강건성 평가 데이터셋을 새롭게 제안하였고, &lt;a href=&quot;https://github.com/kakaoenterprise/KorAdvMRSTestData&quot;&gt;깃허브&lt;/a&gt; 상에 해당 데이터셋을 공개하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-기존-multi-turn-response-selection-모델-연구의-한계&quot;&gt;1. 기존 Multi-turn Response Selection 모델 연구의 한계&lt;/h1&gt;

&lt;p&gt;최근에는 실제 사람과 유사한 수준의 대화 성능을 보여주는 응답 선택 모델 연구 결과들이 다수 발표되었습니다. 하지만 이를 실서비스 환경에서 적용했을 때, 대화 맥락을 포괄적으로 이해하여 답변을 도출하는 것이 아니라, 피상적인 패턴에 크게 의존하여 잘못된 답변을 하는 문제가 있었습니다. 예를 들어 실제 의미 상으로는 틀린 시제나 부정표현을 사용하여 잘못된 답이지만, 대화 맥락과 관련된 키워드를 많이 사용하여 높은 점수를 받아 일어나는 현상인데요.&lt;/p&gt;

&lt;p&gt;본 연구에서는 이러한 오류 패턴을 7가지 유형으로 분류하고, 이를 판단할 수 있는 데이터셋과 해당 환경에서 효과적인 모델을 구축하기 위한 전략을 제안하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-평가-데이터셋과-방법론-소개&quot;&gt;2. 평가 데이터셋과 방법론 소개&lt;/h1&gt;

&lt;p&gt;먼저 카카오엔터프라이즈 연구팀이 구축한 취약점 평가 데이터셋(adversarial dataset)은 &lt;표1&gt;과 같이 총 2220개의 테스트 케이스로 구성되어 있습니다. 이 케이스를 각각 7가지 오류 유형으로 구분하였습니다. 해당 유형으로는 이전 문장을 반복(Repetition)하거나, 부정어(Negation) 또는 시제(Tense)를 잘못 사용한 경우, 주체/대상을 혼동한 경우(Subject-Object), 모순 어휘(Lexcial Contradiction)를 사용한 경우, 토픽에 따른 화용적 오류(Topic)가 발생한 경우 등이 있습니다. 내부 서비스 로그에서 잘못 응답되거나, 빈번하게 발생하는 오류를 기준으로 유형을 분석하였습니다.&lt;/표1&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-07-emnlp-evaluation-dataset-and-strategy/001.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표1. 개별 오류 유형에 따른 평가 데이터셋 샘플&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이 데이터셋은 실제 서비스 환경에서 오갈 수 있는 복잡한 응답에 대비하기 위해, 언어학 전문가의 상세한 지침 하에 어려운 답변으로 구성될 수 있게끔 수작업을 통해 구축되었습니다. 5명의 작업자(annotator)가 총 200개의 대화 세션을 작성하고, 각 세션에 대해 여러 개의 정답과 위 지침에 기반한 오답을 작성하였습니다.&lt;/p&gt;

&lt;p&gt;또한, 강건한 모델을 구축하기 위한 두 가지의 전략을 제시하였습니다. 먼저 탈편향(debiasing) 전략입니다. 신경망(Neural Network)은 데이터의 쉽고 표층적인 패턴에 편향되게(biased) 학습되는 경향을 보입니다. 대화 데이터에서 적절한 답변은 보통 문맥에서 다룬 주제(Topic)에 기반하거나, 문맥에 나왔던 키워드들을 활용하는 경향을 보입니다. 본 연구팀은 모델이 주제와 키워드에 편향되게 학습되는 것을 취약점의 원인이라 보았습니다. 이에 DRiFt[1] 탈편향 알고리즘을 활용하여 &lt;그림1&gt;과 같이 전체적인 모델 구조를 설계하였고, 모델 성능을 향상시킬 수 있었습니다.&lt;/그림1&gt;&lt;/p&gt;

&lt;p&gt;두 번째로는 멀티태스크 러닝과의 결합입니다. 최근 답변 선택 태스크에서는 UMS[2]와 같은 자기지도학습(Self-supervised Learning) 기반 멀티태스크 러닝을 활용한 기법이 우수한 성능을 보여주고 있습니다. 앞서 언급한 탈편향 기법과 UMS 기법을 결합하는 전략을 제시하여 더욱 향상된 성능을 얻을 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-07-emnlp-evaluation-dataset-and-strategy/002.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림1. 전체적인 모델 구조&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-성능-평가&quot;&gt;3. 성능 평가&lt;/h1&gt;

&lt;p&gt;실제 성능 평가는 아래 &lt;표2&gt;와 같은 데이터셋 구성으로 진행되었습니다. 각 데이터셋은 기존 학습 데이터와 동일한 방식으로 구축된 데이터(In-domain), 앞서 설명드린 연구팀이 새롭게 구축한 취약점 평가 데이터(Adv), 실제 서비스 환경과 동일한 방식의 데이터(Real)로 구성되었습니다.&lt;/표2&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-07-emnlp-evaluation-dataset-and-strategy/003.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표2. 데이터셋 구성&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&amp;lt;표3&amp;gt;과 같이 탈편향 기법(deb)과 UMS 방법론을 결합한 전략이 취약점 평가 데이터(Adversarial)에서 baseline 모델 대비 +7.8%의 상당한 높은 성능 향상을 보였습니다. 또한, 실제 환경과 유사한 데이터셋(Real Env.)에서도 본 연구팀이 제시한 전략이 +4.2%의 성능 향상을 보였습니다. 이를 통해 Adversarial한 환경에서의 강건성이 실제 환경에서도 유효함을 확인하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-07-emnlp-evaluation-dataset-and-strategy/004.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표3. 각 데이터셋과 방법론에 따른 성능 비교&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&amp;lt;표4&amp;gt;는 본 연구팀이 제시한 전략이 기존 모델보다 잘 작동하는 예시입니다. 기존 baseline 모델은 단순히 ‘핸드폰’, ‘바꾸다’ 라는 키워드만 들어가있고, 문맥상 올바르지 않은 답변에 정답보다도 더 높은 0.998 이라는 점수를 주었습니다. 반면 제시한 전략을 활용하면 이와 같은 오답에 0.094라는 낮은 점수를 주는 것을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-07-emnlp-evaluation-dataset-and-strategy/005.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표4. 제안한 전략이 잘 작동하는 예시&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-향후-연구-계획&quot;&gt;4. 향후 연구 계획&lt;/h1&gt;

&lt;p&gt;현재 이 연구 결과는 외개인아가 챗봇의 답변 선택 로직에 적용되어 있습니다. 외개인아가는 대화 주제가 열려있는 비목적성 대화, 즉 일상 대화에 초점을 둔 챗봇입니다. 실제 사람 간의 대화를 살펴보면 일상 대화나 감정 교류 목적의 ‘스몰톡(small talk)’이 차지하는 비중이 높은데요. 카카오엔터프라이즈에서는 이러한 스몰톡에서 이전 대화 맥락을 반영하여 적절한 발화를 선택하는 기술을 지속적으로 연구해, 서비스를 고도화시켜 나갈 계획입니다. 앞으로도 카카오엔터프라이즈의 AI 연구와 서비스에 많은 관심 부탁드립니다. 감사합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;참조-문헌&quot;&gt;참조 문헌&lt;/h1&gt;

&lt;p&gt;[1] He et al., “&lt;a href=&quot;https://arxiv.org/abs/1908.10763&quot;&gt;Unlearn Dataset Bias in Natural Language Inference by Fitting the Residual&lt;/a&gt;”, EMNLP, 2019.&lt;/p&gt;

&lt;p&gt;[2] Whang et al., “&lt;a href=&quot;https://kakaoenterprise.github.io/papers/aaai2021-multi-turn-response-selection&quot;&gt;Do Response Selection Models Really Know What’s Next? Utterance Manipulation Strategies for Multi-turn Response Selection&lt;/a&gt;”, AAAI, 2021.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;현재 카카오엔터프라이즈 AI Lab에서는 다양한 AI 연구와 서비스화를 함께 고민해나갈 여러분의 지원을 기다리고 있습니다. AI를 통해 더욱 가치있는 세상을 만들고, 꿈을 현실로 만들어가는 여정에 함께하세요!&lt;/p&gt;

&lt;p&gt;👨🏻‍💻 &lt;a href=&quot;http://kko.to/ailab_career&quot;&gt;인재채용&lt;/a&gt;&lt;/p&gt;</content><author><name>mat:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">AligNART: Non-autoregressive Neural Machine Translation by Jointly Learning to Estimate Alignment and Translate</title><link href="https://kakaoenterprise.github.io/papers/emnlp-alignart" rel="alternate" type="text/html" title="AligNART: Non-autoregressive Neural Machine Translation by Jointly Learning to Estimate Alignment and Translate" /><published>2021-11-07T00:00:00-05:00</published><updated>2021-11-07T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/emnlp-alignart</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/emnlp-alignart">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Non-autoregressive neural machine translation (NART) models suffer from the multi-modality problem which causes translation inconsistency such as token repetition. Most recent approaches have attempted to solve this problem by implicitly modeling dependencies between outputs. In this paper, we introduce AligNART, which leverages full alignment information to explicitly reduce the modality of the target distribution. AligNART divides the machine translation task into (i) alignment estimation and (ii) translation with aligned decoder inputs, guiding the decoder to focus on simplified one-to-one translation. To alleviate the alignment estimation problem, we further propose a novel alignment decomposition method. Our experiments show that AligNART outperforms previous non-iterative NART models that focus on explicit modality reduction on WMT14 En↔De and WMT16 Ro→En. Furthermore, AligNART achieves BLEU scores comparable to those of the state-of-the-art connectionist temporal classification based models on WMT14 En↔De. We also observe that AligNART effectively addresses the token repetition problem even without sequence-level knowledge distillation.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈 AI Lab에서는 고품질의 번역 서비스를 제공하고자 신경망 기계 번역(Neural  Machine Translation, 이하 NMT) 연구를 진행하고 있습니다. 본 글에서는 송종윤 님이 카카오엔터프라이즈 AI Lab 인턴 당시, 서울대 연구팀과 함께 연구한 AligNART 방법론을 간략하게 소개드리고자 합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-nmtneural--machine-translation의-등장&quot;&gt;1. NMT(Neural  Machine Translation)의 등장&lt;/h1&gt;

&lt;p&gt;먼저 기계 번역 발전과정을 짧게 살펴보면, 기존 기계 번역 분야는 수많은 과정을 거쳐 통계를 기반으로 진행되었습니다. 지난 2014년 말, 처음 등장한 NMT는 관련 업계에 큰 혁신을 가져왔습니다.&lt;/p&gt;

&lt;p&gt;NMT는 encoder와 decoder로 구성된 하나의 큰 인공신경망을 기반으로, 간단히 기계 번역을 출력할 수 있도록 그 구조를 완전히 새롭게 바꾸었습니다. 현재도 번역 분야는 딥러닝이 가장 크게 활용되는 분야 중 하나인데요. NMT의 첫 등장 이후, NMT는 지속적인 발전을 거듭해오고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-기존-nmt-연구의-한계&quot;&gt;2. 기존 NMT 연구의 한계&lt;/h1&gt;

&lt;p&gt;일반적으로 NMT에서는 자기회귀(autoregressive) 모델이 활용되었습니다. 자기회귀 모델은 출력 단어 간의 종속성을 고려하여 좋은 성능을 내지만, 이로 인해 병렬화가 어려워 디코딩 속도가 느리다는 한계가 있습니다. 이러한 이유로 최근에는 단어 간의 종속성을 직접적으로 고려하기보다, 이같은 고려를 최소화한 비자기회귀(non-autoregressive) 모델이 주목받고 있습니다.&lt;/p&gt;

&lt;p&gt;비자기회귀 모델은 독립적인 단어 생성을 통해 병렬화가 가능해, 속도를 크게 개선한 점이 특징입니다. 하지만, 이 과정에서 동일한 의미를 가진 토큰이 반복되거나 중요한 단어를 누락하여 잘못된 번역 결과를 도출하는 멀티 모달리티(multi modality) 문제를 안고 있습니다. 이번 연구는 바로 이 문제를 해결하기 위해 제시된 방법론입니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-alignart-방법론-소개&quot;&gt;3. AligNART 방법론 소개&lt;/h1&gt;

&lt;p&gt;AligNART는 단어의 정렬(alignment) 정보를 활용하여 멀티 모달리티 문제를 개선하였습니다. 여기서 가장 중요한 역할을 하는 모듈이 바로 aligner입니다. aligner는 수많은 타겟 토큰의 정렬 정보를 동시에 예측하는 역할을 합니다.&lt;/p&gt;

&lt;p&gt;이를 위해 정렬 분해(alignment decomposition) 구조를 새롭게 구성하여 사용했습니다. ‘Duplication - Permutation - Grouping’ 3단계를 통해 단어의 중첩을 예상하고, 단어의 어순이 바뀌지 않고 번역될 수 있도록 그 순서배열을 정리하고, 복합 형태의 단어가 담고 있는 단일 의미를 고려하여 최종 단어를 매핑하는 과정을 거쳤습니다. 이렇게 출력된 정렬 정보를 다시 디코더의 입력값(input)으로 활용하여 번역 성능을 높였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-07-EMNLP-AligNART/001.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림1. (좌)AligNART 전체 구조, (우)Alignment decomposition 구조&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-성능-평가&quot;&gt;4. 성능 평가&lt;/h1&gt;

&lt;p&gt;모델 성능을 평가하기 위해, WMT14 En↔De와 WMT16 Ro↔En 케이스에서 BLEU score를 측정하였습니다. BLEU는 기계 번역 결과와 사람이 직접 번역한 결과를 비교하여 그 결과가 얼마나 유사한지를 기준으로, 기계 번역에 대한 성능을 평가하는 방법입니다.&lt;/p&gt;

&lt;p&gt;AligNART는 해당 평가에서 SOTA 수준의 우수한 성능을 보였습니다. 본 연구에서는 aligner 모듈의 유효성을 검증하는 것이 주요 목적이었기 때문에, 별도의 목적함수를 조정하지 않았습니다. 향후 후속 연구에서 목적함수를 최적화한다면 현재보다 높은 성능을 보일 것으로 기대가 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-07-EMNLP-AligNART/002.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표1. BLEU Score 측정 결과&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5-향후-연구-계획&quot;&gt;5. 향후 연구 계획&lt;/h1&gt;

&lt;p&gt;AligNART 모델은 기존 NMT보다 추론이 단순하고 속도가 빨라, 엣지 디바이스와 같이 가볍고 빠른 번역 결과가 필요한 곳에 효과적으로 적용될 수 있습니다. 향후 엣지 디바이스 상에서 보다 빠르고 정확한 번역 서비스를 제공하기 위해 관련 연구를 지속적으로 발전시켜 나갈 계획입니다. 앞으로도 카카오엔터프라이즈의 AI 연구에 많은 관심 부탁드립니다. 감사합니다.&lt;/p&gt;

&lt;p&gt;► 카카오엔터프라이즈의 번역서비스가 궁금하다면 지금 바로 &lt;a href=&quot;https://translate.kakao.com/&quot;&gt;카카오 i 엔진&lt;/a&gt;을 확인해보세요!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;현재 카카오엔터프라이즈 AI Lab에서는 다양한 AI 연구와 서비스화를 함께 고민해나갈 여러분의 지원을 기다리고 있습니다. AI를 통해 더욱 가치있는 세상을 만들고, 꿈을 현실로 만들어가는 여정에 함께하세요!&lt;/p&gt;

&lt;p&gt;👨🏻‍💻 &lt;a href=&quot;http://kko.to/ailab_career&quot;&gt;인재채용&lt;/a&gt;&lt;/p&gt;</content><author><name>송종윤:카카오엔터프라이즈, 서울대</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Distilling Global and Local Logits with Densely Connected Relations</title><link href="https://kakaoenterprise.github.io/papers/iccv-distilling-global-and-local-logits" rel="alternate" type="text/html" title="Distilling Global and Local Logits with Densely Connected Relations" /><published>2021-10-11T00:00:00-05:00</published><updated>2021-10-11T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/iccv-distilling-global-and-local-logits</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/iccv-distilling-global-and-local-logits">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;In prevalent knowledge distillation, logits in most image recognition models are computed by global average pooling, then used to learn to encode the high-level and task-relevant knowledge. In this work, we solve the limitation of this global logit transfer in this distillation context. We point out that it prevents the transfer of informative spatial information, which provides localized knowledge as well as rich relational information across contexts of an input scene. To exploit the rich spatial information, we propose a simple yet effective logit distillation approach. We add a local spatial pooling layer branch to the penultimate layer, thereby our method extends the standard logit distillation and enables learning of both finely-localized knowledge and holistic representation. Our proposed method shows favorable accuracy improvement against the state-of-the-art methods on several image classification datasets. We show that our distilled students trained on the image classification task can be successfully leveraged for object detection and semantic segmentation tasks; this result demonstrates our method’s high transferability.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;본 글에서는 카카오엔터프라이즈 AI Lab과 경희대, 포항공대에서 함께 연구한 새로운 지식 증류(Knowledge Distillation) 방법론이 ICCV 2021 학회를 통해 발표되어, 간략하게 소개드리고자 합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-지식-증류-기법의-등장&quot;&gt;1. 지식 증류 기법의 등장&lt;/h1&gt;

&lt;p&gt;지식 증류 기법은 기 학습된 거대 모델(teacher)의 지식을 새로운 네트워크(student)가 전달받아 학습하는 방식으로, ‘teacher-student’ 모델이라고도 합니다. 잘 학습된 teacher 모델을 기반으로, 경량화된 student 모델이 학습을 통해 그에 버금가는 우수한 성능을 내고자 한다는 점이 특징입니다.&lt;/p&gt;

&lt;p&gt;지식 증류 기법은 기존 딥러닝 모델이 가지는 컴퓨팅 리소스과 메모리의 한계, 긴 추론시간 등의 문제를 해결하고자 제시된 방법입니다. 일반적으로 딥러닝 모델은 모델의 크기가 커질수록, 즉 파라미터 수가 많아질수록 더 높은 성능을 내게 됩니다. 더 많은 연산량을 처리하기 위해서는 대량의 컴퓨팅 리소스와 학습시간을 필요로 하기 때문에, 상대적으로 저성능, 저전력의 소형 모바일 디바이스나 IoT 기기에는 이를 활용하기 어렵다는 문제가 있었습니다. 이같은 문제를 해결하고 효율적인 딥러닝 학습을 시도하기 위한 움직임으로, 현재 지식 증류 기법 연구가 주목받고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-기존-지식-증류-기법의-한계&quot;&gt;2. 기존 지식 증류 기법의 한계&lt;/h1&gt;

&lt;p&gt;지식 증류 과정에서 teacher 모델의 정보를 student 모델에 전달하기 위해, logit 값이 활용됩니다. 여기서 logit은 해당 task와 직접적인 연관을 가지는 모델의 출력값으로, feature보다 입력 이미지에 대한 모델의 representation 정보를 풍부하게 담고 있어 학습 데이터와 함께 사용될 경우 효율적인 학습이 가능해집니다.&lt;/p&gt;

&lt;p&gt;이때 logit은 과적합(overfitting)을 방지하기 위해 global average pooling(GAP)으로 계산되는데, 이로 인해 logit을 활용한 기존 연구들에서는 세부 공간에 대한 logit을 사용할 수 없다는 한계가 존재했습니다. 이에 카카오엔터프라이즈 연구팀은 global logit과 local logit이라는 개념을 새롭게 제시한 ‘Global and Local Logit with Densely Connected Relations(GLD)’ 방법론을 제안하여 이같은 문제를 해결하고자 하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-global-and-local-logit-with-densely-connected-relationsgld-방법론-소개&quot;&gt;3. Global and Local Logit with Densely Connected Relations(GLD) 방법론 소개&lt;/h1&gt;

&lt;p&gt;해당 방법론의 가장 큰 특징은 앞서 언급한 global logit과 local logit을 모두 사용했다는 점입니다. 먼저 global logit은 입력된 이미지의 global feature에서 classifier를 거쳐 최종적으로 산출된 값으로, 기존 연구에서 주로 활용되던 정보입니다. 여기에 global feature를 세분화한 뒤, 동일한 방식으로 산출한 값이 local logit입니다. 보다 세밀한 공간 정보를 담은 local logit을 추가적으로 사용함으로써 디테일한 정보를 학습에 반영할 수 있게 되었습니다.&lt;/p&gt;

&lt;p&gt;또한, 개별 이미지 샘플에서 세부 영역의 관계 정보를 파악할 수 있음은 물론, 여러 샘플값 간의 관계 정보도 파악하여 모델 성능을 높였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-10-11-ICCV-distilling-global-and-local-logits/001.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림1. GLD 전체 구조&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이밖에도 GLD에서는 logit 값을 정규화하기 위해 loss 함수 LND을 새롭게 제안하였습니다. 기존 방법론에서는 softmax 함수 사용으로 정보량이 적은 확률 분포가 도출되는 문제를 해결하기 위해, 고정된 temperature 파라미터를 사용하여 확률 분포의 정보량을 증가시켰습니다. 하지만, 이는 개별 이미지마다 확률 분포의 특징이 다르다는 것을 고려하지 않았다는 한계가 있었기 때문에, GLD에서는 입력 이미지마다 logit의 표준편차를 사용하여 개별 조정하는 방식을 활용하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-성능-평가&quot;&gt;4. 성능 평가&lt;/h1&gt;

&lt;p&gt;카카오엔터프라이즈 연구팀은 모델의 성능을 검증하기 위해, 9가지의 지식 증류 SOTA(State-of-the-art) 모델과 성능 비교 실험을 진행하였습니다. 실험결과는 각각 CIFAR-100, ImageNet, CINIC-10, STL-10, VOC2007, COCO2017 데이터셋으로 측정하였습니다.&lt;/p&gt;

&lt;p&gt;먼저 이미지 분류 문제에서 성능 테스트를 위해 CIFAR-100, ImageNet 데이터를 활용하였습니다. CIFAR-100 테스트에서는 다양한 환경에서의 방법론 검증을 위해 총 4가지의 실험모델을 구성하여 테스트를 진행하였고, ImageNet 테스트에서는 Top-1과 Top-5 정확도를 구분하여 평가한 결과 기존 연구 모델보다 평균적으로 우수한 성능을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-10-11-ICCV-distilling-global-and-local-logits/002.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표1. 실험모델 구성 (CIFAR-100 데이터셋 기준)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-10-11-ICCV-distilling-global-and-local-logits/003.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표2. GLD와 기존 방법론 성능 비교 (CIFAR-100 데이터셋 기준)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-10-11-ICCV-distilling-global-and-local-logits/004.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표3. GLD와 기존 방법론 성능 비교 (ImageNet 데이터셋 기준)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;또한, 실질적으로 teacher 모델에서 student 모델로 얼마나 지식이 잘 전달될 수 있는지, 그 성능을 평가해보고자 학습되지 않은 CINIC-10과 STL-10 데이터셋을 활용하여 실험을 진행한 결과 SOTA보다 높은 성능을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-10-11-ICCV-distilling-global-and-local-logits/005.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표4. GLD와 기존 방법론 성능 비교 (CINIC-10과 STL-10 데이터셋 기준)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이밖에도 객체 탐지와 시멘틱 세그멘테이션 문제에서 성능을 확인하기 위해 VOC2007, COCO2017 데이터셋을 활용한 결과, 우수한 성능을 확인함은 물론, 이미지 분류뿐만 아니라 feature representation 영역에서 높은 성능을 나타냄을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-10-11-ICCV-distilling-global-and-local-logits/006.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표5. 객체 탐지 문제에서의 GLD와 기존 방법론 성능 비교 (VOC2007과 COCO2017 데이터셋 기준)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-10-11-ICCV-distilling-global-and-local-logits/007.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표6. 시멘틱 세그멘테이션 문제에서의 GLD와 기존 방법론 성능 비교 (VOC2007과 COCO2017 데이터셋 기준)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5-향후-연구-계획&quot;&gt;5. 향후 연구 계획&lt;/h1&gt;

&lt;p&gt;향후 해당 방법론을 기반으로 딥러닝 알고리즘을 경량화하여 얼굴 인식 및 여러가지 비전 기반 서비스의 계산량을 효율화하는 데에 활용할 계획입니다. 앞으로도 카카오엔터프라이즈 연구에 많은 관심과 응원 부탁드립니다. 감사합니다.&lt;/p&gt;</content><author><name>harry:경희대, 카카오엔터프라이즈</name></author><category term="papers" /><category term="ICCV" /><category term="distillation" /><category term="GLD" /><summary type="html">Abstract</summary></entry><entry><title type="html">Improving End-to-End Contextual Speech Recognition via a Word-Matching Algorithm with Backward Search</title><link href="https://kakaoenterprise.github.io/papers/ieee-e2e-csr" rel="alternate" type="text/html" title="Improving End-to-End Contextual Speech Recognition via a Word-Matching Algorithm with Backward Search" /><published>2021-10-04T00:00:00-05:00</published><updated>2021-10-04T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/ieee-e2e-csr</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/ieee-e2e-csr">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;End-to-end automatic speech recognition (E2E-ASR) prefers the common words during training rather than rare ones related to contextual information such as song names. Thus, recognizing contextual information correctly is a hurdle for E2E-ASR to reach the production-level. To overcome the limitations of E2E-ASR in recognizing contextual information, this work presents a post-processing followed by E2E-ASR in an algorithmic way, referred to as a word-matching algorithm with backward search (WMA-BS). At first, we allow E2E-ASR to roughly detect the position of target words that has similar pronunciation with desired contextual phrases. After that, given the hypothesis from E2E-ASR with the rough position of target words, WMA-BS estimates the correct target words and decides whether to replace the target words with the contextual phrase or not, according to their phonetic and literal similarity. Applying the proposed method to E2E-ASR achieved relative improvement up to 52.7% in word error rate across several harsh conditions.&lt;/p&gt;</content><author><name>jaytee:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation</title><link href="https://kakaoenterprise.github.io/papers/interspeech2021-univnet" rel="alternate" type="text/html" title="UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation" /><published>2021-08-30T00:00:00-05:00</published><updated>2021-08-30T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/interspeech2021-univnet</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/interspeech2021-univnet">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Most neural vocoders employ band-limited mel-spectrograms to generate waveforms. If full-band spectral features are used as the input, the vocoder can be provided with as much acoustic information as possible. However, in some models employing full-band mel-spectrograms, an over-smoothing problem occurs as part of which non-sharp spectrograms are generated. To address this problem, we propose UnivNet, a neural vocoder that synthesizes high-fidelity waveforms in real time. Inspired by works in the field of voice activity detection, we added a multi-resolution spectrogram discriminator that employs multiple linear spectrogram magnitudes computed using various parameter sets. Using full-band mel-spectrograms as input, we expect to generate high-resolution signals by adding a discriminator that employs spectrograms of multiple resolutions as the input. In an evaluation on a dataset containing information on hundreds of speakers, UnivNet obtained the best objective and subjective results among competing models for both seen and unseen speakers. These results, including the best subjective score for text-to-speech, demonstrate the potential for fast adaptation to new speakers without a need for training from scratch.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈 AI Lab 음성처리팀은 카카오 i에 적용되는 TTS(Text to Speech) 연구를 진행해오고 있습니다.​​​ TTS 시스템은 크게 텍스트에서 acoustic feature를 생성하는 어쿠스틱 모델(acoustic model)과 이 스펙트로그램에서 음성신호를 합성해 AI 음성을 만들어내는 보코더(vocoder)로 구성됩니다. 여기서 보코더는 고품질의 음성을 생성하는데 주요한 역할을 담당하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-08-30-INTERSPEECH-UnivNet/001.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림1. TTS 구조&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈 연구팀은 기존 연구보다 개선된 고품질 음성 합성을 가능케하는 뉴럴 보코더 기술 ‘UnivNet’을 고안해, 이번 INTERSPEECH 2021에서 연구 내용을 공개하게 되었습니다. 지난해 음성합성 모델과 음소-오디오 정렬 모델을 한꺼번에 훈련하는 아키텍처 ‘JDI-T’를 공개한데 이어, 2년 연속 연구 성과를 발표하게 되었습니다. 본 글에서는 이번 연구 성과에 대해 간략하게 소개드리고자 합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-기존-뉴럴-보코더-연구의-한계&quot;&gt;1. 기존 뉴럴 보코더 연구의 한계&lt;/h1&gt;

&lt;p&gt;대다수 뉴럴 보코더(neural vocoder) 연구에서는 전체 주파수 대역 중 일부(0-8kHz)에 해당하는 멜 스펙트로그램(mel-spectrogram)을 입력값으로 사용하고 있습니다. 여기서 멜 스펙트로그램은 인간의 인지 기준에 따라 헤르츠(Hz) 단위의 주파수를 mel-scale에 따라 변환한 값으로, 딥러닝에서 오디오 신호 처리에 많이 활용되는 피쳐(feature)입니다. 일반적으로 사람들은 고주파보다 저주파를 잘 인지하기 때문에, 스펙트로그램의 저주파 부분을 보다 잘 인식할 수 있도록 저주파 부분을 확장시킨 점이 특징입니다.&lt;/p&gt;

&lt;p&gt;이때, 전체 대역폭을 입력값으로 사용하면 음향정보가 더욱 많아져 깨끗한 음성을 얻을 수 있음에도 불구하고, 일부값만이 활용되었습니다. 전체 값을 활용한 일부 연구에서는 합성 음성의 고주파수 대역이 흐릿해지는 문제(over smoothing)가 발생해, 음성에 지지직거리는 소리 등 잡음이 섞여 기대했던 것 이상의 음성 품질을 얻기 어려운 경우들이 있었습니다.&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈 연구팀은 이같은 문제를 해결하고자 새로운 뉴럴 보코더 방법론 ‘UnivNet’을 고안해, 실시간 서비스에서 더욱 깨끗한 음성을 제공하고자 하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-univnet-특징-소개&quot;&gt;2. UnivNet 특징 소개&lt;/h1&gt;

&lt;p&gt;먼저 UnivNet의 구조는 &lt;그림2&gt;와 같이 크게 생성기(generator)와 판별기(discriminator)로 구분됩니다. generator는 MelGAN 기반 구조이며, 여기에 더해 모델의 크기를 유지하면서도 효과적으로 로컬 정보를 확보하기 위해 LVC(Location-Variable Convolution)를 추가하였습니다. 이로 인해 mel-spectrogram의 지역별 정보를 효율적으로 모델에 제공하여, 더 적은 파라미터 수로도 더 높은 음질을 얻을 수 있었습니다. 또한, 효율적인 연산을 위해 GAU(Gated Activation Unit)를 더했습니다.&lt;/그림2&gt;&lt;/p&gt;

&lt;p&gt;다음으로 discriminator에서는 generator에서 생성된 가짜 데이터와 실제 데이터를 구별하도록 학습을 진행합니다. 여기서 주목할 점은 multi-resolution spectrogram discriminator(이하 MRSD)를 사용했다는 것입니다. MRSD는 다양한 STFT 파라미터셋을 사용하여 실제 데이터와 생성된 가짜 데이터의 여러 선형 스펙트로그램 크기들을 계산해, 각 하위 판별기에 입력값으로 활용합니다. 이때, STFT 파라미터셋에는 1)푸리에 변환 차수, 2)시간(frame) 이동 간격, 3)윈도우(window) 길이가 포함됩니다.&lt;/p&gt;

&lt;p&gt;UnivNet은 MRSD 구조를 통해 전체 대역폭 데이터가 가진 다양한 시간과 해상도(resolution) 정보를 사용하여 실제 사람 음성과 같은 높은 수준의 음성을 생성하고자 하였습니다. MRSD 구조는 MelGAN의 multi-scale waveform discriminator(MSWD) 구조에 기반하며, 여기에 시간 영역에서 적대적 모델링을 개선하기 위해 multi-period waveform discriminator(MPWD)를 더한 점이 특징입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-08-30-INTERSPEECH-UnivNet/002.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림2. UnivNet 구조&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-실험-결과&quot;&gt;3. 실험 결과&lt;/h1&gt;

&lt;h3 id=&quot;1-데이터-구성&quot;&gt;1) 데이터 구성&lt;/h3&gt;

&lt;p&gt;해당 실험에는 LibriTTS 데이터셋을 활용하였습니다. LibriTTS 데이터셋은 영어 오디오북 데이터셋으로, 이 중 192시간 분량, 11만 6천개의 발화, 904명의 화자 데이터로 구성된 ‘train-clean-360’을 바탕으로 모델 훈련을 진행하고, 이미 아는 화자(seen speaker)에 대한 평가를 진행하였습니다. 9시간 분량, 4천개의 발화, 39명의 화자 데이터로 구성된 ‘train-clean’ 데이터셋으로는 처음 보는 화자(unseen speaker)에 대한 평가를 진행하였습니다. 또한, TTS 성능 평가를 위해서는 24시간 분량, 1만 3천개 발화 데이터로 구성된 LJSpeech 데이터셋을 활용하였습니다. 해당 데이터셋은 영어로 구성된 단일 화자의 데이터셋입니다.&lt;/p&gt;

&lt;h3 id=&quot;2-ablation-study&quot;&gt;2) Ablation study&lt;/h3&gt;

&lt;p&gt;먼저 해당 모델의 자체 성능을 파악하기 위해 Ablation study를 진행하였습니다. 각 구성요소는 G1=LVC, G2=GAU, D1=MRSD, D2=MPWD, D3=MSWD와 같습니다. 여기서 주목할 점은 &lt;표1&gt;에서 D1(MRSD)이 제거되면 &lt;그림3&gt;의 왼쪽 그림과 같이 생성된 음성의 고주파수 대역이 흐릿해지는 문제가 발생한다는 점입니다. 제안하는 모델의 결과를 나타내는 &lt;그림3&gt;의 가운데 그림을 보면 이러한 문제가 개선되어 실제 녹음 음성의 고주파수 대역과 비슷해진 점을 볼 수 있습니다. 이를 통해 Univnet 모델에서 MRSD 구조가 가지는 중요성을 확인할 수 있었습니다.&lt;/그림3&gt;&lt;/그림3&gt;&lt;/표1&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-08-30-INTERSPEECH-UnivNet/003.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표1. Ablation study 결과&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-08-30-INTERSPEECH-UnivNet/004.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림3. 오디오 클립에서 생성된 스펙트로그램&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;3-기존-보코더-모델과-성능-비교&quot;&gt;3) 기존 보코더 모델과 성능 비교&lt;/h3&gt;

&lt;p&gt;다음으로는 generator의 채널 크기가 다른 두 가지 버전의 UnivNet(UnivNet-16, UnivNet-32)을 준비하여 GAN 기반 보코더(MelGAN, Parallel WaveGAN, HiFi-GAN)와 성능을 비교해보았습니다.&lt;/p&gt;

&lt;p&gt;보코더 자체의 성능을 평가하기 위해 실제 화자의 음성(Seen/Unseen speakers)에서 추출된 멜 스펙트로그램을 보코더를 이용하여 음성을 생성하는 과정을 진행하였습니다. &lt;표2&gt;를 보면 UnivNet-16은 학습 때 활용된 화자 데이터 외에 처음 보는 화자 데이터에서도 우수한 품질의 음성을 생성하였습니다. 기존 보코더 모델의 경우 새로운 화자가 추가될 때마다 모델을 추가 학습해야 하는 불편함이 있었지만, UnivNet은 처음 보는 화자 데이터에서도 우수한 성과를 보였다는 점에서 이같은 문제를 상당수 개선하였다고 볼 수 있습니다. 또한, UnivNet-32의 경우 전체 분야에서 기존 보코더 모델보다 높은 점수를 기록하고, 추론 속도도 다소 절감시키는 등 의미있는 결과값을 얻었습니다. 이어 진행된 TTS 성능 평가에서도 UnivNet-32은 우수한 성능을 보이며, 보코더 성능뿐만 아니라, 실제 TTS 구조 상에서도 높은 성능을 보여줌을 확인하였습니다.&lt;/표2&gt;&lt;/p&gt;

&lt;p&gt;해당 연구는 기존 보코더 모델보다 더 많은 대역폭을 쓰면서도 over-smoothing 문제 없이 더 깨끗한, 선명한 합성음을 얻었다는 점에서 의의가 있습니다. 또한, 음성 합성 분야에서 합성음의 품질뿐만 아니라, 중요한 추론 속도를 절감시켰다는 점도 주목할만합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-08-30-INTERSPEECH-UnivNet/005.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표2. 기존 보코더 모델과 성능 비교&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-향후-계획&quot;&gt;4. 향후 계획&lt;/h1&gt;

&lt;p&gt;향후 UnivNet은 카카오 i 서비스에 적용되어 실제 다수의 사용자를 대상으로 서비스될 예정입니다. 합성음의 명료도와 자연성이 실제 사람의 발화 수준과 동일할 정도로, 그 품질을 향상시키기 위해 지속 연구할 계획입니다. 또한, fine-tuning 과정 없이도 여러 화자의 TTS 파이프라인에 활용할 수 있는 유니버셜 보코더 연구를 진행하고자 합니다. 앞으로도 카카오엔터프라이즈의 음성처리 연구에 많은 관심 부탁드립니다. 감사합니다.&lt;/p&gt;</content><author><name>taylor:카카오엔터프라이즈</name></author><category term="papers" /><category term="INTERSPEECH" /><category term="UnivNet" /><category term="vocoder" /><summary type="html">Abstract</summary></entry><entry><title type="html">Auxiliary Sequence Labeling Tasks for Disfluency Detection</title><link href="https://kakaoenterprise.github.io/papers/interspeech2021-sl-tasks-for-disfluency-detection" rel="alternate" type="text/html" title="Auxiliary Sequence Labeling Tasks for Disfluency Detection" /><published>2021-08-30T00:00:00-05:00</published><updated>2021-08-30T00:00:00-05:00</updated><id>https://kakaoenterprise.github.io/papers/interspeech2021-sl-tasks-for-disfluency-detection</id><content type="html" xml:base="https://kakaoenterprise.github.io/papers/interspeech2021-sl-tasks-for-disfluency-detection">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Detecting disfluencies in spontaneous speech is an important preprocessing step in natural language processing and speech recognition applications. Existing works for disfluency detection have focused on designing a single objective only for disfluency detection, while auxiliary objectives utilizing linguistic information of a word such as named entity or part-of-speech information can be effective. In this paper, we focus on detecting disfluencies on spoken transcripts and propose a method utilizing named entity recognition(NER) and part-of-speech(POS) as auxiliary sequence labeling(SL) tasks for disfluency detection. First, we investigate cases that utilizing linguistic information of a word can prevent mispredicting important words and can be helpful for the correct detection of disfluencies. Second, we show that training a disfluency detection model with auxiliary SL tasks can improve its F-score in disfluency detection. Then, we analyze which auxiliary SL tasks are influential depending on baseline models. Experimental results on the widely used English Switchboard dataset show that our method outperforms the previous state-of-the-art in disfluency detection.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;그동안 카카오엔터프라이즈 AI Lab에서는 음성인식 영역과 자연어처리 분야에 활용 가능한 ‘사족제거(disfluency detection)’를 주제로, 연구를 진행해 왔습니다. 이번 INTERSPEECH 2021에서 NER(개체명 인식), POS(품사 태그) 정보를 활용해 사족제거 작업의 정확도를 높이는 새로운 방법론을 공개하게 되어, 해당 내용을 간략하게 소개드리고자 합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-사족제거-연구의-필요성&quot;&gt;1. 사족제거 연구의 필요성&lt;/h1&gt;

&lt;p&gt;먼저 사족제거 작업은 화자가 “음”, “아”와 같이 의미 없이 발화한 간투사를 교정하고, 발화 중 반복 사용한 표현들을 정제하는 과정을 말합니다. 예를 들어 “어… 오늘, 오늘은 날씨가 참 좋네”라는 문장에서 사족을 제거한다면, 별다른 의미를 가지지 않는 “어…”와 반복된 “오늘”을 삭제할 수 있습니다.&lt;/p&gt;

&lt;p&gt;실제 발화 상황에서는 이와 같은 간투사나 숨소리, 머뭇거림 등 음성 전사 후 언어를 처리하는데 불필요한 발화가 다수 포함될 수 있습니다. 이런 발화를 음성인식 모델이 인식하고, 음성번역, 언어이해 등 자연어 처리(NLP)를 하기 위해서는 이러한 사족을 제거하는 작업이 필수적입니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-기존-사족제거-연구의-한계&quot;&gt;2. 기존 사족제거 연구의 한계&lt;/h1&gt;

&lt;p&gt;기존 사족제거 연구는 word 단위의 자질(feature)을 각각 reparandum(RM), interregnum(IM), repair(RP)로 구분하여 우리가 제거해야할 대상(RM, IM)과 아닌 것(RP)을 명확히 파악하는데 초점을 두었습니다. IM에는 ‘음, 아’와 같은 간투사 표현들이 해당되고, 이들은 쉽게 구분되는 특성을 가졌기 때문에 IM보다는 주로 RM에 대한 예측정확도를 높이는데 중점을 둔 연구가 주를 이루고 있습니다. 여기서 RM은 쉽게 말해, 문장 시작에 들어가는 쿠션어, 반복어 표현들을 일컫는데, 먼저 입력된 값(RM)에 대해 오류라고 판단하고 뒤에 오는 값(RP)을 올바른 값으로 보았습니다. 기존 연구들은 이 RM을 파악하는데 목적을 두고, RM으로 분류된 정답 데이터를 학습하는 방식이 주로 활용되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-08-30-INTERSPEECH-SL-tasks-for-disfluency-detection/001.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림1. 기존 사족제거 연구의 어노테이션(annotation) 예시&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;하지만, 이와 같이 제거 대상만을 가려내는데 초점을 두면 중요한 의미를 가진 단어를 사족으로 오예측(false positive)하게 되고 예측정확도가 떨어질 수 있다는 한계점이 있습니다. 이에, 카카오엔터프라이즈 연구팀은 추가적인  정보들을 학습시켜 예측 성능을 높이는 방법론을 고안하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-auxiliary-sequence-labeling-tasks-방법론-소개&quot;&gt;3. Auxiliary Sequence Labeling Tasks 방법론 소개&lt;/h1&gt;

&lt;p&gt;카카오엔터프라이즈 연구팀이 새롭게 제안하는 방법론은 ‘Auxiliary Sequence Labeling Tasks’입니다. 기존 연구에서 추가적인 정보로 NER(개체명 인식, Named Entity Recognition), POS(품사 태그, Part-Of-Speech)를 Multi-Task Learning 방식에 활용해, 총 3개의 목적함수를 사용하여 학습을 진행하였습니다.&lt;/p&gt;

&lt;p&gt;좀 더 자세히 살펴보면, 먼저 NER은 해당 단어의 개체명(Entity Name)이 인명, 장소, 시간 표현 등을 정의하는 과제(task)입니다.  그림2를 예시로 보면 NER 정보는 초록색으로 나타납니다. 기존 연구에서는 사족에 해당하는 ‘i would’를 명확히 파악하지 못하고, 오히려 문장의 중요한 의미를 담고 있는 ‘my forty’를 사족으로 오예측하였습니다. 본 연구에서는 이처럼 중요한 의미를 갖는 단어의 오예측을 방지하고, 정확한 사족 예측이 가능해지도록 NER 정보를 학습에 활용했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-08-30-INTERSPEECH-SL-tasks-for-disfluency-detection/002.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림2. NER 정보 예시 (초록색이 NER에 해당하며, 파란색이 사족에 해당함)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;또한, 추가적으로 사용된 POS는 각 문장 성분의 품사 태그 정보를 의미합니다. 그림3에서는 RM과 RP의 POS가 동일한 태그 형태를 가질 때, 보다 정확한 사족 예측이 가능함을 보여줍니다. 기존 연구에서도 POS를 활용한 연구들은 진행되었지만, rule-base 방식의 경우 단어 의미가 담긴 시맨틱 정보가 제대로 반영되지 않는다는 한계가 있었고, ML방식의 경우 추론(inference) 시 해당 입력 단어들에 대한 feature를 추출하기 위한 추가 시간이 소요된다는 문제가 있었습니다. 카카오엔터프라이즈 연구팀은 POS와 NER 정보를 추가 활용하는 Auxiliary Sequence Labeling Tasks 방법론을 새롭게 제안하여 그동안의 문제점들을 해결하고 더 높은 성능을 얻고자 하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-08-30-INTERSPEECH-SL-tasks-for-disfluency-detection/003.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;그림3. POS 정보 예시&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;본 연구에서는 사족제거, NER, 그리고 POS태그들을 예측을 위해 3가지의 negative log likelihood loss 함수를 사용하였습니다. 사족제거, NER, 그리고 POS 테스크를 위한 loss 함수들을 각각 Ld, Le, Lp라고 정의할때, 최종 loss 함수는 L= Ld + *(Le +Lp)로 정의합니다. 여기서  는 계수(coefficients)로써, NER과 POS 테스크들의 영향도를 학습에 얼마나 반영할지 결정하는 요소입니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-성능-평가&quot;&gt;4. 성능 평가&lt;/h1&gt;

&lt;p&gt;제안한 방법의 성능평가를 위해 기존 연구와의 모델 성능비교와 학습요소별 성능비교 2가지 방식을 이용하였습니다. 먼저 동일한 CRF Layer(Decoder)에 입력 자질(feature input)로 사전훈련된 언어모델 transformer, BERT, ELECTRA의 최종 output layer를 사용하여 각각의 성능을 비교해 보았습니다. 현재 성능 테스트에 많이 활용되고 있는 English Switchboard 데이터셋을 활용하여 테스트해본 결과, F1 score에서 기존 연구 모델보다 평균적으로 높은 수치를 기록하는 것을 확인할 수 있었고, 최고치의 경우 93.1(ELECTRA)에 달하는 우수한 결과를 얻었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-08-30-INTERSPEECH-SL-tasks-for-disfluency-detection/004.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표1. 기존 방식으로 학습된 모델과 Auxiliary SL(Sequence Labeling) Tasks 방식으로 학습된 모델의 성능 비교&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;다음으로, 동일한 English Switchboard 데이터셋을 이용해 Ablation 분석을 진행하였습니다. 1)기존 연구 방식으로 학습된 모델, 2)NER을 추가한 경우, 3)POS를 추가한 경우, 4)AUXILIARY SL Tasks 방식(NER과 POS를 모두 추가, SL : Sequence Labeling)을 각각 비교해 보았습니다. 표2에서 볼 수 있듯이 추가 정보를 모두 활용한 경우가 F1 score에서 가장 높은 수치를 기록하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-08-30-INTERSPEECH-SL-tasks-for-disfluency-detection/005.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표2. Ablation Analysis 분석 결과&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이를 통해 추가 정보를 활용하여 목적함수를 확대하는 것이 실제 성능에 영향력을 미친다는 것을 확인할 수 있었다는 점에서 해당 연구가 갖는 의의가 크다고 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;추론에서도 본 연구의 장점이 있습니다. 기존의 연구에서도 이와 비슷하게 모델의 입력으로 단어의 NER과 POS와 같은 추가 자질들을 사용하는 방법들이 있었지만, 이러한 방법들은 추론시, 단어의 자질들을 추출하는데 추가 시간이 필요한 단점이 있습니다.하지만 본 연구에서는 NER와 POS tasks를 학습시간에만 활용하고, 추론시에는 사용을 하지 않기 때문에 추론 시간을 단축시키는 효과가 있습니다. 그 결과, 아래의 표3과 같이 추론을 위해 추가적으로 요구되는 시간은 없다는 것을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-08-30-INTERSPEECH-SL-tasks-for-disfluency-detection/006.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;표3. Auxiliary SL Tasks를 활용한 방식(Ours)과 활용하지 않은 방식(Ours w/o aux)간의 추론 속도 비교&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5-향후-연구-계획&quot;&gt;5. 향후 연구 계획&lt;/h1&gt;

&lt;p&gt;해당 연구는 현재 헤이카카오앱 중 받아쓰기 기능에 적용되었고, 녹음 내용을 전사한 결과에 사족제거기능으로 활용되고 있습니다. 향후 한국어 서비스 고도화를 위해 한국어용 사족제거 모델 개선에 집중하고 유의미한 성능을 얻을 수 있도록 연구를 발전시켜나갈 계획입니다. 앞으로도 많은 관심 부탁드립니다. 감사합니다.&lt;/p&gt;</content><author><name>이동엽:카카오</name></author><category term="papers" /><category term="INTERSPEECH" /><category term="NLP" /><category term="Disfluency-detection" /><summary type="html">Abstract</summary></entry></feed>