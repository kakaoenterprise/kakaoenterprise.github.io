<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/feed.xml" rel="self" type="application/atom+xml" /><link href="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/" rel="alternate" type="text/html" /><updated>2021-05-13T23:36:51-05:00</updated><id>https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/feed.xml</id><title type="html">Kakao Enterprise AI Research</title><subtitle>카카오엔터프라이즈 연구 성과를 공개하는 리서치 플랫폼</subtitle><author><name>카카오엔터프라이즈</name></author><entry><title type="html">ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision</title><link href="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/icml-vilt" rel="alternate" type="text/html" title="ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision" /><published>2021-07-18T00:00:00-05:00</published><updated>2021-07-18T00:00:00-05:00</updated><id>https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/icml-vilt</id><content type="html" xml:base="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/icml-vilt">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Vision-and-Language Pretraining (VLP) has improved performance on various joint vision-andlanguage downstream tasks. Current approaches to VLP heavily rely on image feature extraction processes, most of which involve region supervision (e.g., object detection) and the convolutional architecture (e.g., ResNet). Although disregarded in the literature, we find it problematic in terms of both (1) efficiency/speed, that simply extracting input features requires much more computation than the multimodal interaction steps; and (2) expressive power, as it is upper bounded to the expressive power of the visual encoder and its predefined visual vocabulary. In this paper, we present a minimal VLP model, Vision-andLanguage Transformer (ViLT), monolithic in the sense that processing of visual inputs is drastically simplified to just the same convolution-free manner that we process textual inputs. We show that ViLT is up to 60 times faster than previous VLP models, yet with competitive or better downstream task performance.&lt;/p&gt;</content><author><name>dandelin:카카오</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">OutFlip: Generating Examples for Unknown Intent Detection with Natural Language Attack</title><link href="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/acl-ijcnlp2021-outflip" rel="alternate" type="text/html" title="OutFlip: Generating Examples for Unknown Intent Detection with Natural Language Attack" /><published>2021-07-01T00:00:00-05:00</published><updated>2021-07-01T00:00:00-05:00</updated><id>https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/acl-ijcnlp2021-outflip</id><content type="html" xml:base="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/acl-ijcnlp2021-outflip">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Out-of-domain (OOD) input detection is vital in a task-oriented dialogue system since the acceptance of unsupported inputs could lead to an incorrect response of the system. This paper proposes OutFlip, a method to generate out-of-domain samples using only in-domain training dataset automatically. A white-box natural language attack method HotFlip is revised to generate out-of-domain samples instead of adversarial examples. Our evaluation results showed that integrating OutFlip-generated out-of-domain samples into the training dataset could significantly improve an intent classification model’s out-of-domain detection performance.&lt;/p&gt;</content><author><name>heuristic:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">Multitask Learning and Joint Optimization For Transformer-Rnn-Tranducer Speech Recognition</title><link href="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/icassp2021-transformer-rnn-tranducer-speech-recognition" rel="alternate" type="text/html" title="Multitask Learning and Joint Optimization For Transformer-Rnn-Tranducer Speech Recognition" /><published>2021-06-13T00:00:00-05:00</published><updated>2021-06-13T00:00:00-05:00</updated><id>https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/icassp2021-transformer-rnn-tranducer-speech-recognition</id><content type="html" xml:base="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/icassp2021-transformer-rnn-tranducer-speech-recognition">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Recently, several types of end-to-end speech recognition methods named transformer-transducer were introduced. According to those kinds of methods, transcription networks are generally modeled by transformer-based neural networks, while prediction networks could be modeled by either transformers or recurrent neural networks (RNN). This paper explores multitask learning, joint optimization, and joint decoding methods for transformer-RNN-transducer systems. Our proposed methods have the main advantage in that the model can maintain information on the large text corpus. We prove their effectiveness by performing experiments utilizing the well-known ESPNET toolkit for the widely used Librispeech datasets. We also show that the proposed meth- ods can reduce word error rate (WER) by 16.6 % and 13.3 % for test-clean and test-other datasets, respectively, with- out changing the overall model structure nor exploiting an external LM.&lt;/p&gt;</content><author><name>jeffrey:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">U-Convolution Based Residual Echo Suppression With Multiple Encoders</title><link href="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/icassp2021-u-convolution-based-residual-eco-suppression" rel="alternate" type="text/html" title="U-Convolution Based Residual Echo Suppression With Multiple Encoders" /><published>2021-06-13T00:00:00-05:00</published><updated>2021-06-13T00:00:00-05:00</updated><id>https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/icassp2021-u-convolution-based-residual-eco-suppression</id><content type="html" xml:base="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/icassp2021-u-convolution-based-residual-eco-suppression">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;In this paper, we propose an efficient end-to-end neural network that can estimate near-end speech using a U- convolution block by exploiting various signals to achieve residual echo suppression (RES). Specifically, the proposed model employs multiple encoders and an integration block to utilize complete signal information in an acoustic echo can- cellation system and also applies the U-convolution blocks to separate near-end speech efficiently. The proposed network affords an improvement in the perceptual evaluation of speech quality (PESQ) and the short-time objective intelligi- bility (STOI), as compared to baselines, in scenarios involving smart audio devices. The experimental results show that the proposed method outperforms the baselines for various types of mismatched background noise and environmental reverberation, while requiring low computational resources.&lt;/p&gt;</content><author><name>chris:카카오엔터프라이즈</name></author><category term="papers" /><summary type="html">Abstract</summary></entry><entry><title type="html">210521</title><link href="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/deepdive/210521" rel="alternate" type="text/html" title="210521" /><published>2021-05-21T00:00:00-05:00</published><updated>2021-05-21T00:00:00-05:00</updated><id>https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/deepdive/210521</id><content type="html" xml:base="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/deepdive/210521"></content><author><name>카카오엔터프라이즈</name></author><category term="deepdive" /><summary type="html"></summary></entry><entry><title type="html">Suppressing Spoof-irrelevant Factors for Domain-agnostic Face Anti-spoofing</title><link href="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/ieeeaccess-face-anti-spoofing" rel="alternate" type="text/html" title="Suppressing Spoof-irrelevant Factors for Domain-agnostic Face Anti-spoofing" /><published>2021-04-30T00:00:00-05:00</published><updated>2021-04-30T00:00:00-05:00</updated><id>https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/ieeeaccess-face-anti-spoofing</id><content type="html" xml:base="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/ieeeaccess-face-anti-spoofing">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Face anti-spoofing aims to prevent false authentications of face recognition systems by distinguishing whether an image is originated from a human face or a spoof medium. In this work, we note that images from unseen domains having different spoof-irrelevant factors (e.g., background patterns and subject) induce domain shift between source and target distributions. Also, when the same SiFs are shared by the spoof and genuine images, they show a higher level of visual similarity and this hinders accurate face anti-spoofing. Hence, we aim to minimize the discrepancies among different domains via alleviating the effects of SiFs, and achieve improvements in generalization to unseen domains. To realize our goal, we propose a novel method called a Doubly Adversarial Suppression Network (DASN) that is trained to neglect the irrelevant factors and to focus more on faithful task-relevant factors. Our DASN consists of two types of adversarial learning schemes. In the first adversarial learning scheme, multiple SiFs are suppressed by deploying multiple discrimination heads that are trained against an encoder. In the second adversarial learning scheme, each of the discrimination heads is also adversarially trained to suppress a spoof factor, and the group of the secondary spoof classifier and the encoder aims to intensify the spoof factor by overcoming the suppression. We evaluate the proposed method on four public benchmark datasets, and achieve remarkable evaluation results in generalizing to unseen domains. The results demonstrate the effectiveness of the proposed method.&lt;/p&gt;</content><author><name>김태욱:카카오엔터프라이즈</name></author><category term="papers" /><category term="face anti-spoofing" /><summary type="html">Abstract</summary></entry><entry><title type="html">RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases</title><link href="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/cljournal2021-ryansql" rel="alternate" type="text/html" title="RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases" /><published>2021-03-26T00:00:00-05:00</published><updated>2021-03-26T00:00:00-05:00</updated><id>https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/cljournal2021-ryansql</id><content type="html" xml:base="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/cljournal2021-ryansql">&lt;p&gt;스파이더 챌린지&lt;sup&gt;SPIDER Text-to-SQL Challenge&lt;/sup&gt; 성과를 정리한 공동 연구 논문이 Computational Linguistics에 실렸습니다. 미국 예일대학교에서 주최한 스파이더 챌린지는 각종 데이터를 정리∙보관할 때 사용하는 데이터베이스와 자연어 형태의 사용자 질의가 주어졌을때, 이 질의문을 SQL&lt;sup&gt;Structured Query Language&lt;/sup&gt;&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;문으로 변환해주는 Text-to-SQL&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 알고리즘의 정확도를 평가합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-03-26-cljournal-ryansql/001.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ 표 1 ] 주어진 자연어 문장과 데이터베이스를 이용해 SQL 문을 생성하는 예시&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;자연어 질의문을 SQL 문으로 변환하는 데에는 스케치 기반 슬롯 채우기&lt;sup&gt;sketch-based Slot Filling&lt;/sup&gt;가 주로 활용돼 왔습니다. SELECT&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; 문에 몇 개의 열&lt;sup&gt;column&lt;/sup&gt;을 입력해야 하는지, 어떤 열을 선택해야 하는지, 집계 함수&lt;sup&gt;aggregator&lt;/sup&gt;&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;로 무엇을 써야 하는지 등 판별해야 할 정보&lt;sup&gt;slot&lt;/sup&gt;를 먼저 구분하고 나서, 각 정보의 값을 채워넣는 식입니다. 다만 이 방식으로는 쿼리 속에 또 다른 쿼리가 든 중첩 질의&lt;sup&gt;nested query&lt;/sup&gt;를 생성하는 데 한계가 있습니다. SELECT 문의 개수가 정해지지 않아서 전체 설계도 자체를 그릴 수 없기 때문입니다.&lt;/p&gt;

&lt;p&gt;공동 연구팀이 제안한 Text-to-SQL 알고리즘인 RYQNSQL&lt;sup&gt;Recursively Yielding Annotation Network for SQL&lt;/sup&gt;은 대규모 영어 비라벨링 말뭉치를 사전학습한 언어 모델인 BERT에 자체 고안한 SPC&lt;sup&gt;Statement Position Code&lt;/sup&gt; 기법을 적용했습니다. SPC는 슬롯을 채울 때 중첩된 SELECT문을 좀 더 정확하게 생성할 수 있도록 합니다. 실험 결과, 스파이더 벤치마크 데이터셋에 대해 현재 최고 성능의(SOTA)&lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; 모델보다 3.2%p 더 높은 58.2%의 정확도를 달성했습니다.&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈는 데이터의 스키마(테이블 이름, 열 이름)뿐만 아니라 실제 값도 활용하는 방식 등으로 자사 Text-to-SQL 알고리즘의 성능과 사용성을 높여 기업 데이터베이스 활용의 문턱을 낮추는 데 기여할 계획입니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;overall-architecture&quot;&gt;Overall Architecture&lt;/h1&gt;

&lt;p&gt;Figure 1 shows the overall network architecture of the input encoder. The input encoder consists of five layers: Embedding layer, Embedding Encoder layer, Question-Column Alignment layer, Table Encoder layer, and Question-Table Alignment layer. Table 1 shows the proposed sketch for a SELECT statement. The sketch-based slot-filling decoder predicts values for slots of the proposed sketch, as well as the number of slots.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-03-26-cljournal-ryansql/002.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ Figure 1 ] Network architecture of the proposed input encoder. S represents self-attention.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-03-26-cljournal-ryansql/003.png&quot; width=&quot;80%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ table 1 ] Proposed sketch for a SELECT statement. $TBL and $COL represent a table and a column, respectively. $AGG is one of {none, max, min, count, sum, avg}, $ARI is one of the arithmetic operators {none, -, +, *, / }, and $COND is one of the conditional operators {between, =, &amp;gt;, &amp;lt;, &amp;gt;=, &amp;lt;=, !=, in, like, is, exists}. $DIST and $NOT are boolean variables representing the existence of keywords DISTINCT and NOT, respectively. $ORD is a binary value for keywords ASC/DESC, and $CONJ is one of conjunctions {AND, OR}. $VAL is the value for WHERE/HAVING condition; $SEL represents the slot for another SELECT statement.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;experiments&quot;&gt;Experiments&lt;/h1&gt;

&lt;p&gt;Table 2 shows that the proposed system RYANSQL improves the previous sketch-based slot filling system RCSQL by a large margin of 15% on the dev set. Note that the RCSQL fine-tuned another well known pretrained language model ELMo. With the use of BERT, among the systems without database content, the proposed systems (RYANSQL + BERT and RYANSQL v2 + BERT) outperforms the previous state-of-the-art by 2.5% and 4.9% respectively on the hidden test dataset. The proposed system still shows competitive results compared to the systems using database content; RATSQL v3 + BERT outperforms the proposed system by better aligning user questions and database schemas using database content.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-03-26-cljournal-ryansql/005.png&quot; width=&quot;90%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ Table 2 ] Evaluation results of the proposed systems and other state-of-the-art systems.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We evaluated the proposed models on the CSpider dataset. CSpider is a chinese-translated version of the Spider benchmark. Only the question of the spider dataset is translated; database table names and column names remain as English. Evaluation on the CSpider dataset will show if the proposed model could be applied on the different languages, even when the question language and database schema language are different. To handle the case, we used multilingual BERT, which has the same network architecture with BERT-base but is trained using multilingual corpus.&lt;/p&gt;

&lt;p&gt;The results are shown in Table 3. Compared to the exact matching accuracy 51.4% of RYANSQL + BERT-base on Spider dataset, the multilingual version shows 10% lower accuracy on dev set, but still shows comparable results to other state-of-the-art systems which are designed for CSpider dataset. Our proposed system showed 34.7% test accuracy on the test set, and ranked at 2nd place on the leaderboard.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-03-26-cljournal-ryansql/005.png&quot; width=&quot;90%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em class=&quot;center&quot;&gt;[ Table 3 ] Evaluation results on CSpider dataset with other state-of-the-art systems.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;footnote&quot;&gt;footnote&lt;/h3&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;관계형 데이터베이스 관리를 위해 설계된 특수목적의 프로그래밍 언어 &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;NLI2DB&lt;sup&gt;natural language interface to databases&lt;/sup&gt;라고도 부른다. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;테이블 전체 또는 일부 열과 행 값을 호출하는 명령어 &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;값 집합에 대한 산술적인 계산(레코드의 수, 값의 합, 값의 평균, 최대값, 최소값)의 결과값을 출력한다. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;논문 제출 시점(2020년 4월) 최고 성능 &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>heuristic:카카오엔터프라이즈</name></author><category term="papers" /><category term="NLI2DB" /><category term="Text-to-SQL" /><summary type="html">스파이더 챌린지SPIDER Text-to-SQL Challenge 성과를 정리한 공동 연구 논문이 Computational Linguistics에 실렸습니다. 미국 예일대학교에서 주최한 스파이더 챌린지는 각종 데이터를 정리∙보관할 때 사용하는 데이터베이스와 자연어 형태의 사용자 질의가 주어졌을때, 이 질의문을 SQLStructured Query Language1문으로 변환해주는 Text-to-SQL2 알고리즘의 정확도를 평가합니다. 관계형 데이터베이스 관리를 위해 설계된 특수목적의 프로그래밍 언어 &amp;#8617; NLI2DBnatural language interface to databases라고도 부른다. &amp;#8617;</summary></entry><entry><title type="html">A Plug-in Method for Representation Factorization in Connectionist Models</title><link href="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/ieee2020-fden" rel="alternate" type="text/html" title="A Plug-in Method for Representation Factorization in Connectionist Models" /><published>2021-02-10T00:00:00-06:00</published><updated>2021-02-10T00:00:00-06:00</updated><id>https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/ieee2020-fden</id><content type="html" xml:base="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/ieee2020-fden">&lt;p&gt;일반적으로 딥러닝 모델의 성능은 과제를 수행하는 데 필요한 필수 정보를 추출하고 이를 최대한 압축한 임베딩 벡터&lt;sup&gt;embedding vector&lt;/sup&gt;를 제대로 표현하는 능력에 있다고 해도 과언이 아닙니다. 다만 각 차원이 여러 요인을 함축적으로 포함하는 그 특성상, 사람이 벡터를 해석하는 데에는 한계가 있습니다. 머리 색, 머리 길이, 얼굴형, 눈썹 모양, 얼굴색 등이 얼굴을 구성하는 요소라고 본다면, 딥러닝 모델이 생성한 벡터는 차원1-머리색/머리길이, 차원2-머리길이/얼굴색 등으로 여러 차원에 여러 요인이 복잡하게 얽혀 있죠.&lt;/p&gt;

&lt;p&gt;이에 데이터를 독립 요인&lt;sup&gt;independent factor&lt;/sup&gt;에 상응하는 해석 가능한 표현&lt;sup&gt;disentangled representation&lt;/sup&gt;으로 만드는 방법에 관한 연구가 활발하게 이뤄지고 있습니다. 공동 연구팀 또한 이 대열에 합류, 총 상관계수&lt;sup&gt;total correlation&lt;/sup&gt;&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;를 최소화하는 방식으로 의미상 제어할 수 있는 요인으로 임베딩 벡터를 분해하는 기법인 FDEN&lt;sup&gt;Factors Decomposer-Entangler Network&lt;/sup&gt;을 제안했습니다.&lt;/p&gt;

&lt;p&gt;FDEN은 학습된 모델&lt;sup&gt;pre-trained model&lt;/sup&gt;의 가중치&lt;sup&gt;weight&lt;/sup&gt; 값을 변경하지 않고도 사용할 수 있는 플러그인&lt;sup&gt;plug-in&lt;/sup&gt; 방식으로 동작합니다. 모델이 추출한 임베딩 벡터에서 요인에 영향을 미치는 부분을 찾아내는(해석하는) 별도의 단계를 뒀다는 의미입니다. 이 덕분에 우수한 성능을 내는 여러 학습 모델에 바로 적용해볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-02-10-IEEE-FDEN/001.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ 그림 1 ] 가중치를 고정한 사전학습한 모델에 플러그인 방식으로 동작하는 FDEN은 출력된 임베딩 벡터 z를 해석가능한 표현 \(\tilde{z}\)로 바꾼다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;연구팀은 스타일 변환&lt;sup&gt;style transfer&lt;/sup&gt;, 이미지 간 번역&lt;sup&gt;image-to-image translation&lt;/sup&gt;, 퓨샷 러닝&lt;sup&gt;few-shot learning&lt;/sup&gt; 등 다양한 태스크에서 우수한 성능을 내는 모델에 FDEN을 적용했습니다. 그 결과, FDEN은 사람이 라벨링한 요인을 효과적으로 분해할 수 있었습니다. 독립 요인(\(f_0\)+\(f_1\)+\(f_2\)…+\(f_n\))을 합쳐 기존 데이터(\(z\))와 유사한 데이터(\(\tilde{z}\))도 생성할 수 있음을 확인했습니다. 이는 사람이 해석 가능한 독립 요인을 조절해 새로운 데이터 혹은 사람이 원하는 데이터를 만들어낼 수 있음을 시사합니다.&lt;/p&gt;

&lt;p&gt;연구팀은 비지도학습&lt;sup&gt;unsupervised learning&lt;/sup&gt;&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;을 이용해 사람이 찾지 못한 요인을 섬세하게 분해할 방법론에 관한 연구를 진행할 계획입니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;overall-architecture&quot;&gt;Overall Architecture&lt;/h1&gt;

&lt;p&gt;The objective of FDEN is to decompose input representation \(z\) into independent and semantically interpretable factors without losing the original information in the latent or feature representation \(z\). To achieve this aim, we compose an FDEN with three modules (Figure. 1): Decomposer \(D\), Factorizer \(F\), and Entangler \(E\). Note that because FDEN uses a fixed pretrained network and deals with the latent or feature representation from the network, it allows factorizing the input representation for other new tasks while maintaining the network capacity or power for its original tasks intact.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-02-10-IEEE-FDEN/002.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ Figure 1 ] FDEN is divided into three modules: Decomposer \(D\), Factorizer \(F\), and Entangler \(E\). The model is an autoencoder-like architecture that takes representation \(z\) as the input and reconstructs its original representation (\(\tilde{z}\)). (a) First, Decomposer \(D\) takes a representation \(z\) from a fixed pretrained network as the input and decomposes it into a set of factors \(f_i\) (\(∀_i\) ∈ \(N\)). (b) Next, Factorizer \(F\) uses an information theoretic way to maximize the independence of each factor. (c) Finally, Entangler \(E\) takes the factors and reconstructs their original representation (\(\tilde{z}\)).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;experiments&quot;&gt;Experiments&lt;/h1&gt;

&lt;p&gt;Our objective here is to demonstrate that each module of FDEN is effective at decomposing a latent representation into independent factors. First, we evaluate the effectiveness of factors by performing various downstream tasks. Next, we analyze individual units of factors to verify if a representation is indeed reasonably factorized.  We perform style transfer with human labeled attributes (Fig. 2). The results of style transfer with FDEN confirms a clear transfer of attributes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-02-10-IEEE-FDEN/003.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ Figure 2 ] Results of style transfer for the CelebA-128 dataset with N=7 factors (where \(f_0\) is the style factor). Images in the first and second columns are reconstructed images from Pioneer Network and FDEN, respectively. The following images are reconstructed images with one attribute opposite to the input image (e.g., \(1{^{st}}\) row \(f_3\): “not bald” transferred to “bald”; \(2{^{nd}}\) row \(f_3\): “young” transferred to “not young”). The original attributes of both input images are: “not bald”, “male”, “young”, “without smile”, “without beard”, “without eyeglasses” (note that the 1st row image is annotated as “with goatee, but without beard”).&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;주어진 요인의 독립성&lt;sup&gt;independence&lt;/sup&gt;를 직접 계산할 수 있는 수치 &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;사람이 라벨링하지 않은 데이터를 이용한 학습 방법 &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>윤재석:고려대학교</name></author><category term="papers" /><category term="disentangled representation" /><category term="factorial representation" /><summary type="html">일반적으로 딥러닝 모델의 성능은 과제를 수행하는 데 필요한 필수 정보를 추출하고 이를 최대한 압축한 임베딩 벡터embedding vector를 제대로 표현하는 능력에 있다고 해도 과언이 아닙니다. 다만 각 차원이 여러 요인을 함축적으로 포함하는 그 특성상, 사람이 벡터를 해석하는 데에는 한계가 있습니다. 머리 색, 머리 길이, 얼굴형, 눈썹 모양, 얼굴색 등이 얼굴을 구성하는 요소라고 본다면, 딥러닝 모델이 생성한 벡터는 차원1-머리색/머리길이, 차원2-머리길이/얼굴색 등으로 여러 차원에 여러 요인이 복잡하게 얽혀 있죠.</summary></entry><entry><title type="html">Multi-level Distance Regularization for Deep Metric Learning</title><link href="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/aaai2021-mdr" rel="alternate" type="text/html" title="Multi-level Distance Regularization for Deep Metric Learning" /><published>2021-02-02T00:00:00-06:00</published><updated>2021-02-02T00:00:00-06:00</updated><id>https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/aaai2021-mdr</id><content type="html" xml:base="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/aaai2021-mdr">&lt;p&gt;딥러닝 기반 거리 학습(DML&lt;sup&gt;Deep Metric Learning&lt;/sup&gt;)은 주어진 두 데이터 간 의미적인 거리&lt;sup&gt;pairwise distance&lt;/sup&gt;를 학습하는 방법입니다. 특히 입력 이미지와 유사한 이미지를 찾는 데 효과적인 이 기술은 이미지 검색&lt;sup&gt;image retrieval&lt;/sup&gt;, 상품 추천, 얼굴 인식&lt;sup&gt;face recognition&lt;/sup&gt;과 같은 태스크에서 핵심적으로 활용되고 있습니다.&lt;/p&gt;

&lt;p&gt;선행 연구에서는 같은 범주의 이미지 간 거리는 더 가깝게, 범주가 다른 이미지의 거리는 더 멀게 만드는 손실 함수&lt;sup&gt;loss function&lt;/sup&gt; 재정의에 집중했습니다. 다만 거리가 아닌 임베딩 벡터&lt;sup&gt;embedding vector&lt;/sup&gt;를 제약하는 L2 정규화&lt;sup&gt;L2 normalization&lt;/sup&gt;&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;로는 직접적인 거리 정규화가 어려워서 모델이 쉽게 과적합&lt;sup&gt;overfitting&lt;/sup&gt;&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;되는 문제가 있었습니다.&lt;/p&gt;

&lt;p&gt;이에 공동 연구팀은 DML에 더 적합한 새로운 거리 정규화 기법인 MDR&lt;sup&gt;Multi-level Distance Regularization&lt;/sup&gt;을 제안했습니다. MDR은 데이터 간의 거리 분포를 여러 부분으로 나눈 뒤 각 부분을 대표하는 레벨&lt;sup&gt;level&lt;/sup&gt;을 학습하고, 각 레벨에 속하는 두 쌍의 데이터 간 거리를 정규화합니다. MDR는 기존 손실 함수와 함께(jointly) 동작하며 쉬운 샘플&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;이 학습에 영향을 주지 못하거나 어려운 샘플&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;이 학습을 지배하는 현상을 방지합니다.&lt;/p&gt;

&lt;p&gt;트리플릿 손실 함수&lt;sup&gt;Triplet loss function&lt;/sup&gt;에 MDR을 적용해본 결과, 주요 벤치마크 데이터셋에서 유의미한 성능 향상을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈는 이번 연구로 얻은 기술력과 경험을 바탕으로 상품 추천, 얼굴 인식 등 관련 기술을 고도화할 계획입니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p class=&quot;tech-ground&quot;&gt;☛ Tech Ground 데모 페이지 바로 가기 : &lt;b&gt;&lt;a href=&quot;https://labs.kakaoi.ai/facedetection&quot;&gt;얼굴 검출&lt;/a&gt;&lt;/b&gt; 데모&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;overall-architecture&quot;&gt;Overall Architecture&lt;/h1&gt;

&lt;p&gt;At first, MDR normalizes pairwise distances among the embedding vectors of a mini-batch, with their mean and standard deviation to obtain the objective degree of similarity between a pair by considering overall distribution. MDR defines the multiple levels that represent various degrees of similarity for pairwise distances, and the levels and the be- longing distances are trained to approach each other (Figure 1b). A conventional loss function of DML struggles to optimize a model by overcoming the disturbance from the proposed regularization. Therefore, the learning process succeeds in learning a model with a better generalization ability.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-02-02-AAAI-mdr/001.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ Figure 1 ] Conceptual comparison between the conventional learning scheme and our learning scheme. (a) illustrates the triplet learning, which is one of the representative conventional learning. It increases the relative difference between distances of a positive pair and that of a negative pair more than margin m. (b) illustrates our learning combined with the triplet learning. It has multiple levels with disjoint intervals to reflect various degrees of similarity between pairs. It disturbs the learning procedure to construct an efficient embedding space by preventing the pairwise distances from deviating from its belonging level.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-02-02-AAAI-mdr/002.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ Figure 2 ] Learning procedure of the proposed MDR. The embedding network generates embedding vectors from given images. Our MDR computes a matrix of pairwise distances for the embedding vectors, and then, the distances are normalized after vectorization. In our learning scheme, a model is trained by simultaneously optimizing the conventional metric learning loss such as Triplet loss (Schroff, Kalenichenko, and Philbin 2015) and the proposed loss, which regularizes the normalized pairwise distances with multiple levels.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;experiments&quot;&gt;Experiments&lt;/h1&gt;

&lt;p&gt;We employ the four standard datasets of deep metric learning for evaluations: CUB-200-2011 (CUB-200), Cars-196, Stanford Online Product (SOP) and In-Shop Clothes Retrieval (In-Shop). Our method significantly outperforms the other state-of-the-art methods in all recall criteria for all datasets.&lt;/p&gt;

&lt;p&gt;We prove the effectiveness of MDR by showing the improvements that greatly exceed the existing methods, and by extensively performing the ablation studies of its behaviors. By applying our MDR, many methods can be significantly improved without any extra burdens at inference time.&lt;/p&gt;

&lt;p&gt;Moreover, our extensive ablation studies show that MDR can be adopted to any backbone networks and any distance-based loss functions to improve the performance of a model.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-02-02-AAAI-mdr/003.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-02-02-AAAI-mdr/004.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ Table 1 ] Recall@K comparison with state-of-the-art methods. The baseline methods and MDR are grouped in the gray-colored rows. † indicates that the model is trained and tested with large images of 256 × 256 following the setting of (Jacob et al. 2019). We round reported values to the first decimal place.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-02-02-AAAI-mdr/005.png&quot; width=&quot;85%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ Figure 3 ] Class centers in the embedding space of two models trained without MDR (Triplet &amp;amp; Triplet+L2 Norm) and one model trained with MDR (Triplet+MDR). We visualize using t-SNE on CUB-200.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-02-02-AAAI-mdr/006.png&quot; width=&quot;70%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ Table 2 ] Recall@1 comparison with various backbone net- works, loss functions, and level configurations. The models of (a) are trained with Triplet loss. The models of (b) use IBN as the backbone network. In (a) and (b), a column with ✓ indicates that the models are trained with MDR.&lt;/em&gt; &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-02-02-AAAI-mdr/007.png&quot; width=&quot;50%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-02-02-AAAI-mdr/008.png&quot; width=&quot;55%&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ Figure 4 ] (a) compares the three methods on various dimensionalities of the embedding vector on CUB-200 and Cars- 196. (b) shows the learning curves of the three methods for the training and test set on CUB-200.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;footnote&quot;&gt;footnote&lt;/h3&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;정규화는 모델의 설명력을 높이면서도 복잡도를 줄이는 기법을 가리킨다. 정규화 방법론 중 하나인 L2 정규화는 학습 데이터에 따라 특정 가중치의 값이 지나치게 커지는 걸 방지하도록 한다. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;훈련 데이터에 대한 손실(함수)값이 감소한다고 해서 학습하지 않은 새로운 데이터에서도 같은 정확도를 낸다는 보장은 없다. 이처럼 훈련 데이터에 대해서만 좋은 결과를 내는 현상을 과적합이라고 표현한다. 훈련 데이터에 포함된 노이즈&lt;sup&gt;noise&lt;/sup&gt;마저 버린 상태로, 훈련 데이터가 적을수록 과적합 정도는 심해진다. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;손실값이 작아서 실제 가중치 업데이트에 미비한 영향을 미치는 샘플 &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;손실값이 커서 가중치 업데이트에서 지배적인 영향을 미치는 샘플 &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>aiden:카카오엔터프라이즈</name></author><category term="papers" /><category term="deep metric learning" /><category term="regularization" /><summary type="html">딥러닝 기반 거리 학습(DMLDeep Metric Learning)은 주어진 두 데이터 간 의미적인 거리pairwise distance를 학습하는 방법입니다. 특히 입력 이미지와 유사한 이미지를 찾는 데 효과적인 이 기술은 이미지 검색image retrieval, 상품 추천, 얼굴 인식face recognition과 같은 태스크에서 핵심적으로 활용되고 있습니다.</summary></entry><entry><title type="html">Do Response Selection Models Really Know What’s Next? Utterance Manipulation Strategies for Multi-turn Response Selection</title><link href="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/aaai2021-multi-turn-response-selection" rel="alternate" type="text/html" title="Do Response Selection Models Really Know What’s Next? Utterance Manipulation Strategies for Multi-turn Response Selection" /><published>2021-02-02T00:00:00-06:00</published><updated>2021-02-02T00:00:00-06:00</updated><id>https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/aaai2021-multi-turn-response-selection</id><content type="html" xml:base="https://pages.github.kakaocorp.com/ailab-papers/ailab-papers/papers/aaai2021-multi-turn-response-selection">&lt;p&gt;응답 선택&lt;sup&gt;response selection&lt;/sup&gt;은 다자 간의 대화&lt;sup&gt;multi-turn dialog&lt;/sup&gt;를 보고 후보 문장 중 맥락에 가장 어울리는 문장을 선택하는 태스크를 가리킵니다. 최근에는 BERT, RoBERTa, ELECTRA와 같은 대규모 말뭉치를 사전학습한 언어 모델&lt;sup&gt;language model&lt;/sup&gt;을 이용해 관련 벤치마크 테스트에서 눈에 띄는 성능 향상이 이뤄졌습니다.&lt;/p&gt;

&lt;p&gt;최신 언어 모델 기반한 응답 선택 모델은 대화와 응답 후보군을 입력받으면, 후보 문장의 적정성 여부를 이진 분류&lt;sup&gt;binary classification&lt;/sup&gt;&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;한 결과를 내놓습니다. 공동 연구팀은 의미적 유사도를 기반으로 점수를 내는 언어 모델의 특성상, 응답으로 적절하지 않은 문장에 정답보다 더 높은 점수를 부여하는 경향성을 보이는 기존 방식의 한계를 지적했습니다. 이는 기존의 손실 함수&lt;sup&gt;loss function&lt;/sup&gt;가 발화&lt;sup&gt;utterance&lt;/sup&gt;&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 간 연관성&lt;sup&gt;coherence&lt;/sup&gt;을 충분히 표현하지 못해서 생기는 거로 분석됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-02-02-AAAI-Utterance-Manipulation-Strategies/001.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ 그림 1 ] LM에 기반한 최신의 응답 선택 모델은 대화의 맥락에 호응하지 않음에도 불구, 의미적 유사도가 높은 문장 b에 더 높은 점수를 부여하고 있다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;공동 연구팀은 기존의 한계를 극복하고자 UMS&lt;sup&gt;Utterance Manipulation Strategies&lt;/sup&gt;를 제안했습니다. 이 기법은 대화에서 특정 발화가 어느 위치에 삽입돼야 하는지(insertion), 현재 대화 흐름에서 어떤 발화가 올바르지 않은지(deletion), 특정 발화의 바로 이전 발화의 위치가 어딘지(search)를 배우는 3가지 태스크로 구성됩니다. 자가지도학습&lt;sup&gt;self-supervised learning&lt;/sup&gt;&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;이라 사람이 따로 라벨링 작업을 할 필요가 없고, 기존의 응답 선택 모델을 따로 조정할 필요 없이 미세조정&lt;sup&gt;fine-tuning&lt;/sup&gt;단계에서 합동 훈련&lt;sup&gt;joint-training&lt;/sup&gt;을 진행하면 됩니다&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;실험 결과, UMS를 적용한 응답 선택 모델은 대화 일관성을 효과적으로 학습하며, 여러 언어의 벤치마크&lt;sup&gt;benchmark&lt;/sup&gt;에서 기존 성능을 크게 넘어섰습니다.&lt;/p&gt;

&lt;p&gt;카카오엔터프라이즈는 대화의 맥락에 호응하는 응답을 선택하는 모델의 강건성을 향상하는 연구를 계속 진행할 계획입니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;overall-architecture&quot;&gt;Overall Architecture&lt;/h1&gt;

&lt;p&gt;Figure 1 describes the overview of our proposed method, utterance manipulation strategies. We propose a multi-task learning framework, which consists of three highly effective auxiliary tasks for multi-turn response selection, utterance 1) insertion, 2) deletion, and 3) search. These tasks are jointly trained with the response selection model during the fine-tuning period. To train the auxiliary tasks, we add new special tokens, [INS], [DEL], and [SRCH] for the utterance insertion, deletion, and search tasks, respectively.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-02-02-AAAI-Utterance-Manipulation-Strategies/002.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ Figure 1 ] An overview of Utterance Manipulation Strategies. Input sequence for each manipulation strategy is dynamically constructed by extracting k consecutive utterances from the original dialog context during the training period. Also, target utterance is randomly chosen from either the dialog context (Insertion, Search) or the random dialog (Deletion).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;experiments&quot;&gt;Experiments&lt;/h1&gt;

&lt;p&gt;We obtained new state-of-the-art results on multiple public benchmark datasets (i.e., Ubuntu, Douban, and E-Commerce) and significantly improved results on Korean open-domain dialog corpus.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ailab-papers/assets/img/2021-02-02-AAAI-Utterance-Manipulation-Strategies/003.png&quot; width=&quot;&quot; align=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[ Table 2 ] Results on Ubuntu, Douban, and E-Commerce datasets. All the evaluation results except ours are cited from published literature (Tao et al. 2019b; Yuan et al. 2019; Gu et al. 2020). The underlined numbers mean the best performance for each block and the bold numbers mean state-of-the-art performance for each metric. † denotes statistical significance (p-value &amp;lt; 0.05).&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&quot;footnote&quot;&gt;footnote&lt;/h1&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;이진 분류 과정은 다음과 같다. (1) 비선형 활성 함수&lt;sup&gt;activation function&lt;/sup&gt;인 시그모이드&lt;sup&gt;sigmoid&lt;/sup&gt;를 이용해 점수를 산출한다(eg., 0번(올바른 응답) 클래스: 0.87, 1번(올바르지 않은 응답) 클래스: 0.6). (2) 각 클래스 점수값 중 큰 쪽을 선택하는 이진분류를 수행한다. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;대화 속에서 주고 받는 말의 단위 &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;비라벨링 데이터만 주어진 상태에서 입력 데이터 일부를 라벨로 사용하거나, 사전 지식에 따라 라벨을 스스로 만들어 모델을 훈련하는 방식 &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;공동 연구팀이 제안한 방법은 4개의 손실값(response selection loss + insertion loss + deletion loss + search loss Loss)을 최소화하는 가중치&lt;sup&gt;weight&lt;/sup&gt; 탐색을 목표로 학습을 진행한다. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>황태선:고려대학교</name></author><category term="papers" /><category term="response selection" /><category term="multi-turn dialog" /><summary type="html">응답 선택response selection은 다자 간의 대화multi-turn dialog를 보고 후보 문장 중 맥락에 가장 어울리는 문장을 선택하는 태스크를 가리킵니다. 최근에는 BERT, RoBERTa, ELECTRA와 같은 대규모 말뭉치를 사전학습한 언어 모델language model을 이용해 관련 벤치마크 테스트에서 눈에 띄는 성능 향상이 이뤄졌습니다.</summary></entry></feed>