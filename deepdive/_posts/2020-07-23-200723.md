---
layout: post-deepdive
research-area: NLP
title: "얼굴 인식 알고리즘 선행 연구를 소개합니다"
description: ""
image: 000.jpg
published-date: 2020-07-23
paper: https://openaccess.thecvf.com/content_CVPR_2020/papers/Kim_GroupFace_Learning_Latent_Groups_and_Constructing_Group-Based_Representations_for_Face_CVPR_2020_paper.pdf
authors:
  - samantha:작성,편집
  - aiden:작성,감수
  - tony:감수
  - joshua:감수
tag:
  - face recognition
  - loss function
---

얼굴 인식 기술<sup>face recognition</sup>은 지난 수십 년간 컴퓨터 비전<sup>computer vision</sup>의 주요 연구 분야 중 하나로 자리매김하고 있습니다. [그림 1]처럼 시스템에 입력된 두 이미지 속 인물 간의 동일인 여부를 검증<sup>verification</sup>하거나, 이미지 속 인물이 내부 데이터베이스(DB)에 미리 저장된 인물 중 누구와 가장 유사한지를 식별<sup>identification</sup>하는 데 이 기술이 널리 활용되고 있습니다.

{% include image.html name="001.jpg" width="" align="center" %}
<em class="center">[ 그림 1 ] 얼굴 인식 과정</em>

다만 얼굴 인식 모델의 훈련 또는 추론 단계에서 사진 속 얼굴 위치가 제각기 다르거나 그 촬영 각도가 다르면 얼굴 인식 정확도가 낮아질 수 있습니다. 따라서 사진에서 얼굴 영역을 찾아 동일한 형태의 정면 얼굴을 추출하는 전처리 과정이 선행되어야 합니다. 일반적인 전처리 과정은 다음과 같습니다. 1) 시스템에 입력된 이미지에서 얼굴 영역을 찾아(얼굴 검출<sup>face detection</sup>) 눈과 코 등 얼굴의 특징을 나타내는 점을 찾습니다(얼굴 정렬<sup>face alignment</sup>[^1]). 3) 이 특징점을 이용해 얼굴 영역을 동일한 형태와 크기로 변경합니다(정규화<sup>normalization</sup>[^2]).

[^1]: 얼굴 위에서 특징점<sup>keypoints</sup>의 형태를 잡아간다는 점에서 착안해 '정렬<sup>alignment</sup>'이라는 표현을 쓴다. 얼굴 특징점 검출<sup>face landmark detection</sup>이라고도 부른다.
[^2]: 일부 연구에서는 정규화 단계에서 사진 속 조명을 제거하거나 인물 표정을 같은 식으로 변경하기도 하고, 측면 얼굴을 정면 얼굴로 생성하기도 한다. 하지만 기본적으로 2D 영상의 정규화라고 한다면 오려낸 얼굴을 똑같은 형태로 맞추는 일이다.

{% include image.html name="002.jpeg" width="80%" align="center" %}
<em class="center">[ 그림 2 ] 얼굴 이미지 전처리 과정</em>

얼굴 인식 모델은 수만 명에 달하는 인물로부터 획득한 수백만 장의 정규화된 얼굴 이미지로부터 인물을 잘 구분하는 함축된 얼굴 표현<sup>facial representation</sup>인 특징 벡터<sup>feature vector</sup>를 학습합니다. 그 결과, 최종 얼굴 인식 모델은 입력된 이미지의 특징 벡터 간 유사도<sup>similarity</sup>를 비교하는 방식으로 검증 또는 식별을 수행할 수 있게 됩니다.

카카오엔터프라이즈 AI Lab(이하 AI Lab) 또한 이 얼굴 인식과 관련해 다양한 연구를 진행하고 있습니다. 최근에는 AI Lab(김용현, 노명철, 신종주)이 카카오(박원표)와 공동으로 연구한 얼굴 인식에 전문화된 아키텍처에 관한 논문(GroupFace<sup>Learning Latent Groups and Constructing Group-based Representations for Face Recognition</sup><a id="01">[[1]](#rf01)</a>)이 CVPR 2020에 게재 승인되는 성과를 거두기도 했죠. 이번 글에서는 논문에서 다룬 딥러닝 기반 얼굴 인식 선행 연구를 간단하게 살펴보고자 합니다.

<p class="tech-ground">☛ Tech Ground 데모 페이지 바로 가기 : <b><a href="https://labs.kakaoi.ai/facedetection">얼굴 검출</a></b> 데모</p>

<br/>

# 얼굴 인식 모델의 손실 함수 연구 트렌드

딥러닝 모델의 훈련(가중치 업데이트) 과정은 다음과 같습니다([그림 3]). 먼저 순전파<sup>forward propagation</sup>[^3] 과정에서 데이터를 입력받은 모델은 무작위로 초기화된 가중치를 이용해 예측값을 출력합니다. 그다음, 예측값과 정답 사이의 차이를 정의하는 손실 함수를 이용해 입력에 대한 손실<sup>loss</sup>을 계산합니다. 다음으로, 출력층에서 입력층으로 거슬러 올라가는 역전파<sup>backward propagation</sup>[^4] 과정에서 최적화 알고리즘은 기울기<sup>gradient</sup> 값을 이용해 앞서 구한 손실을 최소화하는 방향으로 모델의 가중치 값을 수정합니다. 딥러닝 모델은 이 과정을 여러 번 반복해서 데이터를 점진적으로 학습하게 됩니다.

[^3]: 입력층-은닉층-출력층을 거쳐서 예측값을 내는 방법
[^4]: 출력층-은닉층-입력층으로 거슬러 올라가며 가중치를 업데이트하는 방법

{% include image.html name="003.jpg" width="80%" align="center" %}
<em class="center">[ 그림 3 ] 딥러닝 모델의 학습 과정</em>

얼굴 인식을 학습하기 위한 손실 함수는 소프트맥스 손실 함수<sup>softmax loss function</sup>, 거리 기반 손실 함수<sup>distance-based loss function</sup>, 앵귤러 마진 기반 손실 함수<sup>angular margin based loss function</sup> 등 크게 세 종류<a id="02">[[2]](#rf02)</a>로 나눠볼 수 있습니다. 이제부터 이 손실 함수를 하나씩 알아보겠습니다.

<br/>

## 1. 소프트맥스 손실 함수

일반 객체 분류 모델인 AlexNet과 ResNet, 그리고 초창기 얼굴 인식 모델인 DeepFace, DeepID의 마지막 출력층은 이전 단계에서 추출된 특징 벡터를 N개의 범주로 분류하기 위해 배치된 완전연결층<sup>fully-connected layer</sup>과 소프트맥스<sup>softmax</sup> 함수[^5]로 구성돼 있습니다. 이후 교차 엔트로피<sup>cross entropy</sup>가 소프트맥스 확률 분포와 정답 분포 사이 오차를 계산합니다. 소프트맥스 확률값을 이용한다는 점에서 이 손실 함수를 소프트맥스 손실 함수라고도 부릅니다.

[^5]: 다범주 분류기에서는 출력값을 제대로 해석하고자 다른 출력 노드와의 상대적인 크기를 비교한다. 이를 위해 각 출력 노드를 0~1 사이로 제한해 이를 합한 값을 1로 만든다.

{% include image.html name="004.jpg" width="55%" align="center" %}
<em class="center">[ 그림 4 ] 소프트맥스 손실 함수</em>

소프트맥스 손실 값을 최소화하는 학습을 통해 모델은 특징 공간<sup>feature space</sup>에 동일인의 두 특징 벡터<sup>intra-class</sup>를 더 가깝게, 비동일인의 두 특징 벡터<sup>inter-class</sup>는 더 멀게 표현할 수 있게 됩니다. 하지만 단순히 소프트맥스 함수만을 사용한 손실 함수로는 수만 명에 달하는 인물의 특징 공간을 효율적으로 학습하기가 어렵습니다. 전체적인 최적화를 고려하지 못하고 국부적인 최적 지점<sup>local minimum</sup>으로 쉽게 수렴할 수 있기 때문입니다. 이로 인해 추론 단계에서 마주하는 학습하지 않은 새로운 얼굴 이미지의 인식 성능은 낮을 수 있습니다.

<br/>

## 2. 거리 기반 손실 함수

거리 기반의 손실 함수 또한 앞서 설명한 소프트맥스 손실 함수처럼 특징 공간에 동일인의 두 특징 벡터를 더 가깝게, 비동일인의 두 특징 벡터는 더 멀게 표현하는 학습에 활용됩니다. 차이점은 특징 벡터 간의 거리를 학습에 직>접 활용하는 부분입니다. 대표적인 거리 기반 손실 함수인 대비<sup>contrastive</sup> 손실 함수와 트리플렛<sup>triplet</sup> 손실 함수를 통해 그 작동 원리에 대해 좀 더 자세히 소개해드리겠습니다.

{% include image.html name="005.jpg" width="50%" align="center" %}
<em class="center">[ 그림 5 ] 거리 기반 손실 함수</em>

대비 손실 함수는 두 얼굴 이미지의 쌍을 구성해 두 특징 벡터 간의 거리를 계산합니다. 여기서 손실 값은 동일인의 두 벡터 간 거리가 멀면 커지고, 반대로 비동일인의 두 벡터간 거리가 가까우면 커집니다. 이에 모델은 이 손실 값을 최소화하는 학습을 통해 동일인에 해당하는 두 벡터를 가깝게, 비동일인의 두 벡터를 더 멀게 표현할 수 있게 됩니다.

하지만 이런 손실 계산 방식에는 한계가 있습니다. 동일인에 해당하는 두 벡터 거리와 비동일인의 두 벡터 거리가 개별적으로 학습되기 때문입니다. 즉, 동일인 간의 벡터 거리가 비동일인 사이 벡터 거리보다 상대적으로 가까워져야 함을 고려하지 못하는 거죠.

{% raw %} 트리플렛 손실 함수는 범주가 같은 벡터 간의 거리와 범주가 다른 벡터 간의 거리의 상대적 관계를 고려하는 방식으로 이 문제를 해결합니다. 먼저, 기준이 되는 이미지 a, 동일인 이미지 p, 그리고 비동일인 이미지 n으로 구성된 트리플렛(a, p, n)을 구성합니다. 트리플렛 손실 함수는 a와 p의 벡터 간 거리를 줄이는 동시에, a와 n의 벡터 간 거리를 넓힙니다. 즉, 두 거리의 차$$(\vert a-n \vert - \vert a-p \vert)$$가 개발자가 임의로 정한 마진값보다 크도록 합니다. 그 결과, 트리플렛 손실 함수로 학습된 인식 모델은 대비 손실 함수와 비교했을 때 더 높은 추론 성능을 보이는 경향이 있습니다. {% endraw %}

다만 지난 2017년을 기점으로 얼굴 인식 관련 딥러닝 모델에서는 거리 기반 손실 함수를 잘 사용하지 않는 추세입니다. 트리플렛을 구성하는 방식에 따라 성능이 크게 달라지기 때문입니다. 특히 범주 수가 많을수록 효과적인 트리플렛을 구성하기도 쉽지 않습니다. 많은 방법이 고안되었음에도, 얼굴 인식처럼 분류해야 할 범주가 많은 상황에서는 효과적인 트리플렛을 구성하는 데는 여전히 어려움이 있습니다.

아울러 컴퓨팅 비용도 상대적으로 더 많이 소모됩니다. 일반적으로 이 손실 함수는 범주의 수가 수십~수백개 수준일 때 효과적으로 동작하나, 수천 개 이상의 범주가 존재할 때는 잘 동작하지 않습니다. 기존 대비 2~4배 이상 배치 크기<sup>batch size</sup>[^6]를 키움으로써 성능 저하를 일부 극복할 수 있지만, 수만 명에 달하는 인물을 다루어야 하는 얼굴 인식 모델에서는 그 역시 쉽지 않은 일입니다.

[^6]: 한차례의 훈련, 즉 가중치를 한 번 업데이트하는 데 사용하는 훈련 집합의 크기

<br/>

## 3. 앵귤러 마진 기반 손실 함수

SphereFace에서 CosFace와 ArcFace로 이어지는 근래의 얼굴 인식 연구는 앵귤러 마진을 추가한 소프트맥스 기반 손실 함수를 이용해 서로 다른 인물 간 거리를 충분히 넓히는 방향으로 진행되고 있습니다.

{% include image.html name="006.jpg" width="50%" align="center" %}
<em class="center">[ 그림 6 ] 앵귤러 마진 기반 손실 함수인 AdaM-소프트맥스</em>

충분히 큰 한정된 공간이 있다고 가정해 보겠습니다. 학습 시 다른 범주를 1의 간격으로 분포하게 만들어도 분류는 완벽하게 이뤄집니다. 여기에 더 나아가, 다른 범주를 10의 간격으로 두고 데이터 분포를 훈련한다면 어떻게 될까요? 학습 난이도는 높을지라도 공간을 효율적으로 사용할 수 있어, 모델의 일반화<sup>generalization</sup>[^7] 성능이 높다고 기대해볼 수 있겠습니다. 여기서는 이러한 간격을 특징 벡터 간의 각도에 적용하였다는 점에서 앵귤러 마진이라는 이름이 붙었습니다.

[^7]: 학습 데이터와 조금이라도 다른 성격의 데이터가 입력되어도 모델이 제대로 동작하는 상태

<br/>

# 한계점

이처럼 손실 함수가 새롭게 제안되고 있음에도 불구하고, 얼굴 인식 모델에게 서로 다른 인물의 얼굴을 구분하는 최적의 특징 공간을 생성하는 방법을 가르치기는 여전히 쉽지 않습니다. AI Lab은 기존 대부분의 손실 함수에 대한 얼굴 인식 연구로는 수만 명의 얼굴을 구분하는 충분한 효과를 기대하기가 어렵다고 판단했습니다. AlexNet, VGGNet, ResNet처럼 수십에서 수천 개의 범주를 분류하는 데 최적화된 범용 모델을 그대로 사용해서는 수만 명의 얼굴을 효과적으로 처리하는 데 적합하지 않다고 본 거죠.

선행 연구가 최대 수만 개의 범주를 효과적으로 분류하려는 목적에서 새로운 손실 함수를 도입했듯이, AI Lab은 이를 위한 특별한 인식 모델 구조를  고민했습니다.

AI Lab은 인간의 얼굴에 각자 고유의 특징이 있으면서도, 동시에 공통적인 특징을 가지고 있다는 점을 면밀히 관찰했습니다. 실제로 얼굴의 공통적인 특징을 모아 보는 그룹화 개념은 현실에서도 누군가를 특정하는 데 유용한 기법으로 활용되고 있습니다. 예를 들어, 검은 머리와 붉은 수염을 가진 남자와 같이 주된 특징을 조합한 몽타주 표현처럼 말이죠.

최종적으로 AI Lab은 얼굴의 유사성을 그룹화해 표현하는 특징 벡터<sup>group-aware representation</sup>를 추출하는 새로운 모델 구조인 GroupFace를 제안했습니다. GroupFace는 다양한 얼굴 인식 모델에 적용 가능합니다. 얼굴 인식 분야 대표적인 9개 공개 데이터셋을 상대로 테스트를 진행해본 결과, GroupFace는 모든 데이터셋에 대해 얼굴 인식 성능을 높였습니다. 특히 IJB 벤치마크에서는 그 정확도를 최대 10%P 가까이 끌어올렸습니다.

AI Lab이 새로 고안한 방법론인 GroupFace의 아이디어와 아키텍처, 성능 평가에 관한 자세한 내용은 해당 논문을 확인해 주시기 바랍니다.

{% include image.html name="007.png" width="70%" align="center" %}
<em class="center">[ 그림 7 ] GroupFace</em>

<br/>

# 참고 문헌

[<a id="rf01" href="#01">1</a>] [GroupFace : Learning Latent Groups and Constructing Group-based Representations for Face Recognition](http://openaccess.thecvf.com/content_CVPR_2020/papers/Kim_GroupFace_Learning_Latent_Groups_and_Constructing_Group-Based_Representations_for_Face_CVPR_2020_paper.pdf) (2020) by Yonghyun Kim, Wonpyo Park, Myung-Cheol Roh, Jongju Shin in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)

[<a id="rf02" href="#02">2</a>] [Deep Face Recognition: A Survey](https://arxiv.org/abs/1804.06655) (2018) by Mei Wang, Weihong Deng in arXiv

<br/>

# 각주
