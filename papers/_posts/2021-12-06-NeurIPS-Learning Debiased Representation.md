---
layout: post
use-katex: true
research-area: COMPUTER VISION
title: Learning Debiased Representation via Disentangled Feature Augmentation
slug: neurips-learning-debiased-representation
description:
published-date: 2021-12-06
publisher: NeurIPS Oral
publisher-fullname: Neural Information Processing Systems (NeurIPS) Oral
authors:
  - μ΄μ •μ:μΉ΄μ΄μ¤νΈ, μΉ΄μΉ΄μ¤μ—”ν„°ν”„λΌμ΄μ¦
  - josh:μΉ΄μ΄μ¤νΈ, μΉ΄μΉ΄μ¤μ—”ν„°ν”„λΌμ΄μ¦
  - michael:μΉ΄μΉ΄μ¤μ—”ν„°ν”„λΌμ΄μ¦
  - μ΄μ§€ν„:μΉ΄μ΄μ¤νΈ
  - μ£Όμ¬κ±Έ:μΉ΄μ΄μ¤νΈ
paper: https://papers.nips.cc/paper/2021/file/d360a502598a4b64b936683b44a5523a-Paper.pdf
code:
deepdive:
tag:
---

# Abstract

Image classification models tend to make decisions based on peripheral attributes of data items that have strong correlation with a target variable (i.e., dataset bias). These biased models suffer from the poor generalization capability when evaluated on unbiased datasets. Existing approaches for debiasing often identify and emphasize those samples with no such correlation (i.e., bias-conflicting) without defining the bias type in advance. However, such bias-conflicting samples are significantly scarce in biased datasets, limiting the debiasing capability of these approaches. This paper first presents an empirical analysis revealing that training with "diverse" bias-conflicting samples beyond a given training set is crucial for debiasing as well as the generalization capability. Based on this observation, we propose a novel feature-level data augmentation technique in order to synthesize diverse bias-conflicting samples. To this end, our method learns the disentangled representation of (1) the intrinsic attributes (i.e., those inherently defining a certain class) and (2) bias attributes (i.e., peripheral attributes causing the bias), from a large number of bias-aligned samples, the bias attributes of which have strong correlation with the target variable. Using the disentangled representation, we synthesize bias-conflicting samples that contain the diverse intrinsic attributes of bias-aligned samples by swapping their latent features. By utilizing these diversified bias-conflicting features during the training, our approach achieves superior classification accuracy and debiasing results against the existing baselines on both synthetic as well as real-world datasets.

<br/>

***

<br/>

λ³Έ κΈ€μ—μ„λ” μΉ΄μΉ΄μ¤μ—”ν„°ν”„λΌμ΄μ¦μ™€ μΉ΄μ΄μ¤νΈ κ³µλ™ μ—°κµ¬ν€μ΄ λ°μ΄ν„°μ…‹μ νΈν–¥(bias) λ¬Έμ λ¥Ό κ°μ„ ν•κΈ° μ„ν•΄ μƒλ΅­κ² μ μ•ν• λ°μ΄ν„° μ¦κ°•(data augmentation) κΈ°λ²•μ„ μ†κ°λ“λ¦¬κ³ μ ν•©λ‹λ‹¤. ν•΄λ‹Ή μ—°κµ¬ κ²°κ³Όλ” NeurIPS 2021 ν•™νμ—μ„ oral presentationμ„ ν†µν•΄ κ³µκ°λμ—μµλ‹λ‹¤.

<br/>

# 1. κΈ°μ΅΄ νΈν–¥μ„± κ°μ„  μ—°κµ¬μ ν•κ³„

λ°μ΄ν„°μ…‹μ νΈν–¥ λ¬Έμ λ” μ΄λ―Έμ§€ λ¶„λ¥ λ¨λΈμ ν•™μµ κ³Όμ •μ—μ„ ν”ν•κ² λ°μƒλ©λ‹λ‹¤. λ°μ΄ν„°λ¥Ό μμ§‘, κ°€κ³µν•λ” κ³Όμ •μ—μ„ μμ—°μ¤λ½κ² μ΅΄μ¬ν•κ² λλ” biasλ΅ μΈν•΄, λ¨λΈμ μ„±λ¥μ΄ ν¬κ² μΆμ°λ  μ μμµλ‹λ‹¤. μ΄λ΅ μΈν•΄ ν›λ ¨ κ³Όμ •μ—μ„λ” λ†’μ€ μ •ν™•λ„λ¥Ό λ³΄μ€λ λ¨λΈμ΄ μ‹¤μ  νΈν–¥λμ§€ μ•μ€ λ°μ΄ν„°μ…‹μ— μ μ©λ  λ•, λ‚®μ€ μ„±λ¥μ„ λ³΄μΌ μ μλ”λ°μ”. μλ¥Ό λ“¤μ–΄ β€μƒβ€™ μ΄λ―Έμ§€λ¥Ό ν•™μµν•λ” κ³Όμ •μ—μ„ ν•™μµν• λ¨λ“  μ΄λ―Έμ§€μ— β€ν•λβ€™μ΄ μμ—λ‹¤λ©΄, ν•λκ³Ό ν•¨κ» μλ” λ¬Όμ²΄λ§ μƒλ΅ μΈμ‹ν•μ—¬ β€λ•…β€™ λλ” β€ν’€β€™ μ„μ— μλ” μƒλ” λ¶„λ¥μ— μ‹¤ν¨ν•  μ μμµλ‹λ‹¤. ν•™μµμμ μλ„μ™€ κ΄€κ³„ μ—†μ΄, λ°μ΄ν„°μ…‹ μμ²΄μ— μ΅΄μ¬ν•λ” νΈν–¥μ„±μ— μν•΄ λ¨λΈμ μ„±λ¥μ΄ μ €ν•λ  μ μλ”κ±΄λ°μ”.

κΈ°μ΅΄ μ—°κµ¬λ“¤μ€ μ΄λ¬ν• νΈν–¥μ„±μ„ μ κ±°ν•κΈ° μ„ν•΄, νΈν–¥μ„±μ„ μ κ±°ν• μƒν”(bias-conflicting sample)μ„ μ¶”κ°€ν•κ±°λ‚, κ°€μ¤‘μΉλ¥Ό μ΅°μ •ν•λ” λ°©μ‹μ„ ν™μ©ν–μµλ‹λ‹¤. μ‚¬μ‹¤μƒ bias-conflicting μƒν”μ„ μμ§‘ν•λ” λ°μ—λ” λ¬Όλ¦¬μ , μ‹κ°„μ  μ–΄λ ¤μ›€μ΄ μκΈ° λ•λ¬Έμ— μ΄λ¬ν• λ°©μ‹μ—λ” ν•κ³„κ°€ μμ—μµλ‹λ‹¤.

<br/>

# 2. λ‹¤μ–‘ν• bias-conflicting μƒν”μ μ¤‘μ”μ„±

λ”¥λ¬λ‹ ν•™μµμ— μμ–΄ μ•κ³ λ¦¬μ¦ μ΄μƒμΌλ΅ μ¤‘μ”ν• κ²ƒμ€ λ°”λ΅ λ°μ΄ν„°μ μ–‘μ…λ‹λ‹¤. λ§μ€ λ°μ΄ν„°λ¥Ό μ ν™μ©ν•λ” κ²ƒμ΄ λ¨λΈμ μ„±λ¥μ„ μΆμ°ν•λ”λ°μ”. μ΄μ— κ³µλ™ μ—°κµ¬ν€μ€ νΈν–¥μ„± κ°μ„ μ„ μ„ν•΄μ„λ” β€λ‹¤μ–‘ν• bias-conficting μƒν”μ„ λ§μ΄ ν™μ©ν•λ” κ²ƒμ΄ λ¨λΈ ν•™μµμ— ν¨κ³Όμ β€™μ΄λΌλ” κ°€μ„¤μ„ κ°€μ§€κ³ , μ΄λ¥Ό κ²€μ¦ν•κΈ° μ„ν• ν† μ΄μ…‹(toy-set) μ‹¤ν—μ„ μ§„ν–‰ν•μ€μµλ‹λ‹¤.

λ¨Όμ € ν›λ ¨ κ³Όμ •μ—λ” κ·Έλ¦Ό1κ³Ό κ°™μ΄ λ‘ κ°€μ§€ λ°μ΄ν„°μ…‹(Colored MNIST, Corrupted CIFAR-10)μ„ ν™μ©ν•μ€μµλ‹λ‹¤. ν•λ‚λ” κΈ°μ΅΄ MNIST λ°μ΄ν„°μ…‹μ—μ„ μ«μμ— νΉμ • μƒ‰μƒμ΄ μμ£Ό λ‚μ¤λ„λ΅ μƒ‰μƒ biasλ¥Ό μ„¤μ •ν• Colored MNISTμ΄κ³ , λ‹¤λ¥Έ ν•λ‚λ” κΈ°μ΅΄ CIFAR-10 λ°μ΄ν„°μ…‹μ—μ„ μ‚¬λ¬Όμ— νΉμ • ν…μ¤μ³(Corruption)κ°€ λ°λ³µλλ„λ΅ ν…μ¤μ³ biasλ¥Ό λ³€ν•ν• Corrupted CIFAR-10μ…λ‹λ‹¤.

{% include image.html name="001.png" width="50%" align="center" %}
<em class="center">κ·Έλ¦Ό1. λ°μ΄ν„°μ…‹ ν•νƒ
(μ μ„  μ„λ” κΈ°μ΅΄ bias-aligned μƒν”μ΄λ©°, μ μ„  μ•„λλ” bias-conflicting μƒν”μ„)</em>

μ•„λ ν‘1μ€ ν•΄λ‹Ή λ°μ΄ν„°μ…‹μΌλ΅ ν•™μµν• λ¨λΈμ— νΈν–¥μ„±μ΄ μ—†λ” ν…μ¤νΈμ…‹(unbiased test sets)μ„ μ μ©ν–μ„ λ•μ λ¶„λ¥ μ •ν™•λ„λ¥Ό λ‚νƒ€λƒ…λ‹λ‹¤. λ‹¤μ–‘ν• bias-conflicting μƒν”μ„ ν•™μµμ— λ§μ΄ ν™μ©ν• κ²½μ°κ°€ κ°€μ¥ λ†’μ€ μ •ν™•λ„λ¥Ό λ³΄μ€μµλ‹λ‹¤. μ—¬κΈ°μ„ μ£Όλ©ν•  μ μ€ λ°”λ΅ μƒν”λ§ λΉ„μ¨λ³΄λ‹¤ λ‹¤μ–‘μ„± λΉ„μ¨μ΄ λ†’μ•μ„ λ•, μƒλ€μ μΌλ΅ λ†’μ€ μ •ν™•λ„λ¥Ό λ³΄μ€λ‹¤λ” μ μ…λ‹λ‹¤.

{% include image.html name="002.png" width="70%" align="center" %}
<em class="center">ν‘1. νΈν–¥μ„±μ΄ μ—†λ” ν…μ¤νΈμ…‹(unbiased test sets)μ—μ„μ λ¶„λ¥ μ •ν™•λ„</em>

μ΄λ¥Ό ν†µν•΄ λ³Έ μ—°κµ¬ν€μ€ λ‹¤μ–‘ν• bias-conflicting μƒν”μ ν™μ©μ΄ νΈν–¥ μ κ±°μ— ν¨κ³Όκ°€ μλ‹¤λ” κ°€μ„¤μ„ κ²€μ¦ν•μ€κ³ ,  bias-conflicting μƒν” λ°μ΄ν„°μ μ¦κ°•μ„ ν†µν•΄ νΈν–¥μ„±μ„ κ°μ„ ν• λ°©λ²•λ΅ μ„ μ μ•ν•μ€μµλ‹λ‹¤.

<br/>

# 3. Debiasing via disentangled feature augmentation λ°©λ²•λ΅  μ†κ°

ν•΄λ‹Ή λ°©λ²•λ΅ μ κ°€μ¥ ν° νΉμ§•μ€ κ° μ΄λ―Έμ§€κ°€ κ°€μ§„ κ³ μ μ†μ„±κ³Ό νΈν–¥μ†μ„±μ„ κµμ°¨ν•©μ„±ν•μ—¬ λ°μ΄ν„°λ¥Ό μ¦κ°•μ‹μΌ°λ‹¤λ” μ μ…λ‹λ‹¤.

μ „μ²΄ κµ¬μ΅°λ¥Ό μ‚΄ν΄λ³΄λ©΄ κ°κ° κ³ μ μ†μ„±($$E_{i}$$), νΈν–¥μ†μ„±($$E_{b}$$)μΌλ΅ κµ¬λ¶„λλ” 2κ°μ μΈμ½”λ”κ°€ μμµλ‹λ‹¤. ν•λ‚μ μ΄λ―Έμ§€κ°€ μ…λ ¥λλ©΄ ν•΄λ‹Ή μΈμ½”λ”λ¥Ό κ±°μ³ κ°κ° κ³ μ μ†μ„±κ³Ό νΈν–¥μ†μ„±μ disentangled featureλ΅ $$Z_{i}$$, $$Z_{b}$$κ°€ μ¶λ ¥λ©λ‹λ‹¤.

μ—¬κΈ°μ„ κ³ μ μ†μ„±κ³Ό νΈν–¥μ†μ„±μ disentanglementλ¥Ό ν•™μµν•κΈ° μ„ν•΄, λ‹¤μκ³Ό κ°™μ€ ν•™μµκ³Όμ •μ„ μ§„ν–‰ν•©λ‹λ‹¤. λ¨Όμ € κ³ μ μ†μ„±μ„ ν•™μµν•λ”λ° μ‚¬μ©λλ” $$E_{b}$$μ™€ $$C_{b}$$λ¥Ό κΈ°μ΅΄ λ…Όλ¬Έ(Nam et al., "Learning from Failure: Training Debiased Classifier from Biased Classifier")μ—μ„ μ μ‹ν• Generalized Cross-Entropy Lossλ¥Ό ν†µν•΄ "μ‰¬μ΄" μ •λ³΄λ§μ„ ν•™μµν•λ„λ΅ κ°•μ ν•©λ‹λ‹¤. μ΄λ¥Ό ν†µν•΄ ν•΄λ‹Ή μΈμ½”λ”λ” μ£Όμ–΄μ§„ μ΄λ―Έμ§€λ΅λ¶€ν„° νΈν–¥μ†μ„±μ„ μ£Όλ΅ μ¶”μ¶ν•κ² λκ³ , μ΄λ ‡κ² νΈν–¥ ν•™μµλ μΈμ½”λ”λ΅λ¶€ν„° μƒλ€μ μΌλ΅ ν° Lossλ¥Ό κ°–κ² λλ” μ΄λ―Έμ§€λ¥Ό Bias-conflicting μƒν”λ΅ νλ‹¨ν•  μ μκ² λ©λ‹λ‹¤. μ΄λ¬ν• μ΄λ―Έμ§€λ“¤μ— λ€ν• κ°€μ¤‘ν•™μµμ„ ν†µν•΄, $$E_{i}$$μ™€ $$C_{i}$$λ” νΈν–¥μ†μ„±μ΄ μ•„λ‹ κ³ μ μ†μ„±μ„ μ£Όλ΅ μ¶”μ¶ν•λ”λ° μ‚¬μ©λ©λ‹λ‹¤.

μ΄λ•, μ΄ ν• μμ ν”Όμ³λ“¤μ„ λ―Έλ‹λ°°μΉ λ‚΄ λ‹¤λ¥Έ λλ¤ μ΄λ―Έμ§€μ ν”Όμ³κ°’κ³Ό κµμ°¨ ν•©μ„±(swapping)μ„ ν•¨μΌλ΅μ¨ κΈ°μ΅΄ κ³ μ μ†μ„±κ³Ό νΈν–¥μ†μ„± κ°„μ κ°•ν• μƒκ΄€κ΄€κ³„(correlation)κ°€ λμ–΄μ§„ μƒν”μ„ μƒμ„±ν•  μ μλ”λ°μ”. μ΄λ” κ³§ νΈν–¥μ„±μ„ κ°€μ§€μ§€ μ•λ” μƒλ΅μ΄ bias-conflicting μƒν”μ„ μλ―Έν•©λ‹λ‹¤. μ΄ κ³Όμ •μ„ ν†µν•΄ μ‹¤μ  νΈν–¥μ„± κ°μ„ μ— ν¨κ³Όμ μΈ μ μλ―Έν• ν•©μ„± κ²°κ³Όλ¬Όμ„ κµ¬ν„ν•  μ μμ—μµλ‹λ‹¤. λν•, λ°μ΄ν„° μ¦κ°•μΌλ΅ ν›λ ¨ λ°μ΄ν„°μ…‹μ λ‹¤μ–‘μ„±μ„ μ¦κ°€μ‹ν‚¤κ³ , λ°μ΄ν„°μ ν’μ§ λν• λ†’μ—¬ λ¶„λ¥ μ •ν™•λ„λ¥Ό ν–¥μƒμ‹ν‚¬ μ μμ—μµλ‹λ‹¤.

{% include image.html name="003.png" width="70%" align="center" %}
<em class="center">κ·Έλ¦Ό2. μ „μ²΄ λ¨λΈμ κµ¬μ΅°</em>

<br/>

# 4. μ„±λ¥ ν‰κ°€

λ³΄λ‹¤ μ •λ‰μ μΈ μ„±λ¥ ν‰κ°€λ¥Ό μ„ν•΄, μ•μ„ μ–ΈκΈ‰ν• 2κ°€μ§€ ν•©μ„± λ°μ΄ν„°μ…‹(Colored MNIST, Corrupted CIFAR-10)κ³Ό ν•¨κ» BFFHQ λ°μ΄ν„°μ…‹μ„ ν™μ©ν•μ—¬ μ‹¤ν—μ„ μ§„ν–‰ν•μ€μµλ‹λ‹¤. μ—¬κΈ°μ„ BFFHQλ” κΈ°μ΅΄ FFHQ λ°μ΄ν„°μ…‹μ΄ κ°€μ§„ λ‚μ΄μ™€ μ„±λ³„ νΈν–¥μ„±(λ€λ‹¤μ λ°μ΄ν„°κ°€ μ μ€ μ—¬μμ™€ λ‚μ΄ λ“  λ‚¨μλ΅ κµ¬μ„±λ¨)μ— λ³€ν•μ„ λ‘” λ°μ΄ν„°μ…‹μ…λ‹λ‹¤.

μ΄ μ„Έκ°€μ§€ λ°μ΄ν„°μ…‹μΌλ΅ ν•™μµν• λ¨λΈμ„ κ°κ° νΈν–¥μ„±μ΄ μ—†λ” ν…μ¤νΈμ…‹μΌλ΅ ν‰κ°€ν–μ„ λ•, μ•„λ ν‘2μ™€ κ°™μ΄ SOTA(State-of-the-art)λ¥Ό λ›°μ–΄λ„λ” μ°μν• μ„±λ¥μ„ λ³΄μ„μ„ ν™•μΈν•μ€μµλ‹λ‹¤. ν•΄λ‹Ή λ°©λ²•λ΅ μ€ ν•©μ„± λ°μ΄ν„°μ…‹ λΏλ§ μ•„λ‹λΌ μ‹¤μ„λΉ„μ¤ μƒμ λ°μ΄ν„°μ…‹μ—λ„ ν¨κ³Όμ μ΄λΌλ” μ‚¬μ‹¤μ„ μ• μ μμ—μµλ‹λ‹¤.

{% include image.html name="004.png" width="70%" align="center" %}
<em class="center">ν‘2. νΈν–¥μ„±μ΄ μ—†λ” ν…μ¤νΈμ…‹(unbiased test sets)μΌλ΅ ν‰κ°€ν• λ¶„λ¥ μ •ν™•λ„</em>

<br/>

# 5. ν–¥ν›„ μ—°κµ¬ κ³„ν

Dataset Bias λ¬Έμ  ν•΄κ²°μ€ μ΄λ―Έμ§€ μΈμ‹, μ–Όκµ΄ μΈμ‹ λ“± μ—¬λ¬ μ»΄ν“¨ν„° λΉ„μ „ κ³Όμ λ¥Ό ν•΄κ²°ν•λ”λ° ν° μ—­ν• μ„ ν•  μ μμµλ‹λ‹¤. μλ¥Ό λ“¤μ–΄ μ•μ„ μ–ΈκΈ‰ν• μ΄λ―Έμ§€ λ¶„λ¥ λ¬Έμ μ—μ„ μ¤μ‹λ¥ μ„ κ°μ„ ν•κ³ , λ¨λΈμ μ„±λ¥μ„ λ†’μ΄λ” λ°μ—λ„ ν™μ©λ  μ μλ”λ°μ”. λ³΄λ‹¤ κµ¬μ²΄μ μΌλ΅λ” λ”¥λ¬λ‹ λ¨λΈμ΄ μ„±λ³„, μΈμΆ…, λ‚μ΄ λ“±κ³Ό κ°™μ΄ νΈν–¥κ³Ό κ΄€λ ¨λ μ—¬λ¬ λ―Όκ°ν• λ¬Έμ μ— λ€ν•΄ λ³΄λ‹¤ μ‹ λΆ°μ„± λ†’μ€ μ •λ‹µμ„ λ„μ¶ν•  μ μλ„λ΅ κΈ°μ—¬ν•  μ μμ„ κ²ƒμΌλ΅ κΈ°λ€λ©λ‹λ‹¤.

ν–¥ν›„ μΉ΄μΉ΄μ¤μ—”ν„°ν”„λΌμ΄μ¦ AI Lab λΉ„μ „ν€μ€ ν•΄λ‹Ή λ°©λ²•λ΅ μ„ κΈ°λ°μΌλ΅ μ—¬λ¬κ°€μ§€ μ»΄ν“¨ν„° λΉ„μ „ λ¬Έμ λ¥Ό ν•΄κ²°ν•κ³ , μ„λΉ„μ¤λ¥Ό κ³ λ„ν™”ν•  κ³„νμ…λ‹λ‹¤. μ•μΌλ΅λ„ μΉ΄μΉ΄μ¤μ—”ν„°ν”„λΌμ΄μ¦ μ—°κµ¬μ— λ§μ€ κ΄€μ‹¬κ³Ό μ‘μ› λ¶€νƒλ“λ¦½λ‹λ‹¤. κ°μ‚¬ν•©λ‹λ‹¤.

<br/>

***

ν„μ¬ μΉ΄μΉ΄μ¤μ—”ν„°ν”„λΌμ΄μ¦ AI Labμ—μ„λ” λ‹¤μ–‘ν• AI μ—°κµ¬μ™€ μ„λΉ„μ¤ν™”λ¥Ό ν•¨κ» κ³ λ―Όν•΄λ‚κ° μ—¬λ¬λ¶„μ μ§€μ›μ„ κΈ°λ‹¤λ¦¬κ³  μμµλ‹λ‹¤. AIλ¥Ό ν†µν•΄ λ”μ± κ°€μΉμλ” μ„Έμƒμ„ λ§λ“¤κ³ , κΏμ„ ν„μ‹¤λ΅ λ§λ“¤μ–΄κ°€λ” μ—¬μ •μ— ν•¨κ»ν•μ„Έμ”!

π‘¨π»β€π’» [μΈμ¬μμ…](http://kko.to/ailab_career)
